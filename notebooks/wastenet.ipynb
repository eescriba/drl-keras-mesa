{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.7 64-bit ('venv': venv)",
      "metadata": {
        "interpreter": {
          "hash": "915e8579bc6bc5b7e6bdee387f64d79c54c721fc11f17b28b0b204a29bde1622"
        }
      }
    },
    "colab": {
      "name": "rllib.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO9547wOqrGb"
      },
      "source": [
        "# WasteNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWzkFkIFqz4C"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pLSISOhRLDK"
      },
      "source": [
        "# Colab\n",
        "!rm -r smart-cities-drl\n",
        "!git clone https://github.com/eescriba/smart-cities-drl\n",
        "!cd smart-cities-drl/ && pip install -e .\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'./smart-cities-drl/src/')\n",
        "\n",
        "# Local\n",
        "# !pip install -e ..\n",
        "# import sys\n",
        "# sys.path.insert(0,'../src/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv2IiHGYRLDQ",
        "outputId": "66deba64-10b9-4217-e4fd-41cbda5c70a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import json\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "import gym\n",
        "import ray\n",
        "from ray.tune import run, choice\n",
        "from core.rl import PPOAgent\n",
        "from core.pbt import PbtOptimizer\n",
        "from wastenet.env import WasteNetEnv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "  \"update your install command.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_compile is deprecated, use jit_compile instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hrqtufqq24H"
      },
      "source": [
        "## Proximal Policy Optimization (PPO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0jHuZL9Tgm_"
      },
      "source": [
        "### Tune hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpHcdjslVi9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7ef665-f0dc-4242-9b04-446d6b6ad701"
      },
      "source": [
        "ppo = PPOAgent(\"wastenet_ppo_tune\", WasteNetEnv, {})"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-25 06:54:32,717\tINFO services.py:1274 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "2021-06-25 06:54:35,580\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "2021-06-25 06:54:35,582\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=256)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=256)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=256)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=257)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=257)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=257)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "2021-06-25 06:54:52,453\tINFO trainable.py:104 -- Trainable.setup took 16.874 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
            "2021-06-25 06:54:52,456\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49VrIblUM4wT"
      },
      "source": [
        "tune_config = {\n",
        "    \"env\": WasteNetEnv,\n",
        "    \"seed\": 123,\n",
        "    \"num_gpus\": 1,\n",
        "    \"num_workers\": 1,\n",
        "    \"observation_filter\": \"MeanStdFilter\",\n",
        "    \"model\": {\n",
        "        \"free_log_std\": True\n",
        "    },\n",
        "    \"lambda\": 0.95,\n",
        "    \"clip_param\": 0.3,\n",
        "    \"lr\": 5e-5,\n",
        "    \"num_sgd_iter\": choice([10, 20, 30]),\n",
        "    \"sgd_minibatch_size\": choice([128, 256, 512]),\n",
        "    \"train_batch_size\": choice([8000, 16000, 32000])\n",
        "}\n",
        "stop_criteria = {\n",
        "    \"timesteps_total\": 2000000\n",
        "}\n",
        "hyperparam_mutations={\n",
        "    \"lambda\": lambda: random.uniform(0.7, 1.0),\n",
        "    \"clip_param\": lambda: random.uniform(0.1, 0.5),\n",
        "    \"lr\": [1e-3, 5e-4, 1e-4, 5e-5, 1e-5],\n",
        "    \"num_sgd_iter\": lambda: random.randint(1, 30),\n",
        "    \"sgd_minibatch_size\": lambda: random.randint(128, 16384),\n",
        "    \"train_batch_size\": lambda: random.randint(2000, 160000),\n",
        "}\n",
        "pbt = PbtOptimizer(hyperparam_mutations)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhEbUSY6Vs-r",
        "outputId": "c189cf53-2fa5-40ea-c7ca-235769b8d87c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ppo.restart()\n",
        "analysis = ppo.tune(tune_config, stop_criteria, scheduler=pbt.scheduler)\n",
        "best_config =  analysis.get_best_config(metric=\"episode_reward_mean\", mode=\"max\")\n",
        "print(\"Best hyperparameters found: \", best_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-25 06:57:02,354\tINFO services.py:1274 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 1.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (8 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m 2021-06-25 06:57:07,532\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m 2021-06-25 06:57:07,532\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=464)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=464)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=464)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=464)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=464)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=464)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=464)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=464)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=464)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=464)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=463)\u001b[0m 2021-06-25 06:57:15,499\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 20000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_06-57-38\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1032.0\n",
            "  episode_reward_mean: -1373.6060606060605\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 66\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6655796766281128\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.028304753825068474\n",
            "          model: {}\n",
            "          policy_loss: -0.04645070433616638\n",
            "          total_loss: 1542.11474609375\n",
            "          vf_explained_var: 0.19557024538516998\n",
            "          vf_loss: 1542.1556396484375\n",
            "    num_agent_steps_sampled: 20000\n",
            "    num_agent_steps_trained: 20000\n",
            "    num_steps_sampled: 20000\n",
            "    num_steps_trained: 20000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.30909090909092\n",
            "    ram_util_percent: 22.748484848484843\n",
            "  pid: 463\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04822207381681087\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059844076582791964\n",
            "    mean_inference_ms: 0.7228077092735025\n",
            "    mean_raw_obs_processing_ms: 0.1356694336074822\n",
            "  time_since_restore: 23.011029958724976\n",
            "  time_this_iter_s: 23.011029958724976\n",
            "  time_total_s: 23.011029958724976\n",
            "  timers:\n",
            "    learn_throughput: 5941.9\n",
            "    learn_time_ms: 3365.927\n",
            "    load_throughput: 662147.007\n",
            "    load_time_ms: 30.205\n",
            "    sample_throughput: 1021.191\n",
            "    sample_time_ms: 19584.97\n",
            "    update_time_ms: 2.825\n",
            "  timestamp: 1624604258\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 20000\n",
            "  training_iteration: 1\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:463</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">          23.011</td><td style=\"text-align: right;\">20000</td><td style=\"text-align: right;\">-1373.61</td><td style=\"text-align: right;\">               -1032</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 40000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_06-58-01\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -722.0\n",
            "  episode_reward_mean: -1084.58\n",
            "  episode_reward_min: -1644.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 133\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.30000001192092896\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6084969639778137\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.025190914049744606\n",
            "          model: {}\n",
            "          policy_loss: -0.05230894312262535\n",
            "          total_loss: 735.4019775390625\n",
            "          vf_explained_var: 0.19240757822990417\n",
            "          vf_loss: 735.4467163085938\n",
            "    num_agent_steps_sampled: 40000\n",
            "    num_agent_steps_trained: 40000\n",
            "    num_steps_sampled: 40000\n",
            "    num_steps_trained: 40000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.07575757575758\n",
            "    ram_util_percent: 22.8\n",
            "  pid: 463\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047886919811656735\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06003278126038911\n",
            "    mean_inference_ms: 0.7214102975312804\n",
            "    mean_raw_obs_processing_ms: 0.13514122124800262\n",
            "  time_since_restore: 45.557868003845215\n",
            "  time_this_iter_s: 22.54683804512024\n",
            "  time_total_s: 45.557868003845215\n",
            "  timers:\n",
            "    learn_throughput: 6210.982\n",
            "    learn_time_ms: 3220.103\n",
            "    load_throughput: 1154906.828\n",
            "    load_time_ms: 17.317\n",
            "    sample_throughput: 1024.544\n",
            "    sample_time_ms: 19520.878\n",
            "    update_time_ms: 2.776\n",
            "  timestamp: 1624604281\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 40000\n",
            "  training_iteration: 2\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:463</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         45.5579</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">-1084.58</td><td style=\"text-align: right;\">                -722</td><td style=\"text-align: right;\">               -1644</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 60000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_06-58-23\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -425.0\n",
            "  episode_reward_mean: -752.55\n",
            "  episode_reward_min: -1208.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 200\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.5499230623245239\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.014201642945408821\n",
            "          model: {}\n",
            "          policy_loss: -0.03488915041089058\n",
            "          total_loss: 453.30194091796875\n",
            "          vf_explained_var: 0.11838731914758682\n",
            "          vf_loss: 453.3304748535156\n",
            "    num_agent_steps_sampled: 60000\n",
            "    num_agent_steps_trained: 60000\n",
            "    num_steps_sampled: 60000\n",
            "    num_steps_trained: 60000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.546875\n",
            "    ram_util_percent: 22.8\n",
            "  pid: 463\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04751531785696857\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06031550607209409\n",
            "    mean_inference_ms: 0.7194105275295187\n",
            "    mean_raw_obs_processing_ms: 0.13451697690923942\n",
            "  time_since_restore: 68.06125617027283\n",
            "  time_this_iter_s: 22.503388166427612\n",
            "  time_total_s: 68.06125617027283\n",
            "  timers:\n",
            "    learn_throughput: 6272.852\n",
            "    learn_time_ms: 3188.343\n",
            "    load_throughput: 1529214.484\n",
            "    load_time_ms: 13.079\n",
            "    sample_throughput: 1027.304\n",
            "    sample_time_ms: 19468.425\n",
            "    update_time_ms: 2.733\n",
            "  timestamp: 1624604303\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 60000\n",
            "  training_iteration: 3\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:463</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         68.0613</td><td style=\"text-align: right;\">60000</td><td style=\"text-align: right;\"> -752.55</td><td style=\"text-align: right;\">                -425</td><td style=\"text-align: right;\">               -1208</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 80000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_06-58-46\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -214.0\n",
            "  episode_reward_mean: -512.29\n",
            "  episode_reward_min: -979.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 266\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.4962548613548279\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.011470436118543148\n",
            "          model: {}\n",
            "          policy_loss: -0.0264006145298481\n",
            "          total_loss: 310.26300048828125\n",
            "          vf_explained_var: 0.10318458080291748\n",
            "          vf_loss: 310.2842712402344\n",
            "    num_agent_steps_sampled: 80000\n",
            "    num_agent_steps_trained: 80000\n",
            "    num_steps_sampled: 80000\n",
            "    num_steps_trained: 80000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.684375\n",
            "    ram_util_percent: 22.8\n",
            "  pid: 463\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047463255662956526\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06081314163064681\n",
            "    mean_inference_ms: 0.7188271874556356\n",
            "    mean_raw_obs_processing_ms: 0.13454715111954163\n",
            "  time_since_restore: 90.6837842464447\n",
            "  time_this_iter_s: 22.622528076171875\n",
            "  time_total_s: 90.6837842464447\n",
            "  timers:\n",
            "    learn_throughput: 6338.906\n",
            "    learn_time_ms: 3155.118\n",
            "    load_throughput: 1849075.419\n",
            "    load_time_ms: 10.816\n",
            "    sample_throughput: 1026.195\n",
            "    sample_time_ms: 19489.476\n",
            "    update_time_ms: 2.755\n",
            "  timestamp: 1624604326\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 80000\n",
            "  training_iteration: 4\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:463</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         90.6838</td><td style=\"text-align: right;\">80000</td><td style=\"text-align: right;\"> -512.29</td><td style=\"text-align: right;\">                -214</td><td style=\"text-align: right;\">                -979</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 100000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_06-59-08\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -156.0\n",
            "  episode_reward_mean: -342.2\n",
            "  episode_reward_min: -647.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 333\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.44390439987182617\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0088455555960536\n",
            "          model: {}\n",
            "          policy_loss: -0.0211667250841856\n",
            "          total_loss: 234.36465454101562\n",
            "          vf_explained_var: 0.1540573388338089\n",
            "          vf_loss: 234.3818359375\n",
            "    num_agent_steps_sampled: 100000\n",
            "    num_agent_steps_trained: 100000\n",
            "    num_steps_sampled: 100000\n",
            "    num_steps_trained: 100000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.56875\n",
            "    ram_util_percent: 22.8\n",
            "  pid: 463\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04737837774900035\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06103647087637141\n",
            "    mean_inference_ms: 0.7172156531096118\n",
            "    mean_raw_obs_processing_ms: 0.13425795467285553\n",
            "  time_since_restore: 112.92583966255188\n",
            "  time_this_iter_s: 22.242055416107178\n",
            "  time_total_s: 112.92583966255188\n",
            "  timers:\n",
            "    learn_throughput: 6376.428\n",
            "    learn_time_ms: 3136.552\n",
            "    load_throughput: 2104116.626\n",
            "    load_time_ms: 9.505\n",
            "    sample_throughput: 1029.621\n",
            "    sample_time_ms: 19424.632\n",
            "    update_time_ms: 2.73\n",
            "  timestamp: 1624604348\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 100000\n",
            "  training_iteration: 5\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:463</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         112.926</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">  -342.2</td><td style=\"text-align: right;\">                -156</td><td style=\"text-align: right;\">                -647</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 120000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_06-59-31\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -94.0\n",
            "  episode_reward_mean: -242.99\n",
            "  episode_reward_min: -429.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 400\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.40162527561187744\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006970599759370089\n",
            "          model: {}\n",
            "          policy_loss: -0.017293790355324745\n",
            "          total_loss: 171.5852813720703\n",
            "          vf_explained_var: 0.26304712891578674\n",
            "          vf_loss: 171.5994415283203\n",
            "    num_agent_steps_sampled: 120000\n",
            "    num_agent_steps_trained: 120000\n",
            "    num_steps_sampled: 120000\n",
            "    num_steps_trained: 120000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.671875\n",
            "    ram_util_percent: 22.8\n",
            "  pid: 463\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047328511924383775\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06117730499775966\n",
            "    mean_inference_ms: 0.7165828098166531\n",
            "    mean_raw_obs_processing_ms: 0.13409730589279845\n",
            "  time_since_restore: 135.45145726203918\n",
            "  time_this_iter_s: 22.525617599487305\n",
            "  time_total_s: 135.45145726203918\n",
            "  timers:\n",
            "    learn_throughput: 6414.094\n",
            "    learn_time_ms: 3118.133\n",
            "    load_throughput: 2311749.808\n",
            "    load_time_ms: 8.651\n",
            "    sample_throughput: 1029.089\n",
            "    sample_time_ms: 19434.659\n",
            "    update_time_ms: 2.625\n",
            "  timestamp: 1624604371\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 120000\n",
            "  training_iteration: 6\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (1 PAUSED, 7 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m 2021-06-25 06:59:35,804\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m 2021-06-25 06:59:35,804\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=592)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=592)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=592)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=592)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=592)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=592)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=592)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=592)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=592)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=592)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=591)\u001b[0m 2021-06-25 06:59:43,706\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 20000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-00-06\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1032.0\n",
            "  episode_reward_mean: -1373.6060606060605\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 66\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6655796766281128\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.028304753825068474\n",
            "          model: {}\n",
            "          policy_loss: -0.04645070433616638\n",
            "          total_loss: 1542.11474609375\n",
            "          vf_explained_var: 0.19557027518749237\n",
            "          vf_loss: 1542.1556396484375\n",
            "    num_agent_steps_sampled: 20000\n",
            "    num_agent_steps_trained: 20000\n",
            "    num_steps_sampled: 20000\n",
            "    num_steps_trained: 20000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.94242424242425\n",
            "    ram_util_percent: 22.8\n",
            "  pid: 591\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04706407307350697\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05766067687979126\n",
            "    mean_inference_ms: 0.7078691361147275\n",
            "    mean_raw_obs_processing_ms: 0.13320161476057057\n",
            "  time_since_restore: 22.515339612960815\n",
            "  time_this_iter_s: 22.515339612960815\n",
            "  time_total_s: 22.515339612960815\n",
            "  timers:\n",
            "    learn_throughput: 6097.482\n",
            "    learn_time_ms: 3280.043\n",
            "    load_throughput: 673232.211\n",
            "    load_time_ms: 29.707\n",
            "    sample_throughput: 1043.098\n",
            "    sample_time_ms: 19173.662\n",
            "    update_time_ms: 3.4\n",
            "  timestamp: 1624604406\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 20000\n",
            "  training_iteration: 1\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (1 PAUSED, 6 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:591</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         22.5153</td><td style=\"text-align: right;\"> 20000</td><td style=\"text-align: right;\">-1373.61</td><td style=\"text-align: right;\">               -1032</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 40000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-00-28\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -722.0\n",
            "  episode_reward_mean: -1084.58\n",
            "  episode_reward_min: -1644.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 133\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.30000001192092896\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6084969639778137\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.02519093081355095\n",
            "          model: {}\n",
            "          policy_loss: -0.05230914056301117\n",
            "          total_loss: 735.4019775390625\n",
            "          vf_explained_var: 0.19240757822990417\n",
            "          vf_loss: 735.4467163085938\n",
            "    num_agent_steps_sampled: 40000\n",
            "    num_agent_steps_trained: 40000\n",
            "    num_steps_sampled: 40000\n",
            "    num_steps_trained: 40000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.909375\n",
            "    ram_util_percent: 22.9\n",
            "  pid: 591\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0471396779389404\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05834153293705285\n",
            "    mean_inference_ms: 0.7095472275446064\n",
            "    mean_raw_obs_processing_ms: 0.13367612263347206\n",
            "  time_since_restore: 45.00619649887085\n",
            "  time_this_iter_s: 22.490856885910034\n",
            "  time_total_s: 45.00619649887085\n",
            "  timers:\n",
            "    learn_throughput: 6236.844\n",
            "    learn_time_ms: 3206.75\n",
            "    load_throughput: 1155670.545\n",
            "    load_time_ms: 17.306\n",
            "    sample_throughput: 1038.606\n",
            "    sample_time_ms: 19256.587\n",
            "    update_time_ms: 3.082\n",
            "  timestamp: 1624604428\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 40000\n",
            "  training_iteration: 2\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (1 PAUSED, 6 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:591</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         45.0062</td><td style=\"text-align: right;\"> 40000</td><td style=\"text-align: right;\">-1084.58</td><td style=\"text-align: right;\">                -722</td><td style=\"text-align: right;\">               -1644</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 60000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-00-51\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -425.0\n",
            "  episode_reward_mean: -752.55\n",
            "  episode_reward_min: -1208.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 200\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.5499230623245239\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.014201642945408821\n",
            "          model: {}\n",
            "          policy_loss: -0.03488915041089058\n",
            "          total_loss: 453.30194091796875\n",
            "          vf_explained_var: 0.11838731914758682\n",
            "          vf_loss: 453.3304748535156\n",
            "    num_agent_steps_sampled: 60000\n",
            "    num_agent_steps_trained: 60000\n",
            "    num_steps_sampled: 60000\n",
            "    num_steps_trained: 60000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.778125\n",
            "    ram_util_percent: 22.9\n",
            "  pid: 591\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04723273768931721\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05917048449543822\n",
            "    mean_inference_ms: 0.7115975672885017\n",
            "    mean_raw_obs_processing_ms: 0.13424348198717578\n",
            "  time_since_restore: 67.51813554763794\n",
            "  time_this_iter_s: 22.51193904876709\n",
            "  time_total_s: 67.51813554763794\n",
            "  timers:\n",
            "    learn_throughput: 6335.007\n",
            "    learn_time_ms: 3157.061\n",
            "    load_throughput: 1526904.184\n",
            "    load_time_ms: 13.098\n",
            "    sample_throughput: 1035.357\n",
            "    sample_time_ms: 19317.001\n",
            "    update_time_ms: 3.136\n",
            "  timestamp: 1624604451\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 60000\n",
            "  training_iteration: 3\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (1 PAUSED, 6 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:591</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         67.5181</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\"> -752.55</td><td style=\"text-align: right;\">                -425</td><td style=\"text-align: right;\">               -1208</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 80000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-01-13\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -214.0\n",
            "  episode_reward_mean: -512.29\n",
            "  episode_reward_min: -979.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 266\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.49625474214553833\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.011470436118543148\n",
            "          model: {}\n",
            "          policy_loss: -0.026400618255138397\n",
            "          total_loss: 310.26300048828125\n",
            "          vf_explained_var: 0.10318458080291748\n",
            "          vf_loss: 310.2842712402344\n",
            "    num_agent_steps_sampled: 80000\n",
            "    num_agent_steps_trained: 80000\n",
            "    num_steps_sampled: 80000\n",
            "    num_steps_trained: 80000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.746875\n",
            "    ram_util_percent: 22.9\n",
            "  pid: 591\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04725969177422144\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059684002214560675\n",
            "    mean_inference_ms: 0.7122230059482431\n",
            "    mean_raw_obs_processing_ms: 0.13450937426718038\n",
            "  time_since_restore: 89.95317244529724\n",
            "  time_this_iter_s: 22.4350368976593\n",
            "  time_total_s: 89.95317244529724\n",
            "  timers:\n",
            "    learn_throughput: 6383.041\n",
            "    learn_time_ms: 3133.303\n",
            "    load_throughput: 1833104.722\n",
            "    load_time_ms: 10.91\n",
            "    sample_throughput: 1034.799\n",
            "    sample_time_ms: 19327.423\n",
            "    update_time_ms: 2.962\n",
            "  timestamp: 1624604473\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 80000\n",
            "  training_iteration: 4\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (1 PAUSED, 6 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:591</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         89.9532</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -512.29</td><td style=\"text-align: right;\">                -214</td><td style=\"text-align: right;\">                -979</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 100000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-01-36\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -156.0\n",
            "  episode_reward_mean: -342.2\n",
            "  episode_reward_min: -647.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 333\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.4439043402671814\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.008845553733408451\n",
            "          model: {}\n",
            "          policy_loss: -0.021166754886507988\n",
            "          total_loss: 234.36465454101562\n",
            "          vf_explained_var: 0.1540573388338089\n",
            "          vf_loss: 234.3818359375\n",
            "    num_agent_steps_sampled: 100000\n",
            "    num_agent_steps_trained: 100000\n",
            "    num_steps_sampled: 100000\n",
            "    num_steps_trained: 100000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.660606060606064\n",
            "    ram_util_percent: 22.9\n",
            "  pid: 591\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047424794454136554\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0601811073040487\n",
            "    mean_inference_ms: 0.7139731484590622\n",
            "    mean_raw_obs_processing_ms: 0.135114885865928\n",
            "  time_since_restore: 112.75725412368774\n",
            "  time_this_iter_s: 22.804081678390503\n",
            "  time_total_s: 112.75725412368774\n",
            "  timers:\n",
            "    learn_throughput: 6421.85\n",
            "    learn_time_ms: 3114.367\n",
            "    load_throughput: 2060313.593\n",
            "    load_time_ms: 9.707\n",
            "    sample_throughput: 1030.29\n",
            "    sample_time_ms: 19412.015\n",
            "    update_time_ms: 2.89\n",
            "  timestamp: 1624604496\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 100000\n",
            "  training_iteration: 5\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (1 PAUSED, 6 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:591</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         112.757</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -342.2 </td><td style=\"text-align: right;\">                -156</td><td style=\"text-align: right;\">                -647</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 120000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-01-59\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -94.0\n",
            "  episode_reward_mean: -242.99\n",
            "  episode_reward_min: -429.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 400\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.40162527561187744\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006970594171434641\n",
            "          model: {}\n",
            "          policy_loss: -0.0172937773168087\n",
            "          total_loss: 171.5852813720703\n",
            "          vf_explained_var: 0.26304706931114197\n",
            "          vf_loss: 171.59945678710938\n",
            "    num_agent_steps_sampled: 120000\n",
            "    num_agent_steps_trained: 120000\n",
            "    num_steps_sampled: 120000\n",
            "    num_steps_trained: 120000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.803125\n",
            "    ram_util_percent: 22.9\n",
            "  pid: 591\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04750464248699867\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0604692615810429\n",
            "    mean_inference_ms: 0.714560635629268\n",
            "    mean_raw_obs_processing_ms: 0.13539093715106076\n",
            "  time_since_restore: 135.227956533432\n",
            "  time_this_iter_s: 22.470702409744263\n",
            "  time_total_s: 135.227956533432\n",
            "  timers:\n",
            "    learn_throughput: 6435.367\n",
            "    learn_time_ms: 3107.826\n",
            "    load_throughput: 2289758.885\n",
            "    load_time_ms: 8.735\n",
            "    sample_throughput: 1030.565\n",
            "    sample_time_ms: 19406.834\n",
            "    update_time_ms: 2.851\n",
            "  timestamp: 1624604519\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 120000\n",
            "  training_iteration: 6\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 6 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m 2021-06-25 07:02:04,027\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m 2021-06-25 07:02:04,028\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=688)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=688)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=688)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=688)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=688)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=688)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=688)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=688)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=688)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=688)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=689)\u001b[0m 2021-06-25 07:02:11,828\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 10000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-02-22\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1174.0\n",
            "  episode_reward_mean: -1416.878787878788\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 33\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6891652941703796\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003971072845160961\n",
            "          model: {}\n",
            "          policy_loss: -0.007431670557707548\n",
            "          total_loss: 2194.807373046875\n",
            "          vf_explained_var: 0.009591028094291687\n",
            "          vf_loss: 2194.81396484375\n",
            "    num_agent_steps_sampled: 10000\n",
            "    num_agent_steps_trained: 10000\n",
            "    num_steps_sampled: 10000\n",
            "    num_steps_trained: 10000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.73333333333334\n",
            "    ram_util_percent: 22.899999999999995\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0470203824572987\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05772189847970769\n",
            "    mean_inference_ms: 0.7157049206730938\n",
            "    mean_raw_obs_processing_ms: 0.13189770653061647\n",
            "  time_since_restore: 10.264394283294678\n",
            "  time_this_iter_s: 10.264394283294678\n",
            "  time_total_s: 10.264394283294678\n",
            "  timers:\n",
            "    learn_throughput: 18186.921\n",
            "    learn_time_ms: 549.846\n",
            "    load_throughput: 297573.891\n",
            "    load_time_ms: 33.605\n",
            "    sample_throughput: 1036.142\n",
            "    sample_time_ms: 9651.187\n",
            "    update_time_ms: 3.275\n",
            "  timestamp: 1624604542\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 10000\n",
            "  training_iteration: 1\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         10.2644</td><td style=\"text-align: right;\"> 10000</td><td style=\"text-align: right;\">-1416.88</td><td style=\"text-align: right;\">               -1174</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 20000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-02-32\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -904.0\n",
            "  episode_reward_mean: -1313.0151515151515\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 66\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6501545310020447\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.022569987922906876\n",
            "          model: {}\n",
            "          policy_loss: -0.035024985671043396\n",
            "          total_loss: 1653.03759765625\n",
            "          vf_explained_var: 0.036851853132247925\n",
            "          vf_loss: 1653.070556640625\n",
            "    num_agent_steps_sampled: 20000\n",
            "    num_agent_steps_trained: 20000\n",
            "    num_steps_sampled: 20000\n",
            "    num_steps_trained: 20000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.40666666666666\n",
            "    ram_util_percent: 22.899999999999995\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047442739031801184\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0587149581911702\n",
            "    mean_inference_ms: 0.7208803649734958\n",
            "    mean_raw_obs_processing_ms: 0.1327143698459703\n",
            "  time_since_restore: 20.606483459472656\n",
            "  time_this_iter_s: 10.342089176177979\n",
            "  time_total_s: 20.606483459472656\n",
            "  timers:\n",
            "    learn_throughput: 21408.62\n",
            "    learn_time_ms: 467.102\n",
            "    load_throughput: 522833.868\n",
            "    load_time_ms: 19.127\n",
            "    sample_throughput: 1020.651\n",
            "    sample_time_ms: 9797.668\n",
            "    update_time_ms: 2.769\n",
            "  timestamp: 1624604552\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 20000\n",
            "  training_iteration: 2\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         20.6065</td><td style=\"text-align: right;\"> 20000</td><td style=\"text-align: right;\">-1313.02</td><td style=\"text-align: right;\">                -904</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 30000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-02-42\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -720.0\n",
            "  episode_reward_mean: -1206.25\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 100\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.15000000596046448\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.5845321416854858\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.019719747826457024\n",
            "          model: {}\n",
            "          policy_loss: -0.03321979194879532\n",
            "          total_loss: 1224.773681640625\n",
            "          vf_explained_var: 0.07767835259437561\n",
            "          vf_loss: 1224.803955078125\n",
            "    num_agent_steps_sampled: 30000\n",
            "    num_agent_steps_trained: 30000\n",
            "    num_steps_sampled: 30000\n",
            "    num_steps_trained: 30000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.35000000000001\n",
            "    ram_util_percent: 22.9\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047524971060470184\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05897698396805623\n",
            "    mean_inference_ms: 0.7215200373560112\n",
            "    mean_raw_obs_processing_ms: 0.13281673729521262\n",
            "  time_since_restore: 30.68121027946472\n",
            "  time_this_iter_s: 10.074726819992065\n",
            "  time_total_s: 30.68121027946472\n",
            "  timers:\n",
            "    learn_throughput: 22562.888\n",
            "    learn_time_ms: 443.206\n",
            "    load_throughput: 726085.24\n",
            "    load_time_ms: 13.772\n",
            "    sample_throughput: 1025.175\n",
            "    sample_time_ms: 9754.434\n",
            "    update_time_ms: 2.677\n",
            "  timestamp: 1624604562\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 30000\n",
            "  training_iteration: 3\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         30.6812</td><td style=\"text-align: right;\"> 30000</td><td style=\"text-align: right;\">-1206.25</td><td style=\"text-align: right;\">                -720</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 40000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-02-52\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -600.0\n",
            "  episode_reward_mean: -994.48\n",
            "  episode_reward_min: -1543.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 133\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.15000000596046448\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.5243884325027466\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.012888263911008835\n",
            "          model: {}\n",
            "          policy_loss: -0.023995308205485344\n",
            "          total_loss: 789.994873046875\n",
            "          vf_explained_var: 0.14112257957458496\n",
            "          vf_loss: 790.0169677734375\n",
            "    num_agent_steps_sampled: 40000\n",
            "    num_agent_steps_trained: 40000\n",
            "    num_steps_sampled: 40000\n",
            "    num_steps_trained: 40000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.319999999999986\n",
            "    ram_util_percent: 22.899999999999995\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04768128811545233\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059550754107222305\n",
            "    mean_inference_ms: 0.7233198483390558\n",
            "    mean_raw_obs_processing_ms: 0.1329781584740173\n",
            "  time_since_restore: 40.715577363967896\n",
            "  time_this_iter_s: 10.034367084503174\n",
            "  time_total_s: 40.715577363967896\n",
            "  timers:\n",
            "    learn_throughput: 23510.376\n",
            "    learn_time_ms: 425.344\n",
            "    load_throughput: 900055.579\n",
            "    load_time_ms: 11.11\n",
            "    sample_throughput: 1027.908\n",
            "    sample_time_ms: 9728.5\n",
            "    update_time_ms: 2.634\n",
            "  timestamp: 1624604572\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 40000\n",
            "  training_iteration: 4\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         40.7156</td><td style=\"text-align: right;\"> 40000</td><td style=\"text-align: right;\"> -994.48</td><td style=\"text-align: right;\">                -600</td><td style=\"text-align: right;\">               -1543</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 50000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-03-02\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -362.0\n",
            "  episode_reward_mean: -804.63\n",
            "  episode_reward_min: -1282.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 166\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.15000000596046448\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.46906232833862305\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.010832453146576881\n",
            "          model: {}\n",
            "          policy_loss: -0.022409094497561455\n",
            "          total_loss: 555.7473754882812\n",
            "          vf_explained_var: 0.2050563544034958\n",
            "          vf_loss: 555.7681884765625\n",
            "    num_agent_steps_sampled: 50000\n",
            "    num_agent_steps_trained: 50000\n",
            "    num_steps_sampled: 50000\n",
            "    num_steps_trained: 50000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.29999999999999\n",
            "    ram_util_percent: 22.9\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04751876459903677\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05951081890997208\n",
            "    mean_inference_ms: 0.7212457382952755\n",
            "    mean_raw_obs_processing_ms: 0.13244214233278945\n",
            "  time_since_restore: 50.728720903396606\n",
            "  time_this_iter_s: 10.013143539428711\n",
            "  time_total_s: 50.728720903396606\n",
            "  timers:\n",
            "    learn_throughput: 24161.347\n",
            "    learn_time_ms: 413.884\n",
            "    load_throughput: 1050614.192\n",
            "    load_time_ms: 9.518\n",
            "    sample_throughput: 1029.926\n",
            "    sample_time_ms: 9709.431\n",
            "    update_time_ms: 2.615\n",
            "  timestamp: 1624604582\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 50000\n",
            "  training_iteration: 5\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         50.7287</td><td style=\"text-align: right;\"> 50000</td><td style=\"text-align: right;\"> -804.63</td><td style=\"text-align: right;\">                -362</td><td style=\"text-align: right;\">               -1282</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 60000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-03-12\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -362.0\n",
            "  episode_reward_mean: -649.76\n",
            "  episode_reward_min: -1118.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 200\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.15000000596046448\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.4204593300819397\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.007903369143605232\n",
            "          model: {}\n",
            "          policy_loss: -0.014680784195661545\n",
            "          total_loss: 414.50555419921875\n",
            "          vf_explained_var: 0.2806284427642822\n",
            "          vf_loss: 414.51904296875\n",
            "    num_agent_steps_sampled: 60000\n",
            "    num_agent_steps_trained: 60000\n",
            "    num_steps_sampled: 60000\n",
            "    num_steps_trained: 60000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.221428571428575\n",
            "    ram_util_percent: 22.9\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04740901481131644\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05961981416125849\n",
            "    mean_inference_ms: 0.720186672023898\n",
            "    mean_raw_obs_processing_ms: 0.13201823388640307\n",
            "  time_since_restore: 60.819461822509766\n",
            "  time_this_iter_s: 10.09074091911316\n",
            "  time_total_s: 60.819461822509766\n",
            "  timers:\n",
            "    learn_throughput: 24562.172\n",
            "    learn_time_ms: 407.13\n",
            "    load_throughput: 1180756.804\n",
            "    load_time_ms: 8.469\n",
            "    sample_throughput: 1030.005\n",
            "    sample_time_ms: 9708.687\n",
            "    update_time_ms: 2.612\n",
            "  timestamp: 1624604592\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 60000\n",
            "  training_iteration: 6\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         60.8195</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\"> -649.76</td><td style=\"text-align: right;\">                -362</td><td style=\"text-align: right;\">               -1118</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 70000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-03-22\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -203.0\n",
            "  episode_reward_mean: -529.63\n",
            "  episode_reward_min: -967.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 233\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.15000000596046448\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.380587637424469\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006405563559383154\n",
            "          model: {}\n",
            "          policy_loss: -0.008524668402969837\n",
            "          total_loss: 273.2839660644531\n",
            "          vf_explained_var: 0.3432725965976715\n",
            "          vf_loss: 273.2914733886719\n",
            "    num_agent_steps_sampled: 70000\n",
            "    num_agent_steps_trained: 70000\n",
            "    num_steps_sampled: 70000\n",
            "    num_steps_trained: 70000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.46\n",
            "    ram_util_percent: 22.899999999999995\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04732769976797282\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05976827266860604\n",
            "    mean_inference_ms: 0.7193242844352759\n",
            "    mean_raw_obs_processing_ms: 0.13178192378981682\n",
            "  time_since_restore: 70.84369039535522\n",
            "  time_this_iter_s: 10.024228572845459\n",
            "  time_total_s: 70.84369039535522\n",
            "  timers:\n",
            "    learn_throughput: 24735.356\n",
            "    learn_time_ms: 404.28\n",
            "    load_throughput: 1307666.831\n",
            "    load_time_ms: 7.647\n",
            "    sample_throughput: 1031.289\n",
            "    sample_time_ms: 9696.606\n",
            "    update_time_ms: 2.633\n",
            "  timestamp: 1624604602\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 70000\n",
            "  training_iteration: 7\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         70.8437</td><td style=\"text-align: right;\"> 70000</td><td style=\"text-align: right;\"> -529.63</td><td style=\"text-align: right;\">                -203</td><td style=\"text-align: right;\">                -967</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 80000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-03-33\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -203.0\n",
            "  episode_reward_mean: -442.52\n",
            "  episode_reward_min: -902.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 266\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.15000000596046448\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.34902626276016235\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006177704781293869\n",
            "          model: {}\n",
            "          policy_loss: -0.018750693649053574\n",
            "          total_loss: 219.2126007080078\n",
            "          vf_explained_var: 0.3847576975822449\n",
            "          vf_loss: 219.23045349121094\n",
            "    num_agent_steps_sampled: 80000\n",
            "    num_agent_steps_trained: 80000\n",
            "    num_steps_sampled: 80000\n",
            "    num_steps_trained: 80000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.86666666666666\n",
            "    ram_util_percent: 22.899999999999995\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04732773951670206\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060009374810023976\n",
            "    mean_inference_ms: 0.7198575998035818\n",
            "    mean_raw_obs_processing_ms: 0.131839300824911\n",
            "  time_since_restore: 81.25678014755249\n",
            "  time_this_iter_s: 10.413089752197266\n",
            "  time_total_s: 81.25678014755249\n",
            "  timers:\n",
            "    learn_throughput: 24785.586\n",
            "    learn_time_ms: 403.46\n",
            "    load_throughput: 1423583.478\n",
            "    load_time_ms: 7.025\n",
            "    sample_throughput: 1027.222\n",
            "    sample_time_ms: 9734.997\n",
            "    update_time_ms: 2.603\n",
            "  timestamp: 1624604613\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 80000\n",
            "  training_iteration: 8\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         81.2568</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -442.52</td><td style=\"text-align: right;\">                -203</td><td style=\"text-align: right;\">                -902</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 90000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-03-43\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -181.0\n",
            "  episode_reward_mean: -360.39\n",
            "  episode_reward_min: -666.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 300\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.15000000596046448\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.3082418441772461\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0041052973829209805\n",
            "          model: {}\n",
            "          policy_loss: -0.014482850208878517\n",
            "          total_loss: 168.8410186767578\n",
            "          vf_explained_var: 0.4288322329521179\n",
            "          vf_loss: 168.85488891601562\n",
            "    num_agent_steps_sampled: 90000\n",
            "    num_agent_steps_trained: 90000\n",
            "    num_steps_sampled: 90000\n",
            "    num_steps_trained: 90000\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.23571428571428\n",
            "    ram_util_percent: 22.957142857142856\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047347218417310974\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06025805675440773\n",
            "    mean_inference_ms: 0.7207114230410295\n",
            "    mean_raw_obs_processing_ms: 0.13198374356702813\n",
            "  time_since_restore: 91.47961163520813\n",
            "  time_this_iter_s: 10.22283148765564\n",
            "  time_total_s: 91.47961163520813\n",
            "  timers:\n",
            "    learn_throughput: 25012.504\n",
            "    learn_time_ms: 399.8\n",
            "    load_throughput: 1532993.397\n",
            "    load_time_ms: 6.523\n",
            "    sample_throughput: 1025.991\n",
            "    sample_time_ms: 9746.674\n",
            "    update_time_ms: 2.6\n",
            "  timestamp: 1624604623\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 90000\n",
            "  training_iteration: 9\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         91.4796</td><td style=\"text-align: right;\"> 90000</td><td style=\"text-align: right;\"> -360.39</td><td style=\"text-align: right;\">                -181</td><td style=\"text-align: right;\">                -666</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 100000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-03-53\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -180.0\n",
            "  episode_reward_mean: -313.37\n",
            "  episode_reward_min: -557.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 333\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.07500000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.27720609307289124\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004781362600624561\n",
            "          model: {}\n",
            "          policy_loss: -0.013201327063143253\n",
            "          total_loss: 141.3533935546875\n",
            "          vf_explained_var: 0.4548262655735016\n",
            "          vf_loss: 141.36624145507812\n",
            "    num_agent_steps_sampled: 100000\n",
            "    num_agent_steps_trained: 100000\n",
            "    num_steps_sampled: 100000\n",
            "    num_steps_trained: 100000\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.466666666666676\n",
            "    ram_util_percent: 22.899999999999995\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04739150696367793\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06050691576257178\n",
            "    mean_inference_ms: 0.7217944951827968\n",
            "    mean_raw_obs_processing_ms: 0.13211246664863072\n",
            "  time_since_restore: 101.57472395896912\n",
            "  time_this_iter_s: 10.095112323760986\n",
            "  time_total_s: 101.57472395896912\n",
            "  timers:\n",
            "    learn_throughput: 25177.711\n",
            "    learn_time_ms: 397.177\n",
            "    load_throughput: 1636814.336\n",
            "    load_time_ms: 6.109\n",
            "    sample_throughput: 1026.382\n",
            "    sample_time_ms: 9742.964\n",
            "    update_time_ms: 2.643\n",
            "  timestamp: 1624604633\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 100000\n",
            "  training_iteration: 10\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         101.575</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -313.37</td><td style=\"text-align: right;\">                -180</td><td style=\"text-align: right;\">                -557</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 110000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-04-03\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -127.0\n",
            "  episode_reward_mean: -268.0\n",
            "  episode_reward_min: -460.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 366\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.03750000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.2656960189342499\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0036249980330467224\n",
            "          model: {}\n",
            "          policy_loss: -0.013403034768998623\n",
            "          total_loss: 116.32189178466797\n",
            "          vf_explained_var: 0.5051747560501099\n",
            "          vf_loss: 116.33516693115234\n",
            "    num_agent_steps_sampled: 110000\n",
            "    num_agent_steps_trained: 110000\n",
            "    num_steps_sampled: 110000\n",
            "    num_steps_trained: 110000\n",
            "  iterations_since_restore: 11\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.32142857142857\n",
            "    ram_util_percent: 22.9\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04737888157075145\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06063778750531386\n",
            "    mean_inference_ms: 0.7217241432810733\n",
            "    mean_raw_obs_processing_ms: 0.13205038292193186\n",
            "  time_since_restore: 111.63425278663635\n",
            "  time_this_iter_s: 10.059528827667236\n",
            "  time_total_s: 111.63425278663635\n",
            "  timers:\n",
            "    learn_throughput: 26213.179\n",
            "    learn_time_ms: 381.487\n",
            "    load_throughput: 3335298.0\n",
            "    load_time_ms: 2.998\n",
            "    sample_throughput: 1026.34\n",
            "    sample_time_ms: 9743.357\n",
            "    update_time_ms: 2.566\n",
            "  timestamp: 1624604643\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 110000\n",
            "  training_iteration: 11\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 1 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (2 PAUSED, 5 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:689</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         111.634</td><td style=\"text-align: right;\">110000</td><td style=\"text-align: right;\"> -268   </td><td style=\"text-align: right;\">                -127</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 120000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-04-13\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -95.0\n",
            "  episode_reward_mean: -236.79\n",
            "  episode_reward_min: -460.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 400\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.01875000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.2356177270412445\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004195921588689089\n",
            "          model: {}\n",
            "          policy_loss: -0.014059938490390778\n",
            "          total_loss: 95.55453491210938\n",
            "          vf_explained_var: 0.541361927986145\n",
            "          vf_loss: 95.56851959228516\n",
            "    num_agent_steps_sampled: 120000\n",
            "    num_agent_steps_trained: 120000\n",
            "    num_steps_sampled: 120000\n",
            "    num_steps_trained: 120000\n",
            "  iterations_since_restore: 12\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.43333333333333\n",
            "    ram_util_percent: 22.899999999999995\n",
            "  pid: 689\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04734928391419626\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06073814675155566\n",
            "    mean_inference_ms: 0.7213541596998183\n",
            "    mean_raw_obs_processing_ms: 0.13194546156543427\n",
            "  time_since_restore: 121.74419379234314\n",
            "  time_this_iter_s: 10.109941005706787\n",
            "  time_total_s: 121.74419379234314\n",
            "  timers:\n",
            "    learn_throughput: 26358.02\n",
            "    learn_time_ms: 379.391\n",
            "    load_throughput: 3547910.234\n",
            "    load_time_ms: 2.819\n",
            "    sample_throughput: 1028.554\n",
            "    sample_time_ms: 9722.391\n",
            "    update_time_ms: 2.61\n",
            "  timestamp: 1624604653\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 120000\n",
            "  training_iteration: 12\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 5 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m 2021-06-25 07:04:18,569\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m 2021-06-25 07:04:18,569\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=802)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=802)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=802)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=802)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=802)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=802)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=802)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=802)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=802)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=802)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=801)\u001b[0m 2021-06-25 07:04:26,321\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 10000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-04-36\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1174.0\n",
            "  episode_reward_mean: -1416.878787878788\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 33\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6927469968795776\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00039088804624043405\n",
            "          model: {}\n",
            "          policy_loss: 0.004110022448003292\n",
            "          total_loss: 2200.55029296875\n",
            "          vf_explained_var: 0.002796560525894165\n",
            "          vf_loss: 2200.546142578125\n",
            "    num_agent_steps_sampled: 10000\n",
            "    num_agent_steps_trained: 10000\n",
            "    num_steps_sampled: 10000\n",
            "    num_steps_trained: 10000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.25333333333334\n",
            "    ram_util_percent: 22.973333333333336\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04741897846195605\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059186595759979664\n",
            "    mean_inference_ms: 0.7210949780571259\n",
            "    mean_raw_obs_processing_ms: 0.13531252045999012\n",
            "  time_since_restore: 10.183043241500854\n",
            "  time_this_iter_s: 10.183043241500854\n",
            "  time_total_s: 10.183043241500854\n",
            "  timers:\n",
            "    learn_throughput: 27285.669\n",
            "    learn_time_ms: 366.493\n",
            "    load_throughput: 321077.837\n",
            "    load_time_ms: 31.145\n",
            "    sample_throughput: 1025.115\n",
            "    sample_time_ms: 9755.0\n",
            "    update_time_ms: 3.657\n",
            "  timestamp: 1624604676\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 10000\n",
            "  training_iteration: 1\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">          10.183</td><td style=\"text-align: right;\"> 10000</td><td style=\"text-align: right;\">-1416.88</td><td style=\"text-align: right;\">               -1174</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 20000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-04-46\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1013.0\n",
            "  episode_reward_mean: -1355.060606060606\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 66\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6896038055419922\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.001505479565821588\n",
            "          model: {}\n",
            "          policy_loss: -0.010102611035108566\n",
            "          total_loss: 1863.615966796875\n",
            "          vf_explained_var: 0.009043216705322266\n",
            "          vf_loss: 1863.6260986328125\n",
            "    num_agent_steps_sampled: 20000\n",
            "    num_agent_steps_trained: 20000\n",
            "    num_steps_sampled: 20000\n",
            "    num_steps_trained: 20000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.685714285714276\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0474355828278027\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05927889040738556\n",
            "    mean_inference_ms: 0.7201994838553505\n",
            "    mean_raw_obs_processing_ms: 0.1351009020188254\n",
            "  time_since_restore: 20.084777116775513\n",
            "  time_this_iter_s: 9.901733875274658\n",
            "  time_total_s: 20.084777116775513\n",
            "  timers:\n",
            "    learn_throughput: 36651.226\n",
            "    learn_time_ms: 272.842\n",
            "    load_throughput: 592470.213\n",
            "    load_time_ms: 16.878\n",
            "    sample_throughput: 1027.433\n",
            "    sample_time_ms: 9732.995\n",
            "    update_time_ms: 3.074\n",
            "  timestamp: 1624604686\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 20000\n",
            "  training_iteration: 2\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         20.0848</td><td style=\"text-align: right;\"> 20000</td><td style=\"text-align: right;\">-1355.06</td><td style=\"text-align: right;\">               -1013</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 30000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-04-56\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -919.0\n",
            "  episode_reward_mean: -1328.14\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 100\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6736770868301392\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0061995298601686954\n",
            "          model: {}\n",
            "          policy_loss: -0.027044573798775673\n",
            "          total_loss: 1873.464111328125\n",
            "          vf_explained_var: 0.01943381130695343\n",
            "          vf_loss: 1873.4908447265625\n",
            "    num_agent_steps_sampled: 30000\n",
            "    num_agent_steps_trained: 30000\n",
            "    num_steps_sampled: 30000\n",
            "    num_steps_trained: 30000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.621428571428574\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047324537631598836\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05918759769638918\n",
            "    mean_inference_ms: 0.7189218221685714\n",
            "    mean_raw_obs_processing_ms: 0.13471259061753674\n",
            "  time_since_restore: 29.903918504714966\n",
            "  time_this_iter_s: 9.819141387939453\n",
            "  time_total_s: 29.903918504714966\n",
            "  timers:\n",
            "    learn_throughput: 39766.173\n",
            "    learn_time_ms: 251.47\n",
            "    load_throughput: 783698.85\n",
            "    load_time_ms: 12.76\n",
            "    sample_throughput: 1032.288\n",
            "    sample_time_ms: 9687.222\n",
            "    update_time_ms: 3.309\n",
            "  timestamp: 1624604696\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 30000\n",
            "  training_iteration: 3\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         29.9039</td><td style=\"text-align: right;\"> 30000</td><td style=\"text-align: right;\">-1328.14</td><td style=\"text-align: right;\">                -919</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 40000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-05-06\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -817.0\n",
            "  episode_reward_mean: -1218.33\n",
            "  episode_reward_min: -1626.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 133\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6309508085250854\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.01213205885142088\n",
            "          model: {}\n",
            "          policy_loss: -0.029525931924581528\n",
            "          total_loss: 1424.11669921875\n",
            "          vf_explained_var: 0.03843072056770325\n",
            "          vf_loss: 1424.1456298828125\n",
            "    num_agent_steps_sampled: 40000\n",
            "    num_agent_steps_trained: 40000\n",
            "    num_steps_sampled: 40000\n",
            "    num_steps_trained: 40000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.707142857142856\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047205476340942375\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059095097618205986\n",
            "    mean_inference_ms: 0.7170293014097204\n",
            "    mean_raw_obs_processing_ms: 0.13411956829335178\n",
            "  time_since_restore: 39.721696853637695\n",
            "  time_this_iter_s: 9.81777834892273\n",
            "  time_total_s: 39.721696853637695\n",
            "  timers:\n",
            "    learn_throughput: 42346.315\n",
            "    learn_time_ms: 236.148\n",
            "    load_throughput: 965145.227\n",
            "    load_time_ms: 10.361\n",
            "    sample_throughput: 1034.204\n",
            "    sample_time_ms: 9669.277\n",
            "    update_time_ms: 3.167\n",
            "  timestamp: 1624604706\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 40000\n",
            "  training_iteration: 4\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         39.7217</td><td style=\"text-align: right;\"> 40000</td><td style=\"text-align: right;\">-1218.33</td><td style=\"text-align: right;\">                -817</td><td style=\"text-align: right;\">               -1626</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 50000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-05-16\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -631.0\n",
            "  episode_reward_mean: -1095.86\n",
            "  episode_reward_min: -1606.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 166\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.5767536163330078\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.011188002303242683\n",
            "          model: {}\n",
            "          policy_loss: -0.030287116765975952\n",
            "          total_loss: 1084.8250732421875\n",
            "          vf_explained_var: 0.06470693647861481\n",
            "          vf_loss: 1084.854736328125\n",
            "    num_agent_steps_sampled: 50000\n",
            "    num_agent_steps_trained: 50000\n",
            "    num_steps_sampled: 50000\n",
            "    num_steps_trained: 50000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.679999999999986\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04710326769320928\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05906764112223611\n",
            "    mean_inference_ms: 0.7161783089648407\n",
            "    mean_raw_obs_processing_ms: 0.13372401584204993\n",
            "  time_since_restore: 49.69240474700928\n",
            "  time_this_iter_s: 9.970707893371582\n",
            "  time_total_s: 49.69240474700928\n",
            "  timers:\n",
            "    learn_throughput: 44208.523\n",
            "    learn_time_ms: 226.201\n",
            "    load_throughput: 1127907.364\n",
            "    load_time_ms: 8.866\n",
            "    sample_throughput: 1032.004\n",
            "    sample_time_ms: 9689.889\n",
            "    update_time_ms: 3.141\n",
            "  timestamp: 1624604716\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 50000\n",
            "  training_iteration: 5\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         49.6924</td><td style=\"text-align: right;\"> 50000</td><td style=\"text-align: right;\">-1095.86</td><td style=\"text-align: right;\">                -631</td><td style=\"text-align: right;\">               -1606</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 60000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-05-26\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -579.0\n",
            "  episode_reward_mean: -935.98\n",
            "  episode_reward_min: -1413.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 200\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.5236678123474121\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.008859435096383095\n",
            "          model: {}\n",
            "          policy_loss: -0.018057474866509438\n",
            "          total_loss: 864.7879028320312\n",
            "          vf_explained_var: 0.09373229742050171\n",
            "          vf_loss: 864.8054809570312\n",
            "    num_agent_steps_sampled: 60000\n",
            "    num_agent_steps_trained: 60000\n",
            "    num_steps_sampled: 60000\n",
            "    num_steps_trained: 60000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.5\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04712611822473667\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05922901122364423\n",
            "    mean_inference_ms: 0.7162103158522277\n",
            "    mean_raw_obs_processing_ms: 0.13361337014188104\n",
            "  time_since_restore: 59.58753418922424\n",
            "  time_this_iter_s: 9.895129442214966\n",
            "  time_total_s: 59.58753418922424\n",
            "  timers:\n",
            "    learn_throughput: 45381.981\n",
            "    learn_time_ms: 220.352\n",
            "    load_throughput: 1280260.47\n",
            "    load_time_ms: 7.811\n",
            "    sample_throughput: 1031.952\n",
            "    sample_time_ms: 9690.377\n",
            "    update_time_ms: 3.076\n",
            "  timestamp: 1624604726\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 60000\n",
            "  training_iteration: 6\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         59.5875</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\"> -935.98</td><td style=\"text-align: right;\">                -579</td><td style=\"text-align: right;\">               -1413</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 70000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-05-36\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -433.0\n",
            "  episode_reward_mean: -780.95\n",
            "  episode_reward_min: -1158.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 233\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.4825896620750427\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.007136927451938391\n",
            "          model: {}\n",
            "          policy_loss: -0.012750966474413872\n",
            "          total_loss: 571.5410766601562\n",
            "          vf_explained_var: 0.1377474069595337\n",
            "          vf_loss: 571.553466796875\n",
            "    num_agent_steps_sampled: 70000\n",
            "    num_agent_steps_trained: 70000\n",
            "    num_steps_sampled: 70000\n",
            "    num_steps_trained: 70000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.61428571428571\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04717890238409551\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05952620581020346\n",
            "    mean_inference_ms: 0.7169487920976632\n",
            "    mean_raw_obs_processing_ms: 0.133729238055109\n",
            "  time_since_restore: 69.59835720062256\n",
            "  time_this_iter_s: 10.010823011398315\n",
            "  time_total_s: 69.59835720062256\n",
            "  timers:\n",
            "    learn_throughput: 46231.995\n",
            "    learn_time_ms: 216.3\n",
            "    load_throughput: 1409816.235\n",
            "    load_time_ms: 7.093\n",
            "    sample_throughput: 1030.181\n",
            "    sample_time_ms: 9707.032\n",
            "    update_time_ms: 3.067\n",
            "  timestamp: 1624604736\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 70000\n",
            "  training_iteration: 7\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         69.5984</td><td style=\"text-align: right;\"> 70000</td><td style=\"text-align: right;\"> -780.95</td><td style=\"text-align: right;\">                -433</td><td style=\"text-align: right;\">               -1158</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 80000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-05-46\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -375.0\n",
            "  episode_reward_mean: -664.78\n",
            "  episode_reward_min: -1055.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 266\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.4393034875392914\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004457156639546156\n",
            "          model: {}\n",
            "          policy_loss: -0.013328619301319122\n",
            "          total_loss: 483.5673522949219\n",
            "          vf_explained_var: 0.17526942491531372\n",
            "          vf_loss: 483.58050537109375\n",
            "    num_agent_steps_sampled: 80000\n",
            "    num_agent_steps_trained: 80000\n",
            "    num_steps_sampled: 80000\n",
            "    num_steps_trained: 80000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.657142857142844\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04723790654492901\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0598339969122916\n",
            "    mean_inference_ms: 0.7174833656473044\n",
            "    mean_raw_obs_processing_ms: 0.13386584070541058\n",
            "  time_since_restore: 79.62726879119873\n",
            "  time_this_iter_s: 10.028911590576172\n",
            "  time_total_s: 79.62726879119873\n",
            "  timers:\n",
            "    learn_throughput: 46994.318\n",
            "    learn_time_ms: 212.792\n",
            "    load_throughput: 1534169.372\n",
            "    load_time_ms: 6.518\n",
            "    sample_throughput: 1028.559\n",
            "    sample_time_ms: 9722.342\n",
            "    update_time_ms: 2.982\n",
            "  timestamp: 1624604746\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 80000\n",
            "  training_iteration: 8\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         79.6273</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -664.78</td><td style=\"text-align: right;\">                -375</td><td style=\"text-align: right;\">               -1055</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 90000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-05-56\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -246.0\n",
            "  episode_reward_mean: -543.33\n",
            "  episode_reward_min: -1015.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 300\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.4051678776741028\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004481499083340168\n",
            "          model: {}\n",
            "          policy_loss: -0.018244072794914246\n",
            "          total_loss: 332.79632568359375\n",
            "          vf_explained_var: 0.2404259294271469\n",
            "          vf_loss: 332.814453125\n",
            "    num_agent_steps_sampled: 90000\n",
            "    num_agent_steps_trained: 90000\n",
            "    num_steps_sampled: 90000\n",
            "    num_steps_trained: 90000\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.60000000000001\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04735125826797506\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06015824325183003\n",
            "    mean_inference_ms: 0.718129510415153\n",
            "    mean_raw_obs_processing_ms: 0.1340173879497978\n",
            "  time_since_restore: 89.59674453735352\n",
            "  time_this_iter_s: 9.969475746154785\n",
            "  time_total_s: 89.59674453735352\n",
            "  timers:\n",
            "    learn_throughput: 47415.387\n",
            "    learn_time_ms: 210.902\n",
            "    load_throughput: 1637674.988\n",
            "    load_time_ms: 6.106\n",
            "    sample_throughput: 1028.091\n",
            "    sample_time_ms: 9726.767\n",
            "    update_time_ms: 2.965\n",
            "  timestamp: 1624604756\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 90000\n",
            "  training_iteration: 9\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         89.5967</td><td style=\"text-align: right;\"> 90000</td><td style=\"text-align: right;\"> -543.33</td><td style=\"text-align: right;\">                -246</td><td style=\"text-align: right;\">               -1015</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 100000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-06-06\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -246.0\n",
            "  episode_reward_mean: -476.77\n",
            "  episode_reward_min: -791.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 333\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.37401846051216125\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0035456756595522165\n",
            "          model: {}\n",
            "          policy_loss: -0.0141130480915308\n",
            "          total_loss: 301.3857727050781\n",
            "          vf_explained_var: 0.25573405623435974\n",
            "          vf_loss: 301.39984130859375\n",
            "    num_agent_steps_sampled: 100000\n",
            "    num_agent_steps_trained: 100000\n",
            "    num_steps_sampled: 100000\n",
            "    num_steps_trained: 100000\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.414285714285704\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04742332054951477\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06041697027560325\n",
            "    mean_inference_ms: 0.7182325156340497\n",
            "    mean_raw_obs_processing_ms: 0.13402584401448675\n",
            "  time_since_restore: 99.44982242584229\n",
            "  time_this_iter_s: 9.85307788848877\n",
            "  time_total_s: 99.44982242584229\n",
            "  timers:\n",
            "    learn_throughput: 48091.858\n",
            "    learn_time_ms: 207.935\n",
            "    load_throughput: 1725128.121\n",
            "    load_time_ms: 5.797\n",
            "    sample_throughput: 1028.795\n",
            "    sample_time_ms: 9720.108\n",
            "    update_time_ms: 2.924\n",
            "  timestamp: 1624604766\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 100000\n",
            "  training_iteration: 10\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         99.4498</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -476.77</td><td style=\"text-align: right;\">                -246</td><td style=\"text-align: right;\">                -791</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 110000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-06-16\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -207.0\n",
            "  episode_reward_mean: -406.55\n",
            "  episode_reward_min: -791.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 366\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.3529828190803528\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004030855838209391\n",
            "          model: {}\n",
            "          policy_loss: -0.00950455479323864\n",
            "          total_loss: 247.55001831054688\n",
            "          vf_explained_var: 0.30598127841949463\n",
            "          vf_loss: 247.55950927734375\n",
            "    num_agent_steps_sampled: 110000\n",
            "    num_agent_steps_trained: 110000\n",
            "    num_steps_sampled: 110000\n",
            "    num_steps_trained: 110000\n",
            "  iterations_since_restore: 11\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.9\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04746125159681796\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060607883416928285\n",
            "    mean_inference_ms: 0.7182406713415699\n",
            "    mean_raw_obs_processing_ms: 0.133959780593436\n",
            "  time_since_restore: 109.43761467933655\n",
            "  time_this_iter_s: 9.987792253494263\n",
            "  time_total_s: 109.43761467933655\n",
            "  timers:\n",
            "    learn_throughput: 52746.691\n",
            "    learn_time_ms: 189.585\n",
            "    load_throughput: 3330319.271\n",
            "    load_time_ms: 3.003\n",
            "    sample_throughput: 1028.404\n",
            "    sample_time_ms: 9723.807\n",
            "    update_time_ms: 2.84\n",
            "  timestamp: 1624604776\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 110000\n",
            "  training_iteration: 11\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         109.438</td><td style=\"text-align: right;\">110000</td><td style=\"text-align: right;\"> -406.55</td><td style=\"text-align: right;\">                -207</td><td style=\"text-align: right;\">                -791</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 120000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-06-26\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -182.0\n",
            "  episode_reward_mean: -378.65\n",
            "  episode_reward_min: -645.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 400\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0031250000465661287\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.32571420073509216\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.002876883838325739\n",
            "          model: {}\n",
            "          policy_loss: -0.007882369682192802\n",
            "          total_loss: 241.93124389648438\n",
            "          vf_explained_var: 0.32456982135772705\n",
            "          vf_loss: 241.93910217285156\n",
            "    num_agent_steps_sampled: 120000\n",
            "    num_agent_steps_trained: 120000\n",
            "    num_steps_sampled: 120000\n",
            "    num_steps_trained: 120000\n",
            "  iterations_since_restore: 12\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.34285714285714\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04743464182271283\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060788540655473323\n",
            "    mean_inference_ms: 0.7182533046497456\n",
            "    mean_raw_obs_processing_ms: 0.13392848052497125\n",
            "  time_since_restore: 119.40228223800659\n",
            "  time_this_iter_s: 9.964667558670044\n",
            "  time_total_s: 119.40228223800659\n",
            "  timers:\n",
            "    learn_throughput: 52496.856\n",
            "    learn_time_ms: 190.488\n",
            "    load_throughput: 3320143.435\n",
            "    load_time_ms: 3.012\n",
            "    sample_throughput: 1027.836\n",
            "    sample_time_ms: 9729.177\n",
            "    update_time_ms: 2.866\n",
            "  timestamp: 1624604786\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 120000\n",
            "  training_iteration: 12\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (3 PAUSED, 4 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:801</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         119.402</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -378.65</td><td style=\"text-align: right;\">                -182</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-25 07:06:36,188\tINFO pbt.py:543 -- [exploit] transferring weights from trial PPO_WasteNetEnv_8c324_00002 (score -236.79) -> PPO_WasteNetEnv_8c324_00003 (score -345.19)\n",
            "2021-06-25 07:06:36,189\tINFO pbt.py:558 -- [explore] perturbed config from {'lambda': 0.9, 'clip_param': 0.3, 'lr': 5e-05, 'num_sgd_iter': 20, 'sgd_minibatch_size': 2048, 'train_batch_size': 10000} -> {'lambda': 0.9615230483514837, 'clip_param': 0.48677423988167945, 'lr': 0.0001, 'num_sgd_iter': 24, 'sgd_minibatch_size': 14043, 'train_batch_size': 28086}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 130000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-06-36\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -168.0\n",
            "  episode_reward_mean: -345.19\n",
            "  episode_reward_min: -645.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 433\n",
            "  experiment_id: 4f83619180b0476882125d5947c2b2ad\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0015625000232830644\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.30633240938186646\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0029428531415760517\n",
            "          model: {}\n",
            "          policy_loss: -0.004626805428415537\n",
            "          total_loss: 187.84048461914062\n",
            "          vf_explained_var: 0.3756711483001709\n",
            "          vf_loss: 187.84512329101562\n",
            "    num_agent_steps_sampled: 130000\n",
            "    num_agent_steps_trained: 130000\n",
            "    num_steps_sampled: 130000\n",
            "    num_steps_trained: 130000\n",
            "  iterations_since_restore: 13\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.346666666666664\n",
            "    ram_util_percent: 23.0\n",
            "  pid: 801\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04743767501620713\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0609664299005958\n",
            "    mean_inference_ms: 0.7187357498762463\n",
            "    mean_raw_obs_processing_ms: 0.1340171606729717\n",
            "  time_since_restore: 129.50581192970276\n",
            "  time_this_iter_s: 10.103529691696167\n",
            "  time_total_s: 129.50581192970276\n",
            "  timers:\n",
            "    learn_throughput: 52920.738\n",
            "    learn_time_ms: 188.962\n",
            "    load_throughput: 3563009.905\n",
            "    load_time_ms: 2.807\n",
            "    sample_throughput: 1024.64\n",
            "    sample_time_ms: 9759.529\n",
            "    update_time_ms: 2.732\n",
            "  timestamp: 1624604796\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 130000\n",
            "  training_iteration: 13\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (4 PAUSED, 4 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m 2021-06-25 07:06:40,792\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m 2021-06-25 07:06:40,792\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m 2021-06-25 07:06:40,793\tWARNING ppo.py:143 -- `train_batch_size` (28086) cannot be achieved with your other settings (num_workers=1 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 28086.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=927)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=927)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=927)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=927)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=927)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=927)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=927)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=927)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=927)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=927)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m 2021-06-25 07:06:49,047\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m 2021-06-25 07:06:49,124\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00003_3_num_sgd_iter=10,sgd_minibatch_size=2048,train_batch_size=10000_2021-06-25_07-01-59/tmpwc0malz2restore_from_object/checkpoint-12\n",
            "\u001b[2m\u001b[36m(pid=902)\u001b[0m 2021-06-25 07:06:49,125\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 12, '_timesteps_total': None, '_time_total': 121.74419379234314, '_episodes_total': 400}\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m 2021-06-25 07:06:53,799\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m 2021-06-25 07:06:53,800\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=995)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=995)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=995)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=995)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=995)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=995)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=995)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=995)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=995)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=995)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=994)\u001b[0m 2021-06-25 07:07:01,606\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 10000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-07-14\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1174.0\n",
            "  episode_reward_mean: -1416.878787878788\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 33\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6627295017242432\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.031285326927900314\n",
            "          model: {}\n",
            "          policy_loss: -0.049077264964580536\n",
            "          total_loss: 1671.9827880859375\n",
            "          vf_explained_var: 0.21256378293037415\n",
            "          vf_loss: 1672.0255126953125\n",
            "    num_agent_steps_sampled: 10000\n",
            "    num_agent_steps_trained: 10000\n",
            "    num_steps_sampled: 10000\n",
            "    num_steps_trained: 10000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.65789473684212\n",
            "    ram_util_percent: 23.021052631578954\n",
            "  pid: 994\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046136414762759564\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05710161920667064\n",
            "    mean_inference_ms: 0.7375646931995643\n",
            "    mean_raw_obs_processing_ms: 0.12936037595886407\n",
            "  time_since_restore: 13.019428253173828\n",
            "  time_this_iter_s: 13.019428253173828\n",
            "  time_total_s: 13.019428253173828\n",
            "  timers:\n",
            "    learn_throughput: 3186.304\n",
            "    learn_time_ms: 3138.433\n",
            "    load_throughput: 364535.065\n",
            "    load_time_ms: 27.432\n",
            "    sample_throughput: 1017.849\n",
            "    sample_time_ms: 9824.637\n",
            "    update_time_ms: 3.184\n",
            "  timestamp: 1624604834\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 10000\n",
            "  training_iteration: 1\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (4 PAUSED, 3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:994</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         13.0194</td><td style=\"text-align: right;\"> 10000</td><td style=\"text-align: right;\">-1416.88</td><td style=\"text-align: right;\">               -1174</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 20000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-07-27\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -625.0\n",
            "  episode_reward_mean: -1199.2878787878788\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 66\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.30000001192092896\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6059379577636719\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.025192486122250557\n",
            "          model: {}\n",
            "          policy_loss: -0.046799976378679276\n",
            "          total_loss: 730.176513671875\n",
            "          vf_explained_var: 0.20895221829414368\n",
            "          vf_loss: 730.2158203125\n",
            "    num_agent_steps_sampled: 20000\n",
            "    num_agent_steps_trained: 20000\n",
            "    num_steps_sampled: 20000\n",
            "    num_steps_trained: 20000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.17777777777779\n",
            "    ram_util_percent: 23.100000000000005\n",
            "  pid: 994\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046390404337251605\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0578952302817002\n",
            "    mean_inference_ms: 0.7337507741561112\n",
            "    mean_raw_obs_processing_ms: 0.130574381863793\n",
            "  time_since_restore: 25.776849269866943\n",
            "  time_this_iter_s: 12.757421016693115\n",
            "  time_total_s: 25.776849269866943\n",
            "  timers:\n",
            "    learn_throughput: 3269.466\n",
            "    learn_time_ms: 3058.604\n",
            "    load_throughput: 634169.81\n",
            "    load_time_ms: 15.769\n",
            "    sample_throughput: 1020.951\n",
            "    sample_time_ms: 9794.794\n",
            "    update_time_ms: 2.983\n",
            "  timestamp: 1624604847\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 20000\n",
            "  training_iteration: 2\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (4 PAUSED, 3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:994</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         25.7768</td><td style=\"text-align: right;\"> 20000</td><td style=\"text-align: right;\">-1199.29</td><td style=\"text-align: right;\">                -625</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 30000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-07-40\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -510.0\n",
            "  episode_reward_mean: -1033.44\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 100\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.5509965419769287\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.013448664918541908\n",
            "          model: {}\n",
            "          policy_loss: -0.03423546254634857\n",
            "          total_loss: 517.3688354492188\n",
            "          vf_explained_var: 0.10981020331382751\n",
            "          vf_loss: 517.39697265625\n",
            "    num_agent_steps_sampled: 30000\n",
            "    num_agent_steps_trained: 30000\n",
            "    num_steps_sampled: 30000\n",
            "    num_steps_trained: 30000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.21111111111111\n",
            "    ram_util_percent: 23.100000000000005\n",
            "  pid: 994\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04651493533289934\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05840660915926092\n",
            "    mean_inference_ms: 0.7314415268111486\n",
            "    mean_raw_obs_processing_ms: 0.13111224690465687\n",
            "  time_since_restore: 38.45004749298096\n",
            "  time_this_iter_s: 12.673198223114014\n",
            "  time_total_s: 38.45004749298096\n",
            "  timers:\n",
            "    learn_throughput: 3319.44\n",
            "    learn_time_ms: 3012.557\n",
            "    load_throughput: 871272.123\n",
            "    load_time_ms: 11.477\n",
            "    sample_throughput: 1022.832\n",
            "    sample_time_ms: 9776.776\n",
            "    update_time_ms: 2.867\n",
            "  timestamp: 1624604860\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 30000\n",
            "  training_iteration: 3\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (4 PAUSED, 3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:994</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">          38.45 </td><td style=\"text-align: right;\"> 30000</td><td style=\"text-align: right;\">-1033.44</td><td style=\"text-align: right;\">                -510</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 40000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-07-52\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -327.0\n",
            "  episode_reward_mean: -731.39\n",
            "  episode_reward_min: -1282.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 133\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.509957492351532\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.009681403636932373\n",
            "          model: {}\n",
            "          policy_loss: -0.024498404935002327\n",
            "          total_loss: 384.5679016113281\n",
            "          vf_explained_var: 0.06320042908191681\n",
            "          vf_loss: 384.5880432128906\n",
            "    num_agent_steps_sampled: 40000\n",
            "    num_agent_steps_trained: 40000\n",
            "    num_steps_sampled: 40000\n",
            "    num_steps_trained: 40000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.138888888888886\n",
            "    ram_util_percent: 23.100000000000005\n",
            "  pid: 994\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046655318256018624\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05926546473001228\n",
            "    mean_inference_ms: 0.7269188308787552\n",
            "    mean_raw_obs_processing_ms: 0.13197014306989424\n",
            "  time_since_restore: 51.055715560913086\n",
            "  time_this_iter_s: 12.605668067932129\n",
            "  time_total_s: 51.055715560913086\n",
            "  timers:\n",
            "    learn_throughput: 3337.306\n",
            "    learn_time_ms: 2996.429\n",
            "    load_throughput: 1069525.327\n",
            "    load_time_ms: 9.35\n",
            "    sample_throughput: 1026.319\n",
            "    sample_time_ms: 9743.564\n",
            "    update_time_ms: 2.924\n",
            "  timestamp: 1624604872\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 40000\n",
            "  training_iteration: 4\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (4 PAUSED, 3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:994</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         51.0557</td><td style=\"text-align: right;\"> 40000</td><td style=\"text-align: right;\"> -731.39</td><td style=\"text-align: right;\">                -327</td><td style=\"text-align: right;\">               -1282</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 50000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-08-05\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -248.0\n",
            "  episode_reward_mean: -532.95\n",
            "  episode_reward_min: -987.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 166\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.4717772603034973\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006468078121542931\n",
            "          model: {}\n",
            "          policy_loss: -0.016951052471995354\n",
            "          total_loss: 282.1720886230469\n",
            "          vf_explained_var: 0.10445982217788696\n",
            "          vf_loss: 282.18609619140625\n",
            "    num_agent_steps_sampled: 50000\n",
            "    num_agent_steps_trained: 50000\n",
            "    num_steps_sampled: 50000\n",
            "    num_steps_trained: 50000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.51578947368422\n",
            "    ram_util_percent: 23.100000000000005\n",
            "  pid: 994\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04663920523589919\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059720883571668715\n",
            "    mean_inference_ms: 0.7244329519924466\n",
            "    mean_raw_obs_processing_ms: 0.1320179975208928\n",
            "  time_since_restore: 63.74461078643799\n",
            "  time_this_iter_s: 12.688895225524902\n",
            "  time_total_s: 63.74461078643799\n",
            "  timers:\n",
            "    learn_throughput: 3339.089\n",
            "    learn_time_ms: 2994.829\n",
            "    load_throughput: 1243206.137\n",
            "    load_time_ms: 8.044\n",
            "    sample_throughput: 1027.48\n",
            "    sample_time_ms: 9732.552\n",
            "    update_time_ms: 2.954\n",
            "  timestamp: 1624604885\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 50000\n",
            "  training_iteration: 5\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (4 PAUSED, 3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:994</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         63.7446</td><td style=\"text-align: right;\"> 50000</td><td style=\"text-align: right;\"> -532.95</td><td style=\"text-align: right;\">                -248</td><td style=\"text-align: right;\">                -987</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 60000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-08-18\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -120.0\n",
            "  episode_reward_mean: -398.02\n",
            "  episode_reward_min: -691.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 200\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.432300329208374\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005995919927954674\n",
            "          model: {}\n",
            "          policy_loss: -0.016992248594760895\n",
            "          total_loss: 212.5089874267578\n",
            "          vf_explained_var: 0.18808868527412415\n",
            "          vf_loss: 212.52328491210938\n",
            "    num_agent_steps_sampled: 60000\n",
            "    num_agent_steps_trained: 60000\n",
            "    num_steps_sampled: 60000\n",
            "    num_steps_trained: 60000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.37777777777779\n",
            "    ram_util_percent: 23.100000000000005\n",
            "  pid: 994\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04654479503086012\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05999624245602805\n",
            "    mean_inference_ms: 0.7221382066833658\n",
            "    mean_raw_obs_processing_ms: 0.1318855429621464\n",
            "  time_since_restore: 76.29677152633667\n",
            "  time_this_iter_s: 12.552160739898682\n",
            "  time_total_s: 76.29677152633667\n",
            "  timers:\n",
            "    learn_throughput: 3347.165\n",
            "    learn_time_ms: 2987.603\n",
            "    load_throughput: 1384662.415\n",
            "    load_time_ms: 7.222\n",
            "    sample_throughput: 1030.013\n",
            "    sample_time_ms: 9708.611\n",
            "    update_time_ms: 2.828\n",
            "  timestamp: 1624604898\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 60000\n",
            "  training_iteration: 6\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (4 PAUSED, 3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:994</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         76.2968</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\"> -398.02</td><td style=\"text-align: right;\">                -120</td><td style=\"text-align: right;\">                -691</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 70000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-08-30\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -82.0\n",
            "  episode_reward_mean: -305.91\n",
            "  episode_reward_min: -544.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 233\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.39641761779785156\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005048434250056744\n",
            "          model: {}\n",
            "          policy_loss: -0.0124360928311944\n",
            "          total_loss: 133.85414123535156\n",
            "          vf_explained_var: 0.37232574820518494\n",
            "          vf_loss: 133.8643035888672\n",
            "    num_agent_steps_sampled: 70000\n",
            "    num_agent_steps_trained: 70000\n",
            "    num_steps_sampled: 70000\n",
            "    num_steps_trained: 70000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.166666666666664\n",
            "    ram_util_percent: 23.100000000000005\n",
            "  pid: 994\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04648283404503466\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06017649660825406\n",
            "    mean_inference_ms: 0.720264366874125\n",
            "    mean_raw_obs_processing_ms: 0.13178988589507415\n",
            "  time_since_restore: 88.85714316368103\n",
            "  time_this_iter_s: 12.56037163734436\n",
            "  time_total_s: 88.85714316368103\n",
            "  timers:\n",
            "    learn_throughput: 3345.619\n",
            "    learn_time_ms: 2988.984\n",
            "    load_throughput: 1518692.771\n",
            "    load_time_ms: 6.585\n",
            "    sample_throughput: 1032.398\n",
            "    sample_time_ms: 9686.191\n",
            "    update_time_ms: 2.763\n",
            "  timestamp: 1624604910\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 70000\n",
            "  training_iteration: 7\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (4 PAUSED, 3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:994</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         88.8571</td><td style=\"text-align: right;\"> 70000</td><td style=\"text-align: right;\"> -305.91</td><td style=\"text-align: right;\">                 -82</td><td style=\"text-align: right;\">                -544</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 80000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-08-43\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -82.0\n",
            "  episode_reward_mean: -245.32\n",
            "  episode_reward_min: -534.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 266\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.36987873911857605\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005278170574456453\n",
            "          model: {}\n",
            "          policy_loss: -0.014762068167328835\n",
            "          total_loss: 94.73658752441406\n",
            "          vf_explained_var: 0.49395185708999634\n",
            "          vf_loss: 94.74897766113281\n",
            "    num_agent_steps_sampled: 80000\n",
            "    num_agent_steps_trained: 80000\n",
            "    num_steps_sampled: 80000\n",
            "    num_steps_trained: 80000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.80555555555556\n",
            "    ram_util_percent: 23.100000000000005\n",
            "  pid: 994\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04642651090584003\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06029701560871412\n",
            "    mean_inference_ms: 0.7189810377479263\n",
            "    mean_raw_obs_processing_ms: 0.13172578882397346\n",
            "  time_since_restore: 101.63384008407593\n",
            "  time_this_iter_s: 12.776696920394897\n",
            "  time_total_s: 101.63384008407593\n",
            "  timers:\n",
            "    learn_throughput: 3341.234\n",
            "    learn_time_ms: 2992.906\n",
            "    load_throughput: 1627220.802\n",
            "    load_time_ms: 6.145\n",
            "    sample_throughput: 1031.636\n",
            "    sample_time_ms: 9693.345\n",
            "    update_time_ms: 2.788\n",
            "  timestamp: 1624604923\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 80000\n",
            "  training_iteration: 8\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (4 PAUSED, 3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:994</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         101.634</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -245.32</td><td style=\"text-align: right;\">                 -82</td><td style=\"text-align: right;\">                -534</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 90000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-08-56\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -79.0\n",
            "  episode_reward_mean: -191.17\n",
            "  episode_reward_min: -345.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 300\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.3402855098247528\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005262432619929314\n",
            "          model: {}\n",
            "          policy_loss: -0.013767989352345467\n",
            "          total_loss: 70.9498291015625\n",
            "          vf_explained_var: 0.5799325704574585\n",
            "          vf_loss: 70.96123504638672\n",
            "    num_agent_steps_sampled: 90000\n",
            "    num_agent_steps_trained: 90000\n",
            "    num_steps_sampled: 90000\n",
            "    num_steps_trained: 90000\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.05555555555556\n",
            "    ram_util_percent: 23.100000000000005\n",
            "  pid: 994\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046381852346431336\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06036420450540017\n",
            "    mean_inference_ms: 0.7180072319937739\n",
            "    mean_raw_obs_processing_ms: 0.13165046550667664\n",
            "  time_since_restore: 114.16509056091309\n",
            "  time_this_iter_s: 12.531250476837158\n",
            "  time_total_s: 114.16509056091309\n",
            "  timers:\n",
            "    learn_throughput: 3345.343\n",
            "    learn_time_ms: 2989.23\n",
            "    load_throughput: 1736971.632\n",
            "    load_time_ms: 5.757\n",
            "    sample_throughput: 1033.217\n",
            "    sample_time_ms: 9678.508\n",
            "    update_time_ms: 2.756\n",
            "  timestamp: 1624604936\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 90000\n",
            "  training_iteration: 9\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 2 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (4 PAUSED, 3 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc           </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:994</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         114.165</td><td style=\"text-align: right;\"> 90000</td><td style=\"text-align: right;\"> -191.17</td><td style=\"text-align: right;\">                 -79</td><td style=\"text-align: right;\">                -345</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>              </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>              </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 100000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-09-08\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -53.0\n",
            "  episode_reward_mean: -159.6\n",
            "  episode_reward_min: -303.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 333\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.3191593885421753\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005901410710066557\n",
            "          model: {}\n",
            "          policy_loss: -0.014780621975660324\n",
            "          total_loss: 51.30914306640625\n",
            "          vf_explained_var: 0.6594942808151245\n",
            "          vf_loss: 51.32126235961914\n",
            "    num_agent_steps_sampled: 100000\n",
            "    num_agent_steps_trained: 100000\n",
            "    num_steps_sampled: 100000\n",
            "    num_steps_trained: 100000\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.16111111111112\n",
            "    ram_util_percent: 23.100000000000005\n",
            "  pid: 994\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046355404341279785\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0604099062781413\n",
            "    mean_inference_ms: 0.7174192613421081\n",
            "    mean_raw_obs_processing_ms: 0.13156749763886266\n",
            "  time_since_restore: 126.70410251617432\n",
            "  time_this_iter_s: 12.53901195526123\n",
            "  time_total_s: 126.70410251617432\n",
            "  timers:\n",
            "    learn_throughput: 3347.533\n",
            "    learn_time_ms: 2987.275\n",
            "    load_throughput: 1830662.465\n",
            "    load_time_ms: 5.463\n",
            "    sample_throughput: 1034.507\n",
            "    sample_time_ms: 9666.442\n",
            "    update_time_ms: 2.729\n",
            "  timestamp: 1624604948\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 100000\n",
            "  training_iteration: 10\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 1 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (5 PAUSED, 3 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m 2021-06-25 07:09:13,489\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m 2021-06-25 07:09:13,489\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=1089)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1089)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1089)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1089)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1089)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1089)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1089)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1089)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1089)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1089)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1088)\u001b[0m 2021-06-25 07:09:21,300\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 20000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-09-42\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1032.0\n",
            "  episode_reward_mean: -1373.6060606060605\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 66\n",
            "  experiment_id: 49cd2efcff114fd2b183aa8151c33e02\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.665286660194397\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.028585556894540787\n",
            "          model: {}\n",
            "          policy_loss: -0.04261205345392227\n",
            "          total_loss: 1885.9422607421875\n",
            "          vf_explained_var: 0.15075308084487915\n",
            "          vf_loss: 1885.9793701171875\n",
            "    num_agent_steps_sampled: 20000\n",
            "    num_agent_steps_trained: 20000\n",
            "    num_steps_sampled: 20000\n",
            "    num_steps_trained: 20000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.509677419354844\n",
            "    ram_util_percent: 23.10000000000001\n",
            "  pid: 1088\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04744516611754862\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05827053303325435\n",
            "    mean_inference_ms: 0.7218154846003733\n",
            "    mean_raw_obs_processing_ms: 0.13284343259643658\n",
            "  time_since_restore: 21.267178773880005\n",
            "  time_this_iter_s: 21.267178773880005\n",
            "  time_total_s: 21.267178773880005\n",
            "  timers:\n",
            "    learn_throughput: 11388.153\n",
            "    learn_time_ms: 1756.211\n",
            "    load_throughput: 631938.769\n",
            "    load_time_ms: 31.649\n",
            "    sample_throughput: 1028.259\n",
            "    sample_time_ms: 19450.351\n",
            "    update_time_ms: 2.702\n",
            "  timestamp: 1624604982\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 20000\n",
            "  training_iteration: 1\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (5 PAUSED, 2 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:1088</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         21.2672</td><td style=\"text-align: right;\"> 20000</td><td style=\"text-align: right;\">-1373.61</td><td style=\"text-align: right;\">               -1032</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        126.704 </td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 40000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-10-03\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -751.0\n",
            "  episode_reward_mean: -1113.44\n",
            "  episode_reward_min: -1644.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 133\n",
            "  experiment_id: 49cd2efcff114fd2b183aa8151c33e02\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.30000001192092896\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6048493385314941\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.02298310399055481\n",
            "          model: {}\n",
            "          policy_loss: -0.045292552560567856\n",
            "          total_loss: 940.0050048828125\n",
            "          vf_explained_var: 0.22567039728164673\n",
            "          vf_loss: 940.0432739257812\n",
            "    num_agent_steps_sampled: 40000\n",
            "    num_agent_steps_trained: 40000\n",
            "    num_steps_sampled: 40000\n",
            "    num_steps_trained: 40000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.51379310344826\n",
            "    ram_util_percent: 23.106896551724148\n",
            "  pid: 1088\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04704754214577244\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05814575252299774\n",
            "    mean_inference_ms: 0.7172815550781784\n",
            "    mean_raw_obs_processing_ms: 0.13158588014556244\n",
            "  time_since_restore: 41.91043710708618\n",
            "  time_this_iter_s: 20.643258333206177\n",
            "  time_total_s: 41.91043710708618\n",
            "  timers:\n",
            "    learn_throughput: 12055.567\n",
            "    learn_time_ms: 1658.985\n",
            "    load_throughput: 1106625.42\n",
            "    load_time_ms: 18.073\n",
            "    sample_throughput: 1038.524\n",
            "    sample_time_ms: 19258.098\n",
            "    update_time_ms: 2.647\n",
            "  timestamp: 1624605003\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 40000\n",
            "  training_iteration: 2\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (5 PAUSED, 2 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:1088</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         41.9104</td><td style=\"text-align: right;\"> 40000</td><td style=\"text-align: right;\">-1113.44</td><td style=\"text-align: right;\">                -751</td><td style=\"text-align: right;\">               -1644</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        126.704 </td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 60000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-10-24\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -469.0\n",
            "  episode_reward_mean: -815.05\n",
            "  episode_reward_min: -1323.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 200\n",
            "  experiment_id: 49cd2efcff114fd2b183aa8151c33e02\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.5541078448295593\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.011688734404742718\n",
            "          model: {}\n",
            "          policy_loss: -0.033035848289728165\n",
            "          total_loss: 542.08544921875\n",
            "          vf_explained_var: 0.24967074394226074\n",
            "          vf_loss: 542.1133422851562\n",
            "    num_agent_steps_sampled: 60000\n",
            "    num_agent_steps_trained: 60000\n",
            "    num_steps_sampled: 60000\n",
            "    num_steps_trained: 60000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.480000000000004\n",
            "    ram_util_percent: 23.200000000000006\n",
            "  pid: 1088\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0468434650304873\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05845968874084253\n",
            "    mean_inference_ms: 0.7151873803543332\n",
            "    mean_raw_obs_processing_ms: 0.1307717247682517\n",
            "  time_since_restore: 62.7772581577301\n",
            "  time_this_iter_s: 20.86682105064392\n",
            "  time_total_s: 62.7772581577301\n",
            "  timers:\n",
            "    learn_throughput: 12291.932\n",
            "    learn_time_ms: 1627.083\n",
            "    load_throughput: 1392415.636\n",
            "    load_time_ms: 14.364\n",
            "    sample_throughput: 1038.03\n",
            "    sample_time_ms: 19267.265\n",
            "    update_time_ms: 2.803\n",
            "  timestamp: 1624605024\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 60000\n",
            "  training_iteration: 3\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (5 PAUSED, 2 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:1088</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         62.7773</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\"> -815.05</td><td style=\"text-align: right;\">                -469</td><td style=\"text-align: right;\">               -1323</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        126.704 </td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 80000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-10-45\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -304.0\n",
            "  episode_reward_mean: -594.15\n",
            "  episode_reward_min: -956.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 266\n",
            "  experiment_id: 49cd2efcff114fd2b183aa8151c33e02\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.5061208009719849\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.009503154084086418\n",
            "          model: {}\n",
            "          policy_loss: -0.026360278949141502\n",
            "          total_loss: 311.44281005859375\n",
            "          vf_explained_var: 0.28212249279022217\n",
            "          vf_loss: 311.4648742675781\n",
            "    num_agent_steps_sampled: 80000\n",
            "    num_agent_steps_trained: 80000\n",
            "    num_steps_sampled: 80000\n",
            "    num_steps_trained: 80000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.37666666666667\n",
            "    ram_util_percent: 23.200000000000006\n",
            "  pid: 1088\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046881151380768385\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05904184286871853\n",
            "    mean_inference_ms: 0.7158096704977635\n",
            "    mean_raw_obs_processing_ms: 0.13090483667849948\n",
            "  time_since_restore: 83.78808259963989\n",
            "  time_this_iter_s: 21.01082444190979\n",
            "  time_total_s: 83.78808259963989\n",
            "  timers:\n",
            "    learn_throughput: 12387.62\n",
            "    learn_time_ms: 1614.515\n",
            "    load_throughput: 1670746.234\n",
            "    load_time_ms: 11.971\n",
            "    sample_throughput: 1036.002\n",
            "    sample_time_ms: 19304.982\n",
            "    update_time_ms: 3.007\n",
            "  timestamp: 1624605045\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 80000\n",
            "  training_iteration: 4\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (5 PAUSED, 2 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:1088</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         83.7881</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -594.15</td><td style=\"text-align: right;\">                -304</td><td style=\"text-align: right;\">                -956</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        126.704 </td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 100000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-11-05\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -177.0\n",
            "  episode_reward_mean: -406.25\n",
            "  episode_reward_min: -758.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 333\n",
            "  experiment_id: 49cd2efcff114fd2b183aa8151c33e02\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.45912986993789673\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.008163008838891983\n",
            "          model: {}\n",
            "          policy_loss: -0.021989993751049042\n",
            "          total_loss: 208.7262420654297\n",
            "          vf_explained_var: 0.32460838556289673\n",
            "          vf_loss: 208.74456787109375\n",
            "    num_agent_steps_sampled: 100000\n",
            "    num_agent_steps_trained: 100000\n",
            "    num_steps_sampled: 100000\n",
            "    num_steps_trained: 100000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.64000000000001\n",
            "    ram_util_percent: 23.200000000000006\n",
            "  pid: 1088\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046861868565912186\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05939896502879954\n",
            "    mean_inference_ms: 0.7154356627403079\n",
            "    mean_raw_obs_processing_ms: 0.13086095523603591\n",
            "  time_since_restore: 104.54567074775696\n",
            "  time_this_iter_s: 20.757588148117065\n",
            "  time_total_s: 104.54567074775696\n",
            "  timers:\n",
            "    learn_throughput: 12486.323\n",
            "    learn_time_ms: 1601.753\n",
            "    load_throughput: 1935106.206\n",
            "    load_time_ms: 10.335\n",
            "    sample_throughput: 1037.206\n",
            "    sample_time_ms: 19282.572\n",
            "    update_time_ms: 2.958\n",
            "  timestamp: 1624605065\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 100000\n",
            "  training_iteration: 5\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 1 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (5 PAUSED, 2 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:1088</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         104.546</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -406.25</td><td style=\"text-align: right;\">                -177</td><td style=\"text-align: right;\">                -758</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-25 07:11:26,787\tINFO pbt.py:543 -- [exploit] transferring weights from trial PPO_WasteNetEnv_8c324_00004 (score -159.6) -> PPO_WasteNetEnv_8c324_00005 (score -307.72)\n",
            "2021-06-25 07:11:26,788\tINFO pbt.py:558 -- [explore] perturbed config from {'lambda': 0.9, 'clip_param': 0.3, 'lr': 5e-05, 'num_sgd_iter': 10, 'sgd_minibatch_size': 128, 'train_batch_size': 10000} -> {'lambda': 0.972751454205281, 'clip_param': 0.36, 'lr': 1e-05, 'num_sgd_iter': 12, 'sgd_minibatch_size': 153, 'train_batch_size': 12000}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 120000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-11-26\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -152.0\n",
            "  episode_reward_mean: -307.72\n",
            "  episode_reward_min: -492.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 400\n",
            "  experiment_id: 49cd2efcff114fd2b183aa8151c33e02\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.4213167428970337\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005602619145065546\n",
            "          model: {}\n",
            "          policy_loss: -0.017071641981601715\n",
            "          total_loss: 167.0237579345703\n",
            "          vf_explained_var: 0.3529297113418579\n",
            "          vf_loss: 167.03831481933594\n",
            "    num_agent_steps_sampled: 120000\n",
            "    num_agent_steps_trained: 120000\n",
            "    num_steps_sampled: 120000\n",
            "    num_steps_trained: 120000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.52666666666668\n",
            "    ram_util_percent: 23.106666666666676\n",
            "  pid: 1088\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046809677376451135\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05957655935276875\n",
            "    mean_inference_ms: 0.7148200307718404\n",
            "    mean_raw_obs_processing_ms: 0.13062385961697956\n",
            "  time_since_restore: 125.32999873161316\n",
            "  time_this_iter_s: 20.7843279838562\n",
            "  time_total_s: 125.32999873161316\n",
            "  timers:\n",
            "    learn_throughput: 12543.348\n",
            "    learn_time_ms: 1594.471\n",
            "    load_throughput: 2138414.49\n",
            "    load_time_ms: 9.353\n",
            "    sample_throughput: 1037.848\n",
            "    sample_time_ms: 19270.645\n",
            "    update_time_ms: 2.988\n",
            "  timestamp: 1624605086\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 120000\n",
            "  training_iteration: 6\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 2 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 2 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m 2021-06-25 07:11:31,522\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m 2021-06-25 07:11:31,522\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=1166)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1166)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1166)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1166)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1166)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1166)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1166)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1166)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1166)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1166)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m 2021-06-25 07:11:39,372\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m 2021-06-25 07:11:39,443\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00005_5_num_sgd_iter=10,sgd_minibatch_size=512,train_batch_size=20000_2021-06-25_07-06-36/tmpzjpzl31erestore_from_object/checkpoint-10\n",
            "\u001b[2m\u001b[36m(pid=1165)\u001b[0m 2021-06-25 07:11:39,444\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 10, '_timesteps_total': None, '_time_total': 126.70410251617432, '_episodes_total': 333}\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m 2021-06-25 07:11:44,382\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m 2021-06-25 07:11:44,382\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=1255)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1255)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1255)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1255)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1255)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1255)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1255)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1255)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1255)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1255)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1254)\u001b[0m 2021-06-25 07:11:52,285\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 20000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-12-29\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1032.0\n",
            "  episode_reward_mean: -1373.6060606060605\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 66\n",
            "  experiment_id: 1b2163214974428da8e226cb6893ea49\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6679884791374207\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.025824937969446182\n",
            "          model: {}\n",
            "          policy_loss: -0.05307336896657944\n",
            "          total_loss: 1433.4151611328125\n",
            "          vf_explained_var: 0.11215400695800781\n",
            "          vf_loss: 1433.462890625\n",
            "    num_agent_steps_sampled: 20000\n",
            "    num_agent_steps_trained: 20000\n",
            "    num_steps_sampled: 20000\n",
            "    num_steps_trained: 20000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.474074074074075\n",
            "    ram_util_percent: 23.170370370370375\n",
            "  pid: 1254\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.045083974648771216\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.057305582081888344\n",
            "    mean_inference_ms: 0.7018243710426477\n",
            "    mean_raw_obs_processing_ms: 0.12816274698350047\n",
            "  time_since_restore: 37.21918320655823\n",
            "  time_this_iter_s: 37.21918320655823\n",
            "  time_total_s: 37.21918320655823\n",
            "  timers:\n",
            "    learn_throughput: 1095.468\n",
            "    learn_time_ms: 18257.035\n",
            "    load_throughput: 437492.268\n",
            "    load_time_ms: 45.715\n",
            "    sample_throughput: 1058.981\n",
            "    sample_time_ms: 18886.073\n",
            "    update_time_ms: 2.83\n",
            "  timestamp: 1624605149\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 20000\n",
            "  training_iteration: 1\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 2 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1254</td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         37.2192</td><td style=\"text-align: right;\"> 20000</td><td style=\"text-align: right;\">-1373.61</td><td style=\"text-align: right;\">               -1032</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        126.704 </td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        125.33  </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 40000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-13-06\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -700.0\n",
            "  episode_reward_mean: -1060.34\n",
            "  episode_reward_min: -1644.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 133\n",
            "  experiment_id: 1b2163214974428da8e226cb6893ea49\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.30000001192092896\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6020565629005432\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.030081061646342278\n",
            "          model: {}\n",
            "          policy_loss: -0.05843007192015648\n",
            "          total_loss: 662.431396484375\n",
            "          vf_explained_var: 0.1851769983768463\n",
            "          vf_loss: 662.4807739257812\n",
            "    num_agent_steps_sampled: 40000\n",
            "    num_agent_steps_trained: 40000\n",
            "    num_steps_sampled: 40000\n",
            "    num_steps_trained: 40000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.53461538461537\n",
            "    ram_util_percent: 23.200000000000003\n",
            "  pid: 1254\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04519027564883633\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05783756580260868\n",
            "    mean_inference_ms: 0.7033881097260997\n",
            "    mean_raw_obs_processing_ms: 0.12865741305968406\n",
            "  time_since_restore: 74.22427725791931\n",
            "  time_this_iter_s: 37.005094051361084\n",
            "  time_total_s: 74.22427725791931\n",
            "  timers:\n",
            "    learn_throughput: 1104.999\n",
            "    learn_time_ms: 18099.56\n",
            "    load_throughput: 797745.022\n",
            "    load_time_ms: 25.071\n",
            "    sample_throughput: 1054.521\n",
            "    sample_time_ms: 18965.949\n",
            "    update_time_ms: 2.835\n",
            "  timestamp: 1624605186\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 40000\n",
            "  training_iteration: 2\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 2 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1254</td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         74.2243</td><td style=\"text-align: right;\"> 40000</td><td style=\"text-align: right;\">-1060.34</td><td style=\"text-align: right;\">                -700</td><td style=\"text-align: right;\">               -1644</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        126.704 </td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        125.33  </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 60000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-13-43\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -354.0\n",
            "  episode_reward_mean: -693.0\n",
            "  episode_reward_min: -1151.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 200\n",
            "  experiment_id: 1b2163214974428da8e226cb6893ea49\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.5362263917922974\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.016204049810767174\n",
            "          model: {}\n",
            "          policy_loss: -0.04064571484923363\n",
            "          total_loss: 274.5264892578125\n",
            "          vf_explained_var: 0.3391059339046478\n",
            "          vf_loss: 274.5598449707031\n",
            "    num_agent_steps_sampled: 60000\n",
            "    num_agent_steps_trained: 60000\n",
            "    num_steps_sampled: 60000\n",
            "    num_steps_trained: 60000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.77547169811321\n",
            "    ram_util_percent: 23.200000000000003\n",
            "  pid: 1254\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04526222437956932\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05832905986619382\n",
            "    mean_inference_ms: 0.7040110889814741\n",
            "    mean_raw_obs_processing_ms: 0.12885998817186248\n",
            "  time_since_restore: 111.2984402179718\n",
            "  time_this_iter_s: 37.07416296005249\n",
            "  time_total_s: 111.2984402179718\n",
            "  timers:\n",
            "    learn_throughput: 1105.121\n",
            "    learn_time_ms: 18097.572\n",
            "    load_throughput: 1096607.404\n",
            "    load_time_ms: 18.238\n",
            "    sample_throughput: 1054.528\n",
            "    sample_time_ms: 18965.837\n",
            "    update_time_ms: 2.723\n",
            "  timestamp: 1624605223\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 60000\n",
            "  training_iteration: 3\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 2 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1254</td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">         111.298</td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\"> -693   </td><td style=\"text-align: right;\">                -354</td><td style=\"text-align: right;\">               -1151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-25 07:14:20,716\tINFO pbt.py:543 -- [exploit] transferring weights from trial PPO_WasteNetEnv_8c324_00002 (score -236.79) -> PPO_WasteNetEnv_8c324_00006 (score -450.23)\n",
            "2021-06-25 07:14:20,719\tINFO pbt.py:558 -- [explore] perturbed config from {'lambda': 0.9, 'clip_param': 0.3, 'lr': 5e-05, 'num_sgd_iter': 20, 'sgd_minibatch_size': 2048, 'train_batch_size': 10000} -> {'lambda': 1.08, 'clip_param': 0.24, 'lr': 0.0001, 'num_sgd_iter': 16, 'sgd_minibatch_size': 1638, 'train_batch_size': 8000}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 80000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-14-20\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -130.0\n",
            "  episode_reward_mean: -450.23\n",
            "  episode_reward_min: -880.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 266\n",
            "  experiment_id: 1b2163214974428da8e226cb6893ea49\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.47291505336761475\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.011693961918354034\n",
            "          model: {}\n",
            "          policy_loss: -0.03296218812465668\n",
            "          total_loss: 145.34429931640625\n",
            "          vf_explained_var: 0.46804770827293396\n",
            "          vf_loss: 145.37200927734375\n",
            "    num_agent_steps_sampled: 80000\n",
            "    num_agent_steps_trained: 80000\n",
            "    num_steps_sampled: 80000\n",
            "    num_steps_trained: 80000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.46792452830189\n",
            "    ram_util_percent: 23.200000000000003\n",
            "  pid: 1254\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.045244169668390254\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.058668423313178925\n",
            "    mean_inference_ms: 0.7046952690287729\n",
            "    mean_raw_obs_processing_ms: 0.1288233739069695\n",
            "  time_since_restore: 148.33546781539917\n",
            "  time_this_iter_s: 37.03702759742737\n",
            "  time_total_s: 148.33546781539917\n",
            "  timers:\n",
            "    learn_throughput: 1107.492\n",
            "    learn_time_ms: 18058.825\n",
            "    load_throughput: 1340488.265\n",
            "    load_time_ms: 14.92\n",
            "    sample_throughput: 1052.969\n",
            "    sample_time_ms: 18993.917\n",
            "    update_time_ms: 2.598\n",
            "  timestamp: 1624605260\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 80000\n",
            "  training_iteration: 4\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.8/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 2021-06-25 07:14:25,082\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 2021-06-25 07:14:25,082\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1330)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1330)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1330)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1330)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1330)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1330)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1330)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1330)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1330)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1330)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 2021-06-25 07:14:33,015\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 2021-06-25 07:14:33,093\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00006_6_num_sgd_iter=30,sgd_minibatch_size=128,train_batch_size=20000_2021-06-25_07-09-08/tmpcwi1l83orestore_from_object/checkpoint-12\n",
            "\u001b[2m\u001b[36m(pid=1331)\u001b[0m 2021-06-25 07:14:33,094\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 12, '_timesteps_total': None, '_time_total': 121.74419379234314, '_episodes_total': 400}\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m 2021-06-25 07:14:37,753\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m 2021-06-25 07:14:37,753\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1451)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1451)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1451)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1451)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1451)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1451)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1451)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1451)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1451)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1451)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1423)\u001b[0m 2021-06-25 07:14:46,007\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 20000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-15-10\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1032.0\n",
            "  episode_reward_mean: -1373.6060606060605\n",
            "  episode_reward_min: -1726.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 66\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6663699746131897\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.027503179386258125\n",
            "          model: {}\n",
            "          policy_loss: -0.046776168048381805\n",
            "          total_loss: 1480.823486328125\n",
            "          vf_explained_var: 0.16069796681404114\n",
            "          vf_loss: 1480.864990234375\n",
            "    num_agent_steps_sampled: 20000\n",
            "    num_agent_steps_trained: 20000\n",
            "    num_steps_sampled: 20000\n",
            "    num_steps_trained: 20000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.56666666666667\n",
            "    ram_util_percent: 23.200000000000003\n",
            "  pid: 1423\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.045997429761843206\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05586753695686186\n",
            "    mean_inference_ms: 0.7019187323981886\n",
            "    mean_raw_obs_processing_ms: 0.12823728482536442\n",
            "  time_since_restore: 24.94292640686035\n",
            "  time_this_iter_s: 24.94292640686035\n",
            "  time_total_s: 24.94292640686035\n",
            "  timers:\n",
            "    learn_throughput: 3333.252\n",
            "    learn_time_ms: 6000.147\n",
            "    load_throughput: 674601.967\n",
            "    load_time_ms: 29.647\n",
            "    sample_throughput: 1059.283\n",
            "    sample_time_ms: 18880.687\n",
            "    update_time_ms: 3.093\n",
            "  timestamp: 1624605310\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 20000\n",
            "  training_iteration: 1\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         24.9429</td><td style=\"text-align: right;\"> 20000</td><td style=\"text-align: right;\">-1373.61</td><td style=\"text-align: right;\">               -1032</td><td style=\"text-align: right;\">               -1726</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        126.704 </td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        125.33  </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        148.335 </td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 40000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-15-35\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -725.0\n",
            "  episode_reward_mean: -1079.71\n",
            "  episode_reward_min: -1644.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 133\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.30000001192092896\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6088528037071228\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.026200085878372192\n",
            "          model: {}\n",
            "          policy_loss: -0.05122913047671318\n",
            "          total_loss: 723.8287963867188\n",
            "          vf_explained_var: 0.15237842500209808\n",
            "          vf_loss: 723.8721923828125\n",
            "    num_agent_steps_sampled: 40000\n",
            "    num_agent_steps_trained: 40000\n",
            "    num_steps_sampled: 40000\n",
            "    num_steps_trained: 40000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.854285714285716\n",
            "    ram_util_percent: 23.222857142857134\n",
            "  pid: 1423\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046089597405433926\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05634537388670324\n",
            "    mean_inference_ms: 0.7019963405964382\n",
            "    mean_raw_obs_processing_ms: 0.1280551128512397\n",
            "  time_since_restore: 49.69841384887695\n",
            "  time_this_iter_s: 24.7554874420166\n",
            "  time_total_s: 49.69841384887695\n",
            "  timers:\n",
            "    learn_throughput: 3379.312\n",
            "    learn_time_ms: 5918.365\n",
            "    load_throughput: 1175830.226\n",
            "    load_time_ms: 17.009\n",
            "    sample_throughput: 1058.695\n",
            "    sample_time_ms: 18891.18\n",
            "    update_time_ms: 2.961\n",
            "  timestamp: 1624605335\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 40000\n",
            "  training_iteration: 2\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         49.6984</td><td style=\"text-align: right;\"> 40000</td><td style=\"text-align: right;\">-1079.71</td><td style=\"text-align: right;\">                -725</td><td style=\"text-align: right;\">               -1644</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.451 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        135.228 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">        129.506 </td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">        126.704 </td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">        125.33  </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        148.335 </td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">        121.744 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 60000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-16-00\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -424.0\n",
            "  episode_reward_mean: -741.04\n",
            "  episode_reward_min: -1225.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 200\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.551002025604248\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.013578479178249836\n",
            "          model: {}\n",
            "          policy_loss: -0.0327347069978714\n",
            "          total_loss: 397.4873046875\n",
            "          vf_explained_var: 0.16420698165893555\n",
            "          vf_loss: 397.513916015625\n",
            "    num_agent_steps_sampled: 60000\n",
            "    num_agent_steps_trained: 60000\n",
            "    num_steps_sampled: 60000\n",
            "    num_steps_trained: 60000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.830555555555534\n",
            "    ram_util_percent: 23.261111111111106\n",
            "  pid: 1423\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04628823586255807\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05714426709137517\n",
            "    mean_inference_ms: 0.7038593361767812\n",
            "    mean_raw_obs_processing_ms: 0.12835728001912924\n",
            "  time_since_restore: 74.71002960205078\n",
            "  time_this_iter_s: 25.011615753173828\n",
            "  time_total_s: 74.71002960205078\n",
            "  timers:\n",
            "    learn_throughput: 3394.739\n",
            "    learn_time_ms: 5891.469\n",
            "    load_throughput: 1541995.184\n",
            "    load_time_ms: 12.97\n",
            "    sample_throughput: 1053.731\n",
            "    sample_time_ms: 18980.177\n",
            "    update_time_ms: 2.856\n",
            "  timestamp: 1624605360\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 60000\n",
            "  training_iteration: 3\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">          74.71 </td><td style=\"text-align: right;\"> 60000</td><td style=\"text-align: right;\"> -741.04</td><td style=\"text-align: right;\">                -424</td><td style=\"text-align: right;\">               -1225</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 80000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-16-25\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -226.0\n",
            "  episode_reward_mean: -511.14\n",
            "  episode_reward_min: -986.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 266\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.4982525706291199\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.010778131894767284\n",
            "          model: {}\n",
            "          policy_loss: -0.025807080790400505\n",
            "          total_loss: 262.82080078125\n",
            "          vf_explained_var: 0.18554630875587463\n",
            "          vf_loss: 262.84173583984375\n",
            "    num_agent_steps_sampled: 80000\n",
            "    num_agent_steps_trained: 80000\n",
            "    num_steps_sampled: 80000\n",
            "    num_steps_trained: 80000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.858333333333334\n",
            "    ram_util_percent: 23.299999999999997\n",
            "  pid: 1423\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04647332613928498\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.057851355268872806\n",
            "    mean_inference_ms: 0.7063802797092916\n",
            "    mean_raw_obs_processing_ms: 0.12879238410382324\n",
            "  time_since_restore: 99.83700823783875\n",
            "  time_this_iter_s: 25.126978635787964\n",
            "  time_total_s: 99.83700823783875\n",
            "  timers:\n",
            "    learn_throughput: 3403.348\n",
            "    learn_time_ms: 5876.566\n",
            "    load_throughput: 1866977.065\n",
            "    load_time_ms: 10.713\n",
            "    sample_throughput: 1049.571\n",
            "    sample_time_ms: 19055.397\n",
            "    update_time_ms: 2.733\n",
            "  timestamp: 1624605385\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 80000\n",
            "  training_iteration: 4\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:1423</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">          99.837</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -511.14</td><td style=\"text-align: right;\">                -226</td><td style=\"text-align: right;\">                -986</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 100000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-16-51\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -164.0\n",
            "  episode_reward_mean: -344.32\n",
            "  episode_reward_min: -651.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 333\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.44999998807907104\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.44437769055366516\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.010217576287686825\n",
            "          model: {}\n",
            "          policy_loss: -0.021472444757819176\n",
            "          total_loss: 185.7744140625\n",
            "          vf_explained_var: 0.29356545209884644\n",
            "          vf_loss: 185.7913055419922\n",
            "    num_agent_steps_sampled: 100000\n",
            "    num_agent_steps_trained: 100000\n",
            "    num_steps_sampled: 100000\n",
            "    num_steps_trained: 100000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.65277777777779\n",
            "    ram_util_percent: 23.200000000000003\n",
            "  pid: 1423\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04661887169616673\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05831588501471327\n",
            "    mean_inference_ms: 0.7085697209720486\n",
            "    mean_raw_obs_processing_ms: 0.12911158524768251\n",
            "  time_since_restore: 125.01652479171753\n",
            "  time_this_iter_s: 25.179516553878784\n",
            "  time_total_s: 125.01652479171753\n",
            "  timers:\n",
            "    learn_throughput: 3408.182\n",
            "    learn_time_ms: 5868.231\n",
            "    load_throughput: 2107499.824\n",
            "    load_time_ms: 9.49\n",
            "    sample_throughput: 1046.565\n",
            "    sample_time_ms: 19110.136\n",
            "    update_time_ms: 2.721\n",
            "  timestamp: 1624605411\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 100000\n",
            "  training_iteration: 5\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m 2021-06-25 07:16:55,825\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m 2021-06-25 07:16:55,825\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1513)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1513)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1513)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1513)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1513)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1513)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1513)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1513)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1513)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1513)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         121.744</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -236.79</td><td style=\"text-align: right;\">                 -95</td><td style=\"text-align: right;\">                -460</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m 2021-06-25 07:17:03,945\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m 2021-06-25 07:17:04,017\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00002_2_num_sgd_iter=20,sgd_minibatch_size=2048,train_batch_size=10000_2021-06-25_06-59-31/tmpe5kkahysrestore_from_object/checkpoint-12\n",
            "\u001b[2m\u001b[36m(pid=1512)\u001b[0m 2021-06-25 07:17:04,017\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 12, '_timesteps_total': None, '_time_total': 121.74419379234314, '_episodes_total': 400}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 130000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-17-14\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -84.0\n",
            "  episode_reward_mean: -190.96969696969697\n",
            "  episode_reward_min: -284.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 433\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.22841772437095642\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0020630108192563057\n",
            "          model: {}\n",
            "          policy_loss: -0.005116707645356655\n",
            "          total_loss: 83.31045532226562\n",
            "          vf_explained_var: 0.5816450715065002\n",
            "          vf_loss: 83.3151626586914\n",
            "    num_agent_steps_sampled: 130000\n",
            "    num_agent_steps_trained: 130000\n",
            "    num_steps_sampled: 130000\n",
            "    num_steps_trained: 130000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.46666666666666\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04617153030790671\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060250384606619904\n",
            "    mean_inference_ms: 0.7111428320592623\n",
            "    mean_raw_obs_processing_ms: 0.1271740339622654\n",
            "  time_since_restore: 10.217063188552856\n",
            "  time_this_iter_s: 10.217063188552856\n",
            "  time_total_s: 131.961256980896\n",
            "  timers:\n",
            "    learn_throughput: 17811.622\n",
            "    learn_time_ms: 561.431\n",
            "    load_throughput: 370067.144\n",
            "    load_time_ms: 27.022\n",
            "    sample_throughput: 1041.915\n",
            "    sample_time_ms: 9597.713\n",
            "    update_time_ms: 2.121\n",
            "  timestamp: 1624605434\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 130000\n",
            "  training_iteration: 13\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         131.961</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -190.97</td><td style=\"text-align: right;\">                 -84</td><td style=\"text-align: right;\">                -284</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 140000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-17-24\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -84.0\n",
            "  episode_reward_mean: -182.0\n",
            "  episode_reward_min: -284.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 466\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.21455983817577362\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00410229479894042\n",
            "          model: {}\n",
            "          policy_loss: -0.009061901830136776\n",
            "          total_loss: 71.266357421875\n",
            "          vf_explained_var: 0.6140012741088867\n",
            "          vf_loss: 71.2750015258789\n",
            "    num_agent_steps_sampled: 140000\n",
            "    num_agent_steps_trained: 140000\n",
            "    num_steps_sampled: 140000\n",
            "    num_steps_trained: 140000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.03999999999999\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046506418099730135\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06078502172143072\n",
            "    mean_inference_ms: 0.7143412346969772\n",
            "    mean_raw_obs_processing_ms: 0.12806528391823446\n",
            "  time_since_restore: 20.39186716079712\n",
            "  time_this_iter_s: 10.174803972244263\n",
            "  time_total_s: 142.13606095314026\n",
            "  timers:\n",
            "    learn_throughput: 20964.078\n",
            "    learn_time_ms: 477.006\n",
            "    load_throughput: 666942.923\n",
            "    load_time_ms: 14.994\n",
            "    sample_throughput: 1032.757\n",
            "    sample_time_ms: 9682.818\n",
            "    update_time_ms: 2.988\n",
            "  timestamp: 1624605444\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 140000\n",
            "  training_iteration: 14\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         142.136</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\"> -182   </td><td style=\"text-align: right;\">                 -84</td><td style=\"text-align: right;\">                -284</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 150000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-17-34\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -63.0\n",
            "  episode_reward_mean: -170.85\n",
            "  episode_reward_min: -284.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 500\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.2031804472208023\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0032109154853969812\n",
            "          model: {}\n",
            "          policy_loss: -0.004656615667045116\n",
            "          total_loss: 60.6142578125\n",
            "          vf_explained_var: 0.6377132534980774\n",
            "          vf_loss: 60.618751525878906\n",
            "    num_agent_steps_sampled: 150000\n",
            "    num_agent_steps_trained: 150000\n",
            "    num_steps_sampled: 150000\n",
            "    num_steps_trained: 150000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.02142857142858\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046661258916750124\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061050254879121864\n",
            "    mean_inference_ms: 0.7154630103154913\n",
            "    mean_raw_obs_processing_ms: 0.1285635570394979\n",
            "  time_since_restore: 30.47928524017334\n",
            "  time_this_iter_s: 10.08741807937622\n",
            "  time_total_s: 152.22347903251648\n",
            "  timers:\n",
            "    learn_throughput: 22546.013\n",
            "    learn_time_ms: 443.537\n",
            "    load_throughput: 917804.198\n",
            "    load_time_ms: 10.896\n",
            "    sample_throughput: 1032.215\n",
            "    sample_time_ms: 9687.909\n",
            "    update_time_ms: 3.078\n",
            "  timestamp: 1624605454\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 150000\n",
            "  training_iteration: 15\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         152.223</td><td style=\"text-align: right;\">150000</td><td style=\"text-align: right;\"> -170.85</td><td style=\"text-align: right;\">                 -63</td><td style=\"text-align: right;\">                -284</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 160000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-17-44\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -63.0\n",
            "  episode_reward_mean: -153.08\n",
            "  episode_reward_min: -278.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 533\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.19741661846637726\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0021626686211675406\n",
            "          model: {}\n",
            "          policy_loss: -0.004663567058742046\n",
            "          total_loss: 52.2779655456543\n",
            "          vf_explained_var: 0.6712217926979065\n",
            "          vf_loss: 52.28257751464844\n",
            "    num_agent_steps_sampled: 160000\n",
            "    num_agent_steps_trained: 160000\n",
            "    num_steps_sampled: 160000\n",
            "    num_steps_trained: 160000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.94285714285714\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04684445434370654\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06137632062045837\n",
            "    mean_inference_ms: 0.7169251915790579\n",
            "    mean_raw_obs_processing_ms: 0.12930094588673424\n",
            "  time_since_restore: 40.428903579711914\n",
            "  time_this_iter_s: 9.949618339538574\n",
            "  time_total_s: 162.17309737205505\n",
            "  timers:\n",
            "    learn_throughput: 23526.567\n",
            "    learn_time_ms: 425.051\n",
            "    load_throughput: 1108768.257\n",
            "    load_time_ms: 9.019\n",
            "    sample_throughput: 1035.442\n",
            "    sample_time_ms: 9657.713\n",
            "    update_time_ms: 3.161\n",
            "  timestamp: 1624605464\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 160000\n",
            "  training_iteration: 16\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         162.173</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\"> -153.08</td><td style=\"text-align: right;\">                 -63</td><td style=\"text-align: right;\">                -278</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 170000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-17-54\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -58.0\n",
            "  episode_reward_mean: -141.71\n",
            "  episode_reward_min: -259.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 566\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.18856289982795715\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.002975242445245385\n",
            "          model: {}\n",
            "          policy_loss: -0.006895768456161022\n",
            "          total_loss: 54.15354919433594\n",
            "          vf_explained_var: 0.6618754863739014\n",
            "          vf_loss: 54.16040802001953\n",
            "    num_agent_steps_sampled: 170000\n",
            "    num_agent_steps_trained: 170000\n",
            "    num_steps_sampled: 170000\n",
            "    num_steps_trained: 170000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.0\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04677620353150793\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061295373913657004\n",
            "    mean_inference_ms: 0.7158679279247013\n",
            "    mean_raw_obs_processing_ms: 0.12940178378066666\n",
            "  time_since_restore: 50.38284134864807\n",
            "  time_this_iter_s: 9.953937768936157\n",
            "  time_total_s: 172.1270351409912\n",
            "  timers:\n",
            "    learn_throughput: 24173.431\n",
            "    learn_time_ms: 413.677\n",
            "    load_throughput: 1277613.832\n",
            "    load_time_ms: 7.827\n",
            "    sample_throughput: 1037.252\n",
            "    sample_time_ms: 9640.859\n",
            "    update_time_ms: 3.052\n",
            "  timestamp: 1624605474\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 170000\n",
            "  training_iteration: 17\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         172.127</td><td style=\"text-align: right;\">170000</td><td style=\"text-align: right;\"> -141.71</td><td style=\"text-align: right;\">                 -58</td><td style=\"text-align: right;\">                -259</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 180000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-18-04\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -49.0\n",
            "  episode_reward_mean: -134.46\n",
            "  episode_reward_min: -258.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 600\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.17559663951396942\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0024773222394287586\n",
            "          model: {}\n",
            "          policy_loss: -0.008409330621361732\n",
            "          total_loss: 50.07133483886719\n",
            "          vf_explained_var: 0.6779707074165344\n",
            "          vf_loss: 50.07973098754883\n",
            "    num_agent_steps_sampled: 180000\n",
            "    num_agent_steps_trained: 180000\n",
            "    num_steps_sampled: 180000\n",
            "    num_steps_trained: 180000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.92142857142857\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04667044460278541\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061091662603381475\n",
            "    mean_inference_ms: 0.7146258982990438\n",
            "    mean_raw_obs_processing_ms: 0.12927482919179314\n",
            "  time_since_restore: 60.38249945640564\n",
            "  time_this_iter_s: 9.999658107757568\n",
            "  time_total_s: 182.12669324874878\n",
            "  timers:\n",
            "    learn_throughput: 24462.224\n",
            "    learn_time_ms: 408.794\n",
            "    load_throughput: 1430095.753\n",
            "    load_time_ms: 6.993\n",
            "    sample_throughput: 1037.986\n",
            "    sample_time_ms: 9634.039\n",
            "    update_time_ms: 3.337\n",
            "  timestamp: 1624605484\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 180000\n",
            "  training_iteration: 18\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         182.127</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\"> -134.46</td><td style=\"text-align: right;\">                 -49</td><td style=\"text-align: right;\">                -258</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 190000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-18-14\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -49.0\n",
            "  episode_reward_mean: -126.43\n",
            "  episode_reward_min: -258.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 633\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0031250000465661287\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.16974413394927979\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0018804057035595179\n",
            "          model: {}\n",
            "          policy_loss: -0.013743339106440544\n",
            "          total_loss: 41.23089599609375\n",
            "          vf_explained_var: 0.7143781185150146\n",
            "          vf_loss: 41.24463653564453\n",
            "    num_agent_steps_sampled: 190000\n",
            "    num_agent_steps_trained: 190000\n",
            "    num_steps_sampled: 190000\n",
            "    num_steps_trained: 190000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.03571428571429\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04663454708239002\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06098354481700538\n",
            "    mean_inference_ms: 0.7140396208450883\n",
            "    mean_raw_obs_processing_ms: 0.12916785721749238\n",
            "  time_since_restore: 70.38232588768005\n",
            "  time_this_iter_s: 9.999826431274414\n",
            "  time_total_s: 192.1265196800232\n",
            "  timers:\n",
            "    learn_throughput: 24646.171\n",
            "    learn_time_ms: 405.743\n",
            "    load_throughput: 1580200.646\n",
            "    load_time_ms: 6.328\n",
            "    sample_throughput: 1038.486\n",
            "    sample_time_ms: 9629.406\n",
            "    update_time_ms: 3.206\n",
            "  timestamp: 1624605494\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 190000\n",
            "  training_iteration: 19\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         192.127</td><td style=\"text-align: right;\">190000</td><td style=\"text-align: right;\"> -126.43</td><td style=\"text-align: right;\">                 -49</td><td style=\"text-align: right;\">                -258</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 200000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-18-24\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -49.0\n",
            "  episode_reward_mean: -115.65\n",
            "  episode_reward_min: -256.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 666\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0015625000232830644\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.16137608885765076\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.002574753947556019\n",
            "          model: {}\n",
            "          policy_loss: -0.0077271610498428345\n",
            "          total_loss: 37.5389404296875\n",
            "          vf_explained_var: 0.7342050075531006\n",
            "          vf_loss: 37.54666519165039\n",
            "    num_agent_steps_sampled: 200000\n",
            "    num_agent_steps_trained: 200000\n",
            "    num_steps_sampled: 200000\n",
            "    num_steps_trained: 200000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.166666666666664\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04666552498930982\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06095450439208268\n",
            "    mean_inference_ms: 0.7144288955891451\n",
            "    mean_raw_obs_processing_ms: 0.12922367698060797\n",
            "  time_since_restore: 80.57975435256958\n",
            "  time_this_iter_s: 10.197428464889526\n",
            "  time_total_s: 202.32394814491272\n",
            "  timers:\n",
            "    learn_throughput: 24854.969\n",
            "    learn_time_ms: 402.334\n",
            "    load_throughput: 1708421.942\n",
            "    load_time_ms: 5.853\n",
            "    sample_throughput: 1036.087\n",
            "    sample_time_ms: 9651.698\n",
            "    update_time_ms: 3.098\n",
            "  timestamp: 1624605504\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 200000\n",
            "  training_iteration: 20\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         202.324</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -115.65</td><td style=\"text-align: right;\">                 -49</td><td style=\"text-align: right;\">                -256</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 210000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-18-34\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -39.0\n",
            "  episode_reward_mean: -100.52\n",
            "  episode_reward_min: -212.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 700\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0007812500116415322\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.1508558690547943\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.002821437083184719\n",
            "          model: {}\n",
            "          policy_loss: -0.006460774689912796\n",
            "          total_loss: 30.92892074584961\n",
            "          vf_explained_var: 0.7613314390182495\n",
            "          vf_loss: 30.93537712097168\n",
            "    num_agent_steps_sampled: 210000\n",
            "    num_agent_steps_trained: 210000\n",
            "    num_steps_sampled: 210000\n",
            "    num_steps_trained: 210000\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.171428571428564\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04671076431529446\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06096664636086201\n",
            "    mean_inference_ms: 0.7149845268697617\n",
            "    mean_raw_obs_processing_ms: 0.12937204762010268\n",
            "  time_since_restore: 90.65281629562378\n",
            "  time_this_iter_s: 10.0730619430542\n",
            "  time_total_s: 212.39701008796692\n",
            "  timers:\n",
            "    learn_throughput: 25005.404\n",
            "    learn_time_ms: 399.914\n",
            "    load_throughput: 1811846.561\n",
            "    load_time_ms: 5.519\n",
            "    sample_throughput: 1035.756\n",
            "    sample_time_ms: 9654.782\n",
            "    update_time_ms: 3.062\n",
            "  timestamp: 1624605514\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 210000\n",
            "  training_iteration: 21\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         212.397</td><td style=\"text-align: right;\">210000</td><td style=\"text-align: right;\"> -100.52</td><td style=\"text-align: right;\">                 -39</td><td style=\"text-align: right;\">                -212</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 220000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-18-45\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -39.0\n",
            "  episode_reward_mean: -95.7\n",
            "  episode_reward_min: -201.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 733\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0003906250058207661\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.14833581447601318\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0017231854144483805\n",
            "          model: {}\n",
            "          policy_loss: -0.0018881261348724365\n",
            "          total_loss: 36.830745697021484\n",
            "          vf_explained_var: 0.7323019504547119\n",
            "          vf_loss: 36.83263397216797\n",
            "    num_agent_steps_sampled: 220000\n",
            "    num_agent_steps_trained: 220000\n",
            "    num_steps_sampled: 220000\n",
            "    num_steps_trained: 220000\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.43999999999999\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04679273684537763\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061025509988950156\n",
            "    mean_inference_ms: 0.71600845885343\n",
            "    mean_raw_obs_processing_ms: 0.1296218733940424\n",
            "  time_since_restore: 100.86522889137268\n",
            "  time_this_iter_s: 10.212412595748901\n",
            "  time_total_s: 222.60942268371582\n",
            "  timers:\n",
            "    learn_throughput: 25152.231\n",
            "    learn_time_ms: 397.579\n",
            "    load_throughput: 1919633.859\n",
            "    load_time_ms: 5.209\n",
            "    sample_throughput: 1033.937\n",
            "    sample_time_ms: 9671.77\n",
            "    update_time_ms: 3.014\n",
            "  timestamp: 1624605525\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 220000\n",
            "  training_iteration: 22\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         222.609</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">  -95.7 </td><td style=\"text-align: right;\">                 -39</td><td style=\"text-align: right;\">                -201</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 230000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-18-55\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -39.0\n",
            "  episode_reward_mean: -88.58\n",
            "  episode_reward_min: -173.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 766\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.00019531250291038305\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.14538441598415375\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0012867687037214637\n",
            "          model: {}\n",
            "          policy_loss: -0.003390165511518717\n",
            "          total_loss: 30.674976348876953\n",
            "          vf_explained_var: 0.7654518485069275\n",
            "          vf_loss: 30.67836570739746\n",
            "    num_agent_steps_sampled: 230000\n",
            "    num_agent_steps_trained: 230000\n",
            "    num_steps_sampled: 230000\n",
            "    num_steps_trained: 230000\n",
            "  iterations_since_restore: 11\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.0642857142857\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04683869294792692\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06103892264533995\n",
            "    mean_inference_ms: 0.7163691091779573\n",
            "    mean_raw_obs_processing_ms: 0.129735791284731\n",
            "  time_since_restore: 110.88919568061829\n",
            "  time_this_iter_s: 10.023966789245605\n",
            "  time_total_s: 232.63338947296143\n",
            "  timers:\n",
            "    learn_throughput: 26293.29\n",
            "    learn_time_ms: 380.325\n",
            "    load_throughput: 3600570.006\n",
            "    load_time_ms: 2.777\n",
            "    sample_throughput: 1033.668\n",
            "    sample_time_ms: 9674.29\n",
            "    update_time_ms: 3.091\n",
            "  timestamp: 1624605535\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 230000\n",
            "  training_iteration: 23\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 3 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:1512</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         232.633</td><td style=\"text-align: right;\">230000</td><td style=\"text-align: right;\">  -88.58</td><td style=\"text-align: right;\">                 -39</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 240000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-19-05\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -6.0\n",
            "  episode_reward_mean: -87.62\n",
            "  episode_reward_min: -173.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 800\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 9.765625145519152e-05\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.14148232340812683\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0016443373169749975\n",
            "          model: {}\n",
            "          policy_loss: -0.008004935458302498\n",
            "          total_loss: 28.370498657226562\n",
            "          vf_explained_var: 0.7734156847000122\n",
            "          vf_loss: 28.378501892089844\n",
            "    num_agent_steps_sampled: 240000\n",
            "    num_agent_steps_trained: 240000\n",
            "    num_steps_sampled: 240000\n",
            "    num_steps_trained: 240000\n",
            "  iterations_since_restore: 12\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.36\n",
            "    ram_util_percent: 23.199999999999996\n",
            "  pid: 1512\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04687694486144146\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061051061144178125\n",
            "    mean_inference_ms: 0.7171691214985563\n",
            "    mean_raw_obs_processing_ms: 0.12985202794915054\n",
            "  time_since_restore: 121.13196873664856\n",
            "  time_this_iter_s: 10.242773056030273\n",
            "  time_total_s: 242.8761625289917\n",
            "  timers:\n",
            "    learn_throughput: 26413.152\n",
            "    learn_time_ms: 378.599\n",
            "    load_throughput: 3649029.519\n",
            "    load_time_ms: 2.74\n",
            "    sample_throughput: 1032.732\n",
            "    sample_time_ms: 9683.055\n",
            "    update_time_ms: 2.979\n",
            "  timestamp: 1624605545\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 240000\n",
            "  training_iteration: 24\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 4 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m 2021-06-25 07:19:10,265\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m 2021-06-25 07:19:10,265\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m 2021-06-25 07:19:10,266\tWARNING ppo.py:143 -- `train_batch_size` (28086) cannot be achieved with your other settings (num_workers=1 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 28086.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 4 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1632)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1632)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1632)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1632)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1632)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1632)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1632)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1632)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1632)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1632)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 4 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         129.506</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\"> -345.19</td><td style=\"text-align: right;\">                -168</td><td style=\"text-align: right;\">                -645</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m 2021-06-25 07:19:18,221\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m 2021-06-25 07:19:18,297\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00003_3_num_sgd_iter=10,sgd_minibatch_size=2048,train_batch_size=10000_2021-06-25_07-01-59/tmp4v4g8rhjrestore_from_object/checkpoint-12\n",
            "\u001b[2m\u001b[36m(pid=1631)\u001b[0m 2021-06-25 07:19:18,299\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 12, '_timesteps_total': None, '_time_total': 121.74419379234314, '_episodes_total': 400}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 148086\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-19-46\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -84.0\n",
            "  episode_reward_mean: -193.55913978494624\n",
            "  episode_reward_min: -359.0\n",
            "  episodes_this_iter: 93\n",
            "  episodes_total: 493\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.22488367557525635\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0069376155734062195\n",
            "          model: {}\n",
            "          policy_loss: -0.009609299711883068\n",
            "          total_loss: 242.08221435546875\n",
            "          vf_explained_var: 0.33607518672943115\n",
            "          vf_loss: 242.09042358398438\n",
            "    num_agent_steps_sampled: 148086\n",
            "    num_agent_steps_trained: 148086\n",
            "    num_steps_sampled: 148086\n",
            "    num_steps_trained: 148086\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.956097560975614\n",
            "    ram_util_percent: 23.32439024390244\n",
            "  pid: 1631\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0490219055636473\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06211664302574802\n",
            "    mean_inference_ms: 0.7188631775465172\n",
            "    mean_raw_obs_processing_ms: 0.13165566123902364\n",
            "  time_since_restore: 27.97315549850464\n",
            "  time_this_iter_s: 27.97315549850464\n",
            "  time_total_s: 149.71734929084778\n",
            "  timers:\n",
            "    learn_throughput: 36163.265\n",
            "    learn_time_ms: 776.644\n",
            "    load_throughput: 902878.16\n",
            "    load_time_ms: 31.107\n",
            "    sample_throughput: 1034.368\n",
            "    sample_time_ms: 27152.809\n",
            "    update_time_ms: 4.591\n",
            "  timestamp: 1624605586\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 148086\n",
            "  training_iteration: 13\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 4 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:1631</td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         149.717</td><td style=\"text-align: right;\">148086</td><td style=\"text-align: right;\">-193.559</td><td style=\"text-align: right;\">                 -84</td><td style=\"text-align: right;\">                -359</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -87.62 </td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-159.6  </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-307.72 </td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-344.32 </td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\">-450.23 </td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 176172\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-20-13\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -73.0\n",
            "  episode_reward_mean: -171.01\n",
            "  episode_reward_min: -302.0\n",
            "  episodes_this_iter: 94\n",
            "  episodes_total: 587\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.20951500535011292\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0016541721997782588\n",
            "          model: {}\n",
            "          policy_loss: -0.005497604608535767\n",
            "          total_loss: 180.60693359375\n",
            "          vf_explained_var: 0.3760477602481842\n",
            "          vf_loss: 180.61209106445312\n",
            "    num_agent_steps_sampled: 176172\n",
            "    num_agent_steps_trained: 176172\n",
            "    num_steps_sampled: 176172\n",
            "    num_steps_trained: 176172\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.43947368421052\n",
            "    ram_util_percent: 23.402631578947364\n",
            "  pid: 1631\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04822496925865198\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06172619708317826\n",
            "    mean_inference_ms: 0.7127383569312546\n",
            "    mean_raw_obs_processing_ms: 0.12991184361647823\n",
            "  time_since_restore: 55.15827775001526\n",
            "  time_this_iter_s: 27.18512225151062\n",
            "  time_total_s: 176.9024715423584\n",
            "  timers:\n",
            "    learn_throughput: 41814.267\n",
            "    learn_time_ms: 671.685\n",
            "    load_throughput: 1431685.399\n",
            "    load_time_ms: 19.617\n",
            "    sample_throughput: 1045.45\n",
            "    sample_time_ms: 26864.998\n",
            "    update_time_ms: 3.669\n",
            "  timestamp: 1624605613\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 176172\n",
            "  training_iteration: 14\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 4 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:1631</td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         176.902</td><td style=\"text-align: right;\">176172</td><td style=\"text-align: right;\"> -171.01</td><td style=\"text-align: right;\">                 -73</td><td style=\"text-align: right;\">                -302</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 204258\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-20-41\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -67.0\n",
            "  episode_reward_mean: -151.04\n",
            "  episode_reward_min: -283.0\n",
            "  episodes_this_iter: 93\n",
            "  episodes_total: 680\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.1931506097316742\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004730207845568657\n",
            "          model: {}\n",
            "          policy_loss: -0.006278883665800095\n",
            "          total_loss: 143.814697265625\n",
            "          vf_explained_var: 0.41053760051727295\n",
            "          vf_loss: 143.82049560546875\n",
            "    num_agent_steps_sampled: 204258\n",
            "    num_agent_steps_trained: 204258\n",
            "    num_steps_sampled: 204258\n",
            "    num_steps_trained: 204258\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 60.8775\n",
            "    ram_util_percent: 23.48\n",
            "  pid: 1631\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04825164407067215\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.062034192325423024\n",
            "    mean_inference_ms: 0.7145927330988161\n",
            "    mean_raw_obs_processing_ms: 0.13030509912624383\n",
            "  time_since_restore: 82.9233946800232\n",
            "  time_this_iter_s: 27.765116930007935\n",
            "  time_total_s: 204.66758847236633\n",
            "  timers:\n",
            "    learn_throughput: 43208.902\n",
            "    learn_time_ms: 650.005\n",
            "    load_throughput: 1869761.74\n",
            "    load_time_ms: 15.021\n",
            "    sample_throughput: 1041.859\n",
            "    sample_time_ms: 26957.579\n",
            "    update_time_ms: 3.327\n",
            "  timestamp: 1624605641\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 204258\n",
            "  training_iteration: 15\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 4 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:1631</td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         204.668</td><td style=\"text-align: right;\">204258</td><td style=\"text-align: right;\"> -151.04</td><td style=\"text-align: right;\">                 -67</td><td style=\"text-align: right;\">                -283</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 232344\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-21-08\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -60.0\n",
            "  episode_reward_mean: -137.38\n",
            "  episode_reward_min: -263.0\n",
            "  episodes_this_iter: 94\n",
            "  episodes_total: 774\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.18027007579803467\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0035629530902951956\n",
            "          model: {}\n",
            "          policy_loss: -0.005978889763355255\n",
            "          total_loss: 133.95123291015625\n",
            "          vf_explained_var: 0.41725942492485046\n",
            "          vf_loss: 133.95704650878906\n",
            "    num_agent_steps_sampled: 232344\n",
            "    num_agent_steps_trained: 232344\n",
            "    num_steps_sampled: 232344\n",
            "    num_steps_trained: 232344\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.04102564102564\n",
            "    ram_util_percent: 23.41025641025641\n",
            "  pid: 1631\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04810646474240798\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06192490109857183\n",
            "    mean_inference_ms: 0.7144249362170529\n",
            "    mean_raw_obs_processing_ms: 0.1298923070666218\n",
            "  time_since_restore: 110.35704970359802\n",
            "  time_this_iter_s: 27.43365502357483\n",
            "  time_total_s: 232.10124349594116\n",
            "  timers:\n",
            "    learn_throughput: 44033.145\n",
            "    learn_time_ms: 637.838\n",
            "    load_throughput: 2224332.818\n",
            "    load_time_ms: 12.627\n",
            "    sample_throughput: 1043.241\n",
            "    sample_time_ms: 26921.869\n",
            "    update_time_ms: 3.51\n",
            "  timestamp: 1624605668\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 232344\n",
            "  training_iteration: 16\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 4 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:1631</td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         232.101</td><td style=\"text-align: right;\">232344</td><td style=\"text-align: right;\"> -137.38</td><td style=\"text-align: right;\">                 -60</td><td style=\"text-align: right;\">                -263</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 260430\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-21-36\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -61.0\n",
            "  episode_reward_mean: -125.53\n",
            "  episode_reward_min: -243.0\n",
            "  episodes_this_iter: 94\n",
            "  episodes_total: 868\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.1680763214826584\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00541779724881053\n",
            "          model: {}\n",
            "          policy_loss: -0.005131586920469999\n",
            "          total_loss: 112.92448425292969\n",
            "          vf_explained_var: 0.4568294882774353\n",
            "          vf_loss: 112.92948913574219\n",
            "    num_agent_steps_sampled: 260430\n",
            "    num_agent_steps_trained: 260430\n",
            "    num_steps_sampled: 260430\n",
            "    num_steps_trained: 260430\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.14871794871795\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 1631\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04819201461654016\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06185957416836196\n",
            "    mean_inference_ms: 0.7137443181600911\n",
            "    mean_raw_obs_processing_ms: 0.1297921945891555\n",
            "  time_since_restore: 137.75092005729675\n",
            "  time_this_iter_s: 27.39387035369873\n",
            "  time_total_s: 259.4951138496399\n",
            "  timers:\n",
            "    learn_throughput: 45001.529\n",
            "    learn_time_ms: 624.112\n",
            "    load_throughput: 2502362.608\n",
            "    load_time_ms: 11.224\n",
            "    sample_throughput: 1044.126\n",
            "    sample_time_ms: 26899.056\n",
            "    update_time_ms: 3.527\n",
            "  timestamp: 1624605696\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 260430\n",
            "  training_iteration: 17\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m 2021-06-25 07:21:41,210\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m 2021-06-25 07:21:41,210\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.2/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1789)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1789)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1789)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1789)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1789)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1789)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1789)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1789)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1789)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1789)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.8/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         148.335</td><td style=\"text-align: right;\"> 80000</td><td style=\"text-align: right;\"> -450.23</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">                -880</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m 2021-06-25 07:21:49,650\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m 2021-06-25 07:21:49,724\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00006_6_num_sgd_iter=30,sgd_minibatch_size=128,train_batch_size=20000_2021-06-25_07-09-08/tmpursncko_restore_from_object/checkpoint-12\n",
            "\u001b[2m\u001b[36m(pid=1762)\u001b[0m 2021-06-25 07:21:49,725\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 12, '_timesteps_total': None, '_time_total': 121.74419379234314, '_episodes_total': 400}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 128000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-21-57\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -84.0\n",
            "  episode_reward_mean: -180.84615384615384\n",
            "  episode_reward_min: -281.0\n",
            "  episodes_this_iter: 26\n",
            "  episodes_total: 426\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.2394810914993286\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0022196995560079813\n",
            "          model: {}\n",
            "          policy_loss: -0.0027264789678156376\n",
            "          total_loss: 1061153669120.0\n",
            "          vf_explained_var: 8.344650268554688e-07\n",
            "          vf_loss: 1061153669120.0\n",
            "    num_agent_steps_sampled: 128000\n",
            "    num_agent_steps_trained: 128000\n",
            "    num_steps_sampled: 128000\n",
            "    num_steps_trained: 128000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.30833333333334\n",
            "    ram_util_percent: 23.391666666666666\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.045563128423339164\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06053394383899033\n",
            "    mean_inference_ms: 0.7155165048319614\n",
            "    mean_raw_obs_processing_ms: 0.12992718952504595\n",
            "  time_since_restore: 8.267906665802002\n",
            "  time_this_iter_s: 8.267906665802002\n",
            "  time_total_s: 130.01210045814514\n",
            "  timers:\n",
            "    learn_throughput: 17061.503\n",
            "    learn_time_ms: 468.892\n",
            "    load_throughput: 284443.962\n",
            "    load_time_ms: 28.125\n",
            "    sample_throughput: 1033.481\n",
            "    sample_time_ms: 7740.832\n",
            "    update_time_ms: 2.357\n",
            "  timestamp: 1624605717\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 128000\n",
            "  training_iteration: 13\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         130.012</td><td style=\"text-align: right;\">128000</td><td style=\"text-align: right;\">-180.846</td><td style=\"text-align: right;\">                 -84</td><td style=\"text-align: right;\">                -281</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -87.62 </td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-159.6  </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-307.72 </td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-344.32 </td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 136000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-22-06\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -84.0\n",
            "  episode_reward_mean: -190.03773584905662\n",
            "  episode_reward_min: -281.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 453\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.22679118812084198\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003398965112864971\n",
            "          model: {}\n",
            "          policy_loss: -0.013376733288168907\n",
            "          total_loss: 1424123101184.0\n",
            "          vf_explained_var: -7.450580596923828e-08\n",
            "          vf_loss: 1424123101184.0\n",
            "    num_agent_steps_sampled: 136000\n",
            "    num_agent_steps_trained: 136000\n",
            "    num_steps_sampled: 136000\n",
            "    num_steps_trained: 136000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.35\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.045781217143208694\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06086970175167027\n",
            "    mean_inference_ms: 0.7175164076573596\n",
            "    mean_raw_obs_processing_ms: 0.13018954595932758\n",
            "  time_since_restore: 16.373151302337646\n",
            "  time_this_iter_s: 8.105244636535645\n",
            "  time_total_s: 138.1173450946808\n",
            "  timers:\n",
            "    learn_throughput: 20883.509\n",
            "    learn_time_ms: 383.077\n",
            "    load_throughput: 518731.895\n",
            "    load_time_ms: 15.422\n",
            "    sample_throughput: 1029.801\n",
            "    sample_time_ms: 7768.488\n",
            "    update_time_ms: 2.651\n",
            "  timestamp: 1624605726\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 136000\n",
            "  training_iteration: 14\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         138.117</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\">-190.038</td><td style=\"text-align: right;\">                 -84</td><td style=\"text-align: right;\">                -281</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -87.62 </td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-159.6  </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-307.72 </td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-344.32 </td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 144000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-22-14\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -84.0\n",
            "  episode_reward_mean: -185.9625\n",
            "  episode_reward_min: -284.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 480\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.22994427382946014\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0032333757262676954\n",
            "          model: {}\n",
            "          policy_loss: -0.0013539292849600315\n",
            "          total_loss: 898732916736.0\n",
            "          vf_explained_var: 4.3213367462158203e-07\n",
            "          vf_loss: 898732916736.0\n",
            "    num_agent_steps_sampled: 144000\n",
            "    num_agent_steps_trained: 144000\n",
            "    num_steps_sampled: 144000\n",
            "    num_steps_trained: 144000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.73333333333333\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.045834979002079654\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060926166232469714\n",
            "    mean_inference_ms: 0.7184556110294384\n",
            "    mean_raw_obs_processing_ms: 0.13020831106659916\n",
            "  time_since_restore: 24.448012351989746\n",
            "  time_this_iter_s: 8.0748610496521\n",
            "  time_total_s: 146.19220614433289\n",
            "  timers:\n",
            "    learn_throughput: 22538.828\n",
            "    learn_time_ms: 354.943\n",
            "    load_throughput: 723852.674\n",
            "    load_time_ms: 11.052\n",
            "    sample_throughput: 1029.985\n",
            "    sample_time_ms: 7767.103\n",
            "    update_time_ms: 2.661\n",
            "  timestamp: 1624605734\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 144000\n",
            "  training_iteration: 15\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         146.192</td><td style=\"text-align: right;\">144000</td><td style=\"text-align: right;\">-185.963</td><td style=\"text-align: right;\">                 -84</td><td style=\"text-align: right;\">                -284</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -87.62 </td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-159.6  </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-307.72 </td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-344.32 </td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 152000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-22-22\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -101.0\n",
            "  episode_reward_mean: -186.49\n",
            "  episode_reward_min: -327.0\n",
            "  episodes_this_iter: 26\n",
            "  episodes_total: 506\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.22416025400161743\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004791107960045338\n",
            "          model: {}\n",
            "          policy_loss: 0.0017299670726060867\n",
            "          total_loss: 818657296384.0\n",
            "          vf_explained_var: 6.854534149169922e-07\n",
            "          vf_loss: 818657296384.0\n",
            "    num_agent_steps_sampled: 152000\n",
            "    num_agent_steps_trained: 152000\n",
            "    num_steps_sampled: 152000\n",
            "    num_steps_trained: 152000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.75454545454545\n",
            "    ram_util_percent: 23.4\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04590168346266193\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06098766625711976\n",
            "    mean_inference_ms: 0.7192599074850884\n",
            "    mean_raw_obs_processing_ms: 0.13027761769938032\n",
            "  time_since_restore: 32.53510022163391\n",
            "  time_this_iter_s: 8.087087869644165\n",
            "  time_total_s: 154.27929401397705\n",
            "  timers:\n",
            "    learn_throughput: 23614.237\n",
            "    learn_time_ms: 338.779\n",
            "    load_throughput: 890486.771\n",
            "    load_time_ms: 8.984\n",
            "    sample_throughput: 1029.431\n",
            "    sample_time_ms: 7771.28\n",
            "    update_time_ms: 2.64\n",
            "  timestamp: 1624605742\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 152000\n",
            "  training_iteration: 16\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         154.279</td><td style=\"text-align: right;\">152000</td><td style=\"text-align: right;\"> -186.49</td><td style=\"text-align: right;\">                -101</td><td style=\"text-align: right;\">                -327</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 160000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-22-30\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -101.0\n",
            "  episode_reward_mean: -191.74\n",
            "  episode_reward_min: -327.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 533\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.22534765303134918\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004903239198029041\n",
            "          model: {}\n",
            "          policy_loss: 0.00679819704964757\n",
            "          total_loss: 700365537280.0\n",
            "          vf_explained_var: -4.470348358154297e-07\n",
            "          vf_loss: 700365537280.0\n",
            "    num_agent_steps_sampled: 160000\n",
            "    num_agent_steps_trained: 160000\n",
            "    num_steps_sampled: 160000\n",
            "    num_steps_trained: 160000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.81666666666666\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046081989556689705\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06105069100681961\n",
            "    mean_inference_ms: 0.7198946311574212\n",
            "    mean_raw_obs_processing_ms: 0.13027287311120658\n",
            "  time_since_restore: 40.52482748031616\n",
            "  time_this_iter_s: 7.989727258682251\n",
            "  time_total_s: 162.2690212726593\n",
            "  timers:\n",
            "    learn_throughput: 24197.689\n",
            "    learn_time_ms: 330.61\n",
            "    load_throughput: 1044183.901\n",
            "    load_time_ms: 7.661\n",
            "    sample_throughput: 1031.861\n",
            "    sample_time_ms: 7752.979\n",
            "    update_time_ms: 2.783\n",
            "  timestamp: 1624605750\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 160000\n",
            "  training_iteration: 17\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         162.269</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\"> -191.74</td><td style=\"text-align: right;\">                -101</td><td style=\"text-align: right;\">                -327</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 168000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-22-38\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -101.0\n",
            "  episode_reward_mean: -197.85\n",
            "  episode_reward_min: -327.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 560\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24075214564800262\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004139234311878681\n",
            "          model: {}\n",
            "          policy_loss: -0.008000276982784271\n",
            "          total_loss: 1703120207872.0\n",
            "          vf_explained_var: 9.238719940185547e-07\n",
            "          vf_loss: 1703120207872.0\n",
            "    num_agent_steps_sampled: 168000\n",
            "    num_agent_steps_trained: 168000\n",
            "    num_steps_sampled: 168000\n",
            "    num_steps_trained: 168000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.53636363636363\n",
            "    ram_util_percent: 23.4\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04615285213529664\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061030255808236206\n",
            "    mean_inference_ms: 0.7195974778182047\n",
            "    mean_raw_obs_processing_ms: 0.13019865264815406\n",
            "  time_since_restore: 48.55417060852051\n",
            "  time_this_iter_s: 8.029343128204346\n",
            "  time_total_s: 170.29836440086365\n",
            "  timers:\n",
            "    learn_throughput: 24787.935\n",
            "    learn_time_ms: 322.738\n",
            "    load_throughput: 1172978.973\n",
            "    load_time_ms: 6.82\n",
            "    sample_throughput: 1032.268\n",
            "    sample_time_ms: 7749.923\n",
            "    update_time_ms: 2.709\n",
            "  timestamp: 1624605758\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 168000\n",
            "  training_iteration: 18\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         170.298</td><td style=\"text-align: right;\">168000</td><td style=\"text-align: right;\"> -197.85</td><td style=\"text-align: right;\">                -101</td><td style=\"text-align: right;\">                -327</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 176000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-22-46\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -101.0\n",
            "  episode_reward_mean: -212.91\n",
            "  episode_reward_min: -384.0\n",
            "  episodes_this_iter: 26\n",
            "  episodes_total: 586\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0031250000465661287\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24016031622886658\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00395078444853425\n",
            "          model: {}\n",
            "          policy_loss: 0.0017269635573029518\n",
            "          total_loss: 1836946423808.0\n",
            "          vf_explained_var: 1.296401023864746e-06\n",
            "          vf_loss: 1836946423808.0\n",
            "    num_agent_steps_sampled: 176000\n",
            "    num_agent_steps_trained: 176000\n",
            "    num_steps_sampled: 176000\n",
            "    num_steps_trained: 176000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.44999999999999\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04623297050704135\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06104281570484499\n",
            "    mean_inference_ms: 0.7192577783767191\n",
            "    mean_raw_obs_processing_ms: 0.1301718723583946\n",
            "  time_since_restore: 56.651021003723145\n",
            "  time_this_iter_s: 8.096850395202637\n",
            "  time_total_s: 178.39521479606628\n",
            "  timers:\n",
            "    learn_throughput: 24985.514\n",
            "    learn_time_ms: 320.186\n",
            "    load_throughput: 1285237.583\n",
            "    load_time_ms: 6.225\n",
            "    sample_throughput: 1031.705\n",
            "    sample_time_ms: 7754.156\n",
            "    update_time_ms: 2.685\n",
            "  timestamp: 1624605766\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 176000\n",
            "  training_iteration: 19\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         178.395</td><td style=\"text-align: right;\">176000</td><td style=\"text-align: right;\"> -212.91</td><td style=\"text-align: right;\">                -101</td><td style=\"text-align: right;\">                -384</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 184000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-22-54\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -101.0\n",
            "  episode_reward_mean: -224.38\n",
            "  episode_reward_min: -384.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 613\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0015625000232830644\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24324819445610046\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.002292770193889737\n",
            "          model: {}\n",
            "          policy_loss: -0.014943230897188187\n",
            "          total_loss: 1536985661440.0\n",
            "          vf_explained_var: 2.4437904357910156e-06\n",
            "          vf_loss: 1536985661440.0\n",
            "    num_agent_steps_sampled: 184000\n",
            "    num_agent_steps_trained: 184000\n",
            "    num_steps_sampled: 184000\n",
            "    num_steps_trained: 184000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.52727272727273\n",
            "    ram_util_percent: 23.4\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04628215221089452\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06108918215622843\n",
            "    mean_inference_ms: 0.7191090029691308\n",
            "    mean_raw_obs_processing_ms: 0.13017205261617698\n",
            "  time_since_restore: 64.76118540763855\n",
            "  time_this_iter_s: 8.110164403915405\n",
            "  time_total_s: 186.5053791999817\n",
            "  timers:\n",
            "    learn_throughput: 25287.259\n",
            "    learn_time_ms: 316.365\n",
            "    load_throughput: 1399245.508\n",
            "    load_time_ms: 5.717\n",
            "    sample_throughput: 1030.794\n",
            "    sample_time_ms: 7761.006\n",
            "    update_time_ms: 2.689\n",
            "  timestamp: 1624605774\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 184000\n",
            "  training_iteration: 20\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         186.505</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\"> -224.38</td><td style=\"text-align: right;\">                -101</td><td style=\"text-align: right;\">                -384</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 192000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-23-02\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -96.0\n",
            "  episode_reward_mean: -236.17\n",
            "  episode_reward_min: -488.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 640\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0007812500116415322\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.26489052176475525\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00581652345135808\n",
            "          model: {}\n",
            "          policy_loss: -0.0065928734838962555\n",
            "          total_loss: 2687568969728.0\n",
            "          vf_explained_var: 1.0132789611816406e-06\n",
            "          vf_loss: 2687568969728.0\n",
            "    num_agent_steps_sampled: 192000\n",
            "    num_agent_steps_trained: 192000\n",
            "    num_steps_sampled: 192000\n",
            "    num_steps_trained: 192000\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.68333333333333\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04626602157254428\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06113759834033511\n",
            "    mean_inference_ms: 0.7192779208197051\n",
            "    mean_raw_obs_processing_ms: 0.1302650877392459\n",
            "  time_since_restore: 72.80165219306946\n",
            "  time_this_iter_s: 8.040466785430908\n",
            "  time_total_s: 194.5458459854126\n",
            "  timers:\n",
            "    learn_throughput: 25462.913\n",
            "    learn_time_ms: 314.182\n",
            "    load_throughput: 1492317.706\n",
            "    load_time_ms: 5.361\n",
            "    sample_throughput: 1031.207\n",
            "    sample_time_ms: 7757.901\n",
            "    update_time_ms: 2.668\n",
            "  timestamp: 1624605782\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 192000\n",
            "  training_iteration: 21\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         194.546</td><td style=\"text-align: right;\">192000</td><td style=\"text-align: right;\"> -236.17</td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -488</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 200000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-23-10\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -96.0\n",
            "  episode_reward_mean: -243.05\n",
            "  episode_reward_min: -488.0\n",
            "  episodes_this_iter: 26\n",
            "  episodes_total: 666\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0007812500116415322\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24736058712005615\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00565243698656559\n",
            "          model: {}\n",
            "          policy_loss: -0.008309797383844852\n",
            "          total_loss: 2174823170048.0\n",
            "          vf_explained_var: 1.6391277313232422e-06\n",
            "          vf_loss: 2174823170048.0\n",
            "    num_agent_steps_sampled: 200000\n",
            "    num_agent_steps_trained: 200000\n",
            "    num_steps_sampled: 200000\n",
            "    num_steps_trained: 200000\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.73636363636365\n",
            "    ram_util_percent: 23.4\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046273763708568005\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061174746070939534\n",
            "    mean_inference_ms: 0.7195890359867098\n",
            "    mean_raw_obs_processing_ms: 0.13038609442976198\n",
            "  time_since_restore: 80.92314887046814\n",
            "  time_this_iter_s: 8.121496677398682\n",
            "  time_total_s: 202.66734266281128\n",
            "  timers:\n",
            "    learn_throughput: 25642.898\n",
            "    learn_time_ms: 311.977\n",
            "    load_throughput: 1564586.36\n",
            "    load_time_ms: 5.113\n",
            "    sample_throughput: 1030.448\n",
            "    sample_time_ms: 7763.615\n",
            "    update_time_ms: 2.649\n",
            "  timestamp: 1624605790\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 200000\n",
            "  training_iteration: 22\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         202.667</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -243.05</td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -488</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 208000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-23-18\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -96.0\n",
            "  episode_reward_mean: -245.75\n",
            "  episode_reward_min: -488.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 693\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0007812500116415322\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24257655441761017\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003274376969784498\n",
            "          model: {}\n",
            "          policy_loss: -0.0031044003553688526\n",
            "          total_loss: 4021945368576.0\n",
            "          vf_explained_var: 7.450580596923828e-07\n",
            "          vf_loss: 4021945368576.0\n",
            "    num_agent_steps_sampled: 208000\n",
            "    num_agent_steps_trained: 208000\n",
            "    num_steps_sampled: 208000\n",
            "    num_steps_trained: 208000\n",
            "  iterations_since_restore: 11\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.66666666666666\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046266218239370556\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06118899718107315\n",
            "    mean_inference_ms: 0.7196516378142225\n",
            "    mean_raw_obs_processing_ms: 0.13047091383798978\n",
            "  time_since_restore: 88.96051216125488\n",
            "  time_this_iter_s: 8.037363290786743\n",
            "  time_total_s: 210.70470595359802\n",
            "  timers:\n",
            "    learn_throughput: 27019.797\n",
            "    learn_time_ms: 296.079\n",
            "    load_throughput: 3113493.611\n",
            "    load_time_ms: 2.569\n",
            "    sample_throughput: 1030.785\n",
            "    sample_time_ms: 7761.072\n",
            "    update_time_ms: 2.692\n",
            "  timestamp: 1624605798\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 208000\n",
            "  training_iteration: 23\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         210.705</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\"> -245.75</td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -488</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 216000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-23-27\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -96.0\n",
            "  episode_reward_mean: -243.42\n",
            "  episode_reward_min: -424.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 720\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0003906250058207661\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24460580945014954\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0044989679008722305\n",
            "          model: {}\n",
            "          policy_loss: -0.00012564333155751228\n",
            "          total_loss: 4153617678336.0\n",
            "          vf_explained_var: 1.3709068298339844e-06\n",
            "          vf_loss: 4153617678336.0\n",
            "    num_agent_steps_sampled: 216000\n",
            "    num_agent_steps_trained: 216000\n",
            "    num_steps_sampled: 216000\n",
            "    num_steps_trained: 216000\n",
            "  iterations_since_restore: 12\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.85833333333333\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04626476490267743\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06119066181693418\n",
            "    mean_inference_ms: 0.7197322257237224\n",
            "    mean_raw_obs_processing_ms: 0.13054349375928334\n",
            "  time_since_restore: 97.0937147140503\n",
            "  time_this_iter_s: 8.13320255279541\n",
            "  time_total_s: 218.83790850639343\n",
            "  timers:\n",
            "    learn_throughput: 26935.341\n",
            "    learn_time_ms: 297.008\n",
            "    load_throughput: 3200934.11\n",
            "    load_time_ms: 2.499\n",
            "    sample_throughput: 1030.524\n",
            "    sample_time_ms: 7763.043\n",
            "    update_time_ms: 2.703\n",
            "  timestamp: 1624605807\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 216000\n",
            "  training_iteration: 24\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         218.838</td><td style=\"text-align: right;\">216000</td><td style=\"text-align: right;\"> -243.42</td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -424</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 224000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-23-35\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -96.0\n",
            "  episode_reward_mean: -241.56\n",
            "  episode_reward_min: -424.0\n",
            "  episodes_this_iter: 26\n",
            "  episodes_total: 746\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.00019531250291038305\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24026519060134888\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006170427892357111\n",
            "          model: {}\n",
            "          policy_loss: -0.004706155974417925\n",
            "          total_loss: 4850148442112.0\n",
            "          vf_explained_var: 1.9669532775878906e-06\n",
            "          vf_loss: 4850148442112.0\n",
            "    num_agent_steps_sampled: 224000\n",
            "    num_agent_steps_trained: 224000\n",
            "    num_steps_sampled: 224000\n",
            "    num_steps_trained: 224000\n",
            "  iterations_since_restore: 13\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.463636363636354\n",
            "    ram_util_percent: 23.4\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04626319898427842\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06119874007728555\n",
            "    mean_inference_ms: 0.7198774902008117\n",
            "    mean_raw_obs_processing_ms: 0.1305698888374305\n",
            "  time_since_restore: 105.16105341911316\n",
            "  time_this_iter_s: 8.067338705062866\n",
            "  time_total_s: 226.9052472114563\n",
            "  timers:\n",
            "    learn_throughput: 26984.576\n",
            "    learn_time_ms: 296.466\n",
            "    load_throughput: 3222112.197\n",
            "    load_time_ms: 2.483\n",
            "    sample_throughput: 1030.539\n",
            "    sample_time_ms: 7762.927\n",
            "    update_time_ms: 2.711\n",
            "  timestamp: 1624605815\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 224000\n",
            "  training_iteration: 25\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         226.905</td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\"> -241.56</td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -424</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 232000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-23-43\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -96.0\n",
            "  episode_reward_mean: -265.3\n",
            "  episode_reward_min: -523.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 773\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.00019531250291038305\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24845707416534424\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003992302343249321\n",
            "          model: {}\n",
            "          policy_loss: -0.0031059742905199528\n",
            "          total_loss: 7282701107200.0\n",
            "          vf_explained_var: 1.1771917343139648e-06\n",
            "          vf_loss: 7282701107200.0\n",
            "    num_agent_steps_sampled: 232000\n",
            "    num_agent_steps_trained: 232000\n",
            "    num_steps_sampled: 232000\n",
            "    num_steps_trained: 232000\n",
            "  iterations_since_restore: 14\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.63333333333333\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04624864453508275\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06118379449501049\n",
            "    mean_inference_ms: 0.7199621849726424\n",
            "    mean_raw_obs_processing_ms: 0.13054573854767676\n",
            "  time_since_restore: 113.20835661888123\n",
            "  time_this_iter_s: 8.047303199768066\n",
            "  time_total_s: 234.95255041122437\n",
            "  timers:\n",
            "    learn_throughput: 26988.124\n",
            "    learn_time_ms: 296.427\n",
            "    load_throughput: 3302244.048\n",
            "    load_time_ms: 2.423\n",
            "    sample_throughput: 1031.042\n",
            "    sample_time_ms: 7759.142\n",
            "    update_time_ms: 2.72\n",
            "  timestamp: 1624605823\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 232000\n",
            "  training_iteration: 26\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:1762</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         234.953</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\"> -265.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 240000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-23-51\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -96.0\n",
            "  episode_reward_mean: -281.3\n",
            "  episode_reward_min: -523.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 800\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 9.765625145519152e-05\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.23891928791999817\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003462265944108367\n",
            "          model: {}\n",
            "          policy_loss: -0.01304149255156517\n",
            "          total_loss: 5398075015168.0\n",
            "          vf_explained_var: -7.450580596923828e-08\n",
            "          vf_loss: 5398075015168.0\n",
            "    num_agent_steps_sampled: 240000\n",
            "    num_agent_steps_trained: 240000\n",
            "    num_steps_sampled: 240000\n",
            "    num_steps_trained: 240000\n",
            "  iterations_since_restore: 15\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.42727272727273\n",
            "    ram_util_percent: 23.4\n",
            "  pid: 1762\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04624974023613828\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061172957177087234\n",
            "    mean_inference_ms: 0.7200840747432105\n",
            "    mean_raw_obs_processing_ms: 0.13051597453945596\n",
            "  time_since_restore: 121.26560091972351\n",
            "  time_this_iter_s: 8.057244300842285\n",
            "  time_total_s: 243.00979471206665\n",
            "  timers:\n",
            "    learn_throughput: 27106.351\n",
            "    learn_time_ms: 295.134\n",
            "    load_throughput: 3292684.631\n",
            "    load_time_ms: 2.43\n",
            "    sample_throughput: 1029.976\n",
            "    sample_time_ms: 7767.169\n",
            "    update_time_ms: 2.699\n",
            "  timestamp: 1624605831\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 240000\n",
            "  training_iteration: 27\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m 2021-06-25 07:23:55,827\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m 2021-06-25 07:23:55,827\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1857)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1857)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1857)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1857)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1857)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1857)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1857)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1857)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1857)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1857)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         125.017</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -344.32</td><td style=\"text-align: right;\">                -164</td><td style=\"text-align: right;\">                -651</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m 2021-06-25 07:24:03,740\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m 2021-06-25 07:24:03,814\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00007_7_num_sgd_iter=10,sgd_minibatch_size=128,train_batch_size=20000_2021-06-25_07-11-27/tmpdu15xh9arestore_from_object/checkpoint-5\n",
            "\u001b[2m\u001b[36m(pid=1855)\u001b[0m 2021-06-25 07:24:03,814\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 5, '_timesteps_total': None, '_time_total': 125.01652479171753, '_episodes_total': 333}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 120000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-24-29\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -113.0\n",
            "  episode_reward_mean: -216.28787878787878\n",
            "  episode_reward_min: -375.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 399\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.39242398738861084\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.010910212993621826\n",
            "          model: {}\n",
            "          policy_loss: -0.017498651519417763\n",
            "          total_loss: 117.23509216308594\n",
            "          vf_explained_var: 0.45312491059303284\n",
            "          vf_loss: 117.25041198730469\n",
            "    num_agent_steps_sampled: 120000\n",
            "    num_agent_steps_trained: 120000\n",
            "    num_steps_sampled: 120000\n",
            "    num_steps_trained: 120000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.38947368421053\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1855\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046465696200663605\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06088628321193195\n",
            "    mean_inference_ms: 0.732028694738359\n",
            "    mean_raw_obs_processing_ms: 0.13149387210281208\n",
            "  time_since_restore: 25.99629807472229\n",
            "  time_this_iter_s: 25.99629807472229\n",
            "  time_total_s: 151.01282286643982\n",
            "  timers:\n",
            "    learn_throughput: 3203.834\n",
            "    learn_time_ms: 6242.52\n",
            "    load_throughput: 659404.001\n",
            "    load_time_ms: 30.33\n",
            "    sample_throughput: 1014.602\n",
            "    sample_time_ms: 19712.166\n",
            "    update_time_ms: 2.62\n",
            "  timestamp: 1624605869\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 120000\n",
            "  training_iteration: 6\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:1855</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         151.013</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-216.288</td><td style=\"text-align: right;\">                -113</td><td style=\"text-align: right;\">                -375</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -87.62 </td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-307.72 </td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-281.3  </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\">-159.6  </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 140000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-24-55\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -61.0\n",
            "  episode_reward_mean: -171.28\n",
            "  episode_reward_min: -375.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 466\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.3564613163471222\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.008178019896149635\n",
            "          model: {}\n",
            "          policy_loss: -0.014999444596469402\n",
            "          total_loss: 71.95939636230469\n",
            "          vf_explained_var: 0.5811004042625427\n",
            "          vf_loss: 71.97277069091797\n",
            "    num_agent_steps_sampled: 140000\n",
            "    num_agent_steps_trained: 140000\n",
            "    num_steps_sampled: 140000\n",
            "    num_steps_trained: 140000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.638888888888886\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1855\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04669316846455601\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06112192792958854\n",
            "    mean_inference_ms: 0.7315576812559368\n",
            "    mean_raw_obs_processing_ms: 0.13206629377886894\n",
            "  time_since_restore: 51.6151328086853\n",
            "  time_this_iter_s: 25.618834733963013\n",
            "  time_total_s: 176.63165760040283\n",
            "  timers:\n",
            "    learn_throughput: 3293.772\n",
            "    learn_time_ms: 6072.066\n",
            "    load_throughput: 1128669.187\n",
            "    load_time_ms: 17.72\n",
            "    sample_throughput: 1014.888\n",
            "    sample_time_ms: 19706.608\n",
            "    update_time_ms: 2.817\n",
            "  timestamp: 1624605895\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 140000\n",
            "  training_iteration: 7\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:1855</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         176.632</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\"> -171.28</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -375</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 160000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-25-21\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -48.0\n",
            "  episode_reward_mean: -133.41\n",
            "  episode_reward_min: -231.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 533\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.3197552561759949\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.007844640873372555\n",
            "          model: {}\n",
            "          policy_loss: -0.016054557636380196\n",
            "          total_loss: 53.830116271972656\n",
            "          vf_explained_var: 0.644597053527832\n",
            "          vf_loss: 53.844608306884766\n",
            "    num_agent_steps_sampled: 160000\n",
            "    num_agent_steps_trained: 160000\n",
            "    num_steps_sampled: 160000\n",
            "    num_steps_trained: 160000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.640540540540535\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1855\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0468736244867255\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061296138763370644\n",
            "    mean_inference_ms: 0.7312172267885491\n",
            "    mean_raw_obs_processing_ms: 0.13244747937547482\n",
            "  time_since_restore: 77.25489687919617\n",
            "  time_this_iter_s: 25.639764070510864\n",
            "  time_total_s: 202.2714216709137\n",
            "  timers:\n",
            "    learn_throughput: 3320.937\n",
            "    learn_time_ms: 6022.397\n",
            "    load_throughput: 1502805.105\n",
            "    load_time_ms: 13.308\n",
            "    sample_throughput: 1014.977\n",
            "    sample_time_ms: 19704.875\n",
            "    update_time_ms: 2.7\n",
            "  timestamp: 1624605921\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 160000\n",
            "  training_iteration: 8\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:1855</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         202.271</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\"> -133.41</td><td style=\"text-align: right;\">                 -48</td><td style=\"text-align: right;\">                -231</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 180000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-25-46\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -17.0\n",
            "  episode_reward_mean: -98.02\n",
            "  episode_reward_min: -231.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 599\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.28968262672424316\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005811099428683519\n",
            "          model: {}\n",
            "          policy_loss: -0.012223848141729832\n",
            "          total_loss: 40.29069137573242\n",
            "          vf_explained_var: 0.7042778134346008\n",
            "          vf_loss: 40.3017463684082\n",
            "    num_agent_steps_sampled: 180000\n",
            "    num_agent_steps_trained: 180000\n",
            "    num_steps_sampled: 180000\n",
            "    num_steps_trained: 180000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.67499999999999\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1855\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046883968462880975\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061243940989037904\n",
            "    mean_inference_ms: 0.7308835500982349\n",
            "    mean_raw_obs_processing_ms: 0.13244146419813604\n",
            "  time_since_restore: 102.84671759605408\n",
            "  time_this_iter_s: 25.59182071685791\n",
            "  time_total_s: 227.8632423877716\n",
            "  timers:\n",
            "    learn_throughput: 3332.614\n",
            "    learn_time_ms: 6001.295\n",
            "    load_throughput: 1820325.934\n",
            "    load_time_ms: 10.987\n",
            "    sample_throughput: 1015.832\n",
            "    sample_time_ms: 19688.292\n",
            "    update_time_ms: 2.601\n",
            "  timestamp: 1624605946\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 180000\n",
            "  training_iteration: 9\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 5 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:1855</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         227.863</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">  -98.02</td><td style=\"text-align: right;\">                 -17</td><td style=\"text-align: right;\">                -231</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 200000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-26-11\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -8.0\n",
            "  episode_reward_mean: -81.81\n",
            "  episode_reward_min: -176.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 666\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.2687990963459015\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005007986910641193\n",
            "          model: {}\n",
            "          policy_loss: -0.011725394055247307\n",
            "          total_loss: 42.30851364135742\n",
            "          vf_explained_var: 0.7000027894973755\n",
            "          vf_loss: 42.319236755371094\n",
            "    num_agent_steps_sampled: 200000\n",
            "    num_agent_steps_trained: 200000\n",
            "    num_steps_sampled: 200000\n",
            "    num_steps_trained: 200000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.78888888888888\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1855\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04671749226101647\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06091606333655353\n",
            "    mean_inference_ms: 0.7286986947081431\n",
            "    mean_raw_obs_processing_ms: 0.13194791071154077\n",
            "  time_since_restore: 128.03701877593994\n",
            "  time_this_iter_s: 25.190301179885864\n",
            "  time_total_s: 253.05354356765747\n",
            "  timers:\n",
            "    learn_throughput: 3338.646\n",
            "    learn_time_ms: 5990.452\n",
            "    load_throughput: 2034578.537\n",
            "    load_time_ms: 9.83\n",
            "    sample_throughput: 1020.61\n",
            "    sample_time_ms: 19596.126\n",
            "    update_time_ms: 2.566\n",
            "  timestamp: 1624605971\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 200000\n",
            "  training_iteration: 10\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m 2021-06-25 07:26:16,845\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m 2021-06-25 07:26:16,845\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         126.704</td><td style=\"text-align: right;\">100000</td><td style=\"text-align: right;\"> -159.6 </td><td style=\"text-align: right;\">                 -53</td><td style=\"text-align: right;\">                -303</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=1976)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=1976)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=1976)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=1976)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1976)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1976)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1976)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1976)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1976)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1976)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m 2021-06-25 07:26:24,777\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m 2021-06-25 07:26:24,852\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00004_4_num_sgd_iter=10,sgd_minibatch_size=128,train_batch_size=10000_2021-06-25_07-04-14/tmplhgra0izrestore_from_object/checkpoint-10\n",
            "\u001b[2m\u001b[36m(pid=1975)\u001b[0m 2021-06-25 07:26:24,853\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 10, '_timesteps_total': None, '_time_total': 126.70410251617432, '_episodes_total': 333}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 110000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-26-37\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -32.0\n",
            "  episode_reward_mean: -103.81818181818181\n",
            "  episode_reward_min: -152.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 366\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.29841941595077515\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0053154644556343555\n",
            "          model: {}\n",
            "          policy_loss: -0.013919632881879807\n",
            "          total_loss: 40.85951614379883\n",
            "          vf_explained_var: 0.7052722573280334\n",
            "          vf_loss: 40.87236785888672\n",
            "    num_agent_steps_sampled: 110000\n",
            "    num_agent_steps_trained: 110000\n",
            "    num_steps_sampled: 110000\n",
            "    num_steps_trained: 110000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.14736842105264\n",
            "    ram_util_percent: 23.394736842105257\n",
            "  pid: 1975\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04664152553708252\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06192053047350294\n",
            "    mean_inference_ms: 0.7222203919439598\n",
            "    mean_raw_obs_processing_ms: 0.13110995495299102\n",
            "  time_since_restore: 13.074553966522217\n",
            "  time_this_iter_s: 13.074553966522217\n",
            "  time_total_s: 139.77865648269653\n",
            "  timers:\n",
            "    learn_throughput: 3067.638\n",
            "    learn_time_ms: 3259.837\n",
            "    load_throughput: 317625.178\n",
            "    load_time_ms: 31.484\n",
            "    sample_throughput: 1023.159\n",
            "    sample_time_ms: 9773.649\n",
            "    update_time_ms: 2.998\n",
            "  timestamp: 1624605997\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 110000\n",
            "  training_iteration: 11\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:1975</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         139.779</td><td style=\"text-align: right;\">110000</td><td style=\"text-align: right;\">-103.818</td><td style=\"text-align: right;\">                 -32</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -87.62 </td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-281.3  </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81 </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-307.72 </td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 120000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-26-50\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -32.0\n",
            "  episode_reward_mean: -105.89393939393939\n",
            "  episode_reward_min: -184.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 399\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.2789742052555084\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004217824898660183\n",
            "          model: {}\n",
            "          policy_loss: -0.012584006413817406\n",
            "          total_loss: 41.16709518432617\n",
            "          vf_explained_var: 0.7017930746078491\n",
            "          vf_loss: 41.1788330078125\n",
            "    num_agent_steps_sampled: 120000\n",
            "    num_agent_steps_trained: 120000\n",
            "    num_steps_sampled: 120000\n",
            "    num_steps_trained: 120000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.83157894736843\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1975\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04688088360969769\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.062177596706069725\n",
            "    mean_inference_ms: 0.7258417963136549\n",
            "    mean_raw_obs_processing_ms: 0.13162351815041395\n",
            "  time_since_restore: 26.06557822227478\n",
            "  time_this_iter_s: 12.991024255752563\n",
            "  time_total_s: 152.7696807384491\n",
            "  timers:\n",
            "    learn_throughput: 3182.336\n",
            "    learn_time_ms: 3142.345\n",
            "    load_throughput: 581327.087\n",
            "    load_time_ms: 17.202\n",
            "    sample_throughput: 1014.979\n",
            "    sample_time_ms: 9852.417\n",
            "    update_time_ms: 2.986\n",
            "  timestamp: 1624606010\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 120000\n",
            "  training_iteration: 12\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:1975</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         152.77 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-105.894</td><td style=\"text-align: right;\">                 -32</td><td style=\"text-align: right;\">                -184</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -87.62 </td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-281.3  </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81 </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-307.72 </td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 130000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-27-04\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -17.0\n",
            "  episode_reward_mean: -97.86\n",
            "  episode_reward_min: -184.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 433\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.27740421891212463\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0033147954382002354\n",
            "          model: {}\n",
            "          policy_loss: -0.010174863040447235\n",
            "          total_loss: 32.06338119506836\n",
            "          vf_explained_var: 0.75136798620224\n",
            "          vf_loss: 32.07322311401367\n",
            "    num_agent_steps_sampled: 130000\n",
            "    num_agent_steps_trained: 130000\n",
            "    num_steps_sampled: 130000\n",
            "    num_steps_trained: 130000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.49473684210527\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1975\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046979492733615305\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06223190105769426\n",
            "    mean_inference_ms: 0.7273874521544815\n",
            "    mean_raw_obs_processing_ms: 0.1317434957584818\n",
            "  time_since_restore: 39.30969977378845\n",
            "  time_this_iter_s: 13.244121551513672\n",
            "  time_total_s: 166.01380228996277\n",
            "  timers:\n",
            "    learn_throughput: 3106.358\n",
            "    learn_time_ms: 3219.204\n",
            "    load_throughput: 803655.338\n",
            "    load_time_ms: 12.443\n",
            "    sample_throughput: 1014.83\n",
            "    sample_time_ms: 9853.863\n",
            "    update_time_ms: 2.996\n",
            "  timestamp: 1624606024\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 130000\n",
            "  training_iteration: 13\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:1975</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         166.014</td><td style=\"text-align: right;\">130000</td><td style=\"text-align: right;\">  -97.86</td><td style=\"text-align: right;\">                 -17</td><td style=\"text-align: right;\">                -184</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 140000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-27-17\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -10.0\n",
            "  episode_reward_mean: -89.04\n",
            "  episode_reward_min: -184.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 466\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.25949448347091675\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004838019143790007\n",
            "          model: {}\n",
            "          policy_loss: -0.01126557681709528\n",
            "          total_loss: 35.45766830444336\n",
            "          vf_explained_var: 0.7342808842658997\n",
            "          vf_loss: 35.46869659423828\n",
            "    num_agent_steps_sampled: 140000\n",
            "    num_agent_steps_trained: 140000\n",
            "    num_steps_sampled: 140000\n",
            "    num_steps_trained: 140000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.683333333333344\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1975\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04708833114845335\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.062280104253114185\n",
            "    mean_inference_ms: 0.7296512046441309\n",
            "    mean_raw_obs_processing_ms: 0.13190615035883727\n",
            "  time_since_restore: 52.12295603752136\n",
            "  time_this_iter_s: 12.81325626373291\n",
            "  time_total_s: 178.82705855369568\n",
            "  timers:\n",
            "    learn_throughput: 3149.686\n",
            "    learn_time_ms: 3174.92\n",
            "    load_throughput: 990355.477\n",
            "    load_time_ms: 10.097\n",
            "    sample_throughput: 1017.359\n",
            "    sample_time_ms: 9829.371\n",
            "    update_time_ms: 2.943\n",
            "  timestamp: 1624606037\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 140000\n",
            "  training_iteration: 14\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:1975</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         178.827</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">  -89.04</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">                -184</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 150000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-27-29\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -10.0\n",
            "  episode_reward_mean: -79.38\n",
            "  episode_reward_min: -154.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 499\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.25349706411361694\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004782970063388348\n",
            "          model: {}\n",
            "          policy_loss: -0.011881797574460506\n",
            "          total_loss: 34.85804748535156\n",
            "          vf_explained_var: 0.7360741496086121\n",
            "          vf_loss: 34.86981201171875\n",
            "    num_agent_steps_sampled: 150000\n",
            "    num_agent_steps_trained: 150000\n",
            "    num_steps_sampled: 150000\n",
            "    num_steps_trained: 150000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.7611111111111\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1975\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04706307196872137\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06210189288885021\n",
            "    mean_inference_ms: 0.7291270746126353\n",
            "    mean_raw_obs_processing_ms: 0.13169030017616223\n",
            "  time_since_restore: 64.91431999206543\n",
            "  time_this_iter_s: 12.791363954544067\n",
            "  time_total_s: 191.61842250823975\n",
            "  timers:\n",
            "    learn_throughput: 3178.903\n",
            "    learn_time_ms: 3145.74\n",
            "    load_throughput: 1159038.129\n",
            "    load_time_ms: 8.628\n",
            "    sample_throughput: 1019.02\n",
            "    sample_time_ms: 9813.354\n",
            "    update_time_ms: 2.926\n",
            "  timestamp: 1624606049\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 150000\n",
            "  training_iteration: 15\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:1975</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         191.618</td><td style=\"text-align: right;\">150000</td><td style=\"text-align: right;\">  -79.38</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">                -154</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 160000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-27-42\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -10.0\n",
            "  episode_reward_mean: -76.69\n",
            "  episode_reward_min: -163.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 533\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.23657169938087463\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0052495114505290985\n",
            "          model: {}\n",
            "          policy_loss: -0.010619543492794037\n",
            "          total_loss: 34.38517379760742\n",
            "          vf_explained_var: 0.7404647469520569\n",
            "          vf_loss: 34.39572525024414\n",
            "    num_agent_steps_sampled: 160000\n",
            "    num_agent_steps_trained: 160000\n",
            "    num_steps_sampled: 160000\n",
            "    num_steps_trained: 160000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.04736842105264\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1975\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047031140499429254\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06194946241926243\n",
            "    mean_inference_ms: 0.7287591327665871\n",
            "    mean_raw_obs_processing_ms: 0.13159281159639571\n",
            "  time_since_restore: 77.88614082336426\n",
            "  time_this_iter_s: 12.971820831298828\n",
            "  time_total_s: 204.59024333953857\n",
            "  timers:\n",
            "    learn_throughput: 3194.903\n",
            "    learn_time_ms: 3129.986\n",
            "    load_throughput: 1275950.353\n",
            "    load_time_ms: 7.837\n",
            "    sample_throughput: 1017.411\n",
            "    sample_time_ms: 9828.869\n",
            "    update_time_ms: 2.803\n",
            "  timestamp: 1624606062\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 160000\n",
            "  training_iteration: 16\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:1975</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         204.59 </td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\">  -76.69</td><td style=\"text-align: right;\">                 -10</td><td style=\"text-align: right;\">                -163</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 170000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-27-55\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -11.0\n",
            "  episode_reward_mean: -69.46\n",
            "  episode_reward_min: -163.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 566\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.22934894263744354\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00505759147927165\n",
            "          model: {}\n",
            "          policy_loss: -0.009483314119279385\n",
            "          total_loss: 28.33096694946289\n",
            "          vf_explained_var: 0.7782337665557861\n",
            "          vf_loss: 28.34038543701172\n",
            "    num_agent_steps_sampled: 170000\n",
            "    num_agent_steps_trained: 170000\n",
            "    num_steps_sampled: 170000\n",
            "    num_steps_trained: 170000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.0611111111111\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1975\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04708830694201103\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06191085139099604\n",
            "    mean_inference_ms: 0.7291374961004213\n",
            "    mean_raw_obs_processing_ms: 0.13171352739951803\n",
            "  time_since_restore: 90.87955570220947\n",
            "  time_this_iter_s: 12.993414878845215\n",
            "  time_total_s: 217.5836582183838\n",
            "  timers:\n",
            "    learn_throughput: 3204.72\n",
            "    learn_time_ms: 3120.398\n",
            "    load_throughput: 1402998.466\n",
            "    load_time_ms: 7.128\n",
            "    sample_throughput: 1016.086\n",
            "    sample_time_ms: 9841.689\n",
            "    update_time_ms: 2.814\n",
            "  timestamp: 1624606075\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 170000\n",
            "  training_iteration: 17\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:1975</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         217.584</td><td style=\"text-align: right;\">170000</td><td style=\"text-align: right;\">  -69.46</td><td style=\"text-align: right;\">                 -11</td><td style=\"text-align: right;\">                -163</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 180000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-28-08\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1.0\n",
            "  episode_reward_mean: -61.71\n",
            "  episode_reward_min: -163.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 599\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.21950794756412506\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0035772453993558884\n",
            "          model: {}\n",
            "          policy_loss: -0.006957650184631348\n",
            "          total_loss: 31.0656795501709\n",
            "          vf_explained_var: 0.7575615048408508\n",
            "          vf_loss: 31.07259750366211\n",
            "    num_agent_steps_sampled: 180000\n",
            "    num_agent_steps_trained: 180000\n",
            "    num_steps_sampled: 180000\n",
            "    num_steps_trained: 180000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.94736842105263\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1975\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0471386483077555\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06190124035087896\n",
            "    mean_inference_ms: 0.7297838616739264\n",
            "    mean_raw_obs_processing_ms: 0.13190856715137797\n",
            "  time_since_restore: 103.71059727668762\n",
            "  time_this_iter_s: 12.83104157447815\n",
            "  time_total_s: 230.41469979286194\n",
            "  timers:\n",
            "    learn_throughput: 3219.146\n",
            "    learn_time_ms: 3106.414\n",
            "    load_throughput: 1521046.233\n",
            "    load_time_ms: 6.574\n",
            "    sample_throughput: 1016.499\n",
            "    sample_time_ms: 9837.692\n",
            "    update_time_ms: 2.814\n",
            "  timestamp: 1624606088\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 180000\n",
            "  training_iteration: 18\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:1975</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         230.415</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\">  -61.71</td><td style=\"text-align: right;\">                  -1</td><td style=\"text-align: right;\">                -163</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 190000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-28-21\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 18.0\n",
            "  episode_reward_mean: -48.65\n",
            "  episode_reward_min: -138.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 633\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.20799225568771362\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006544445641338825\n",
            "          model: {}\n",
            "          policy_loss: -0.008671785704791546\n",
            "          total_loss: 25.387096405029297\n",
            "          vf_explained_var: 0.7950728535652161\n",
            "          vf_loss: 25.39573097229004\n",
            "    num_agent_steps_sampled: 190000\n",
            "    num_agent_steps_trained: 190000\n",
            "    num_steps_sampled: 190000\n",
            "    num_steps_trained: 190000\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.96111111111111\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1975\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04721727268239376\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06190928685887687\n",
            "    mean_inference_ms: 0.7303230691229939\n",
            "    mean_raw_obs_processing_ms: 0.13214330900954896\n",
            "  time_since_restore: 116.7759325504303\n",
            "  time_this_iter_s: 13.065335273742676\n",
            "  time_total_s: 243.48003506660461\n",
            "  timers:\n",
            "    learn_throughput: 3222.229\n",
            "    learn_time_ms: 3103.442\n",
            "    load_throughput: 1625594.212\n",
            "    load_time_ms: 6.152\n",
            "    sample_throughput: 1014.954\n",
            "    sample_time_ms: 9852.664\n",
            "    update_time_ms: 2.97\n",
            "  timestamp: 1624606101\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 190000\n",
            "  training_iteration: 19\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:1975</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         243.48 </td><td style=\"text-align: right;\">190000</td><td style=\"text-align: right;\">  -48.65</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -138</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 200000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-28-34\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 18.0\n",
            "  episode_reward_mean: -44.21\n",
            "  episode_reward_min: -137.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 666\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.20133914053440094\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004135518334805965\n",
            "          model: {}\n",
            "          policy_loss: -0.010117597877979279\n",
            "          total_loss: 29.62833595275879\n",
            "          vf_explained_var: 0.767234206199646\n",
            "          vf_loss: 29.638427734375\n",
            "    num_agent_steps_sampled: 200000\n",
            "    num_agent_steps_trained: 200000\n",
            "    num_steps_sampled: 200000\n",
            "    num_steps_trained: 200000\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.95789473684209\n",
            "    ram_util_percent: 23.399999999999995\n",
            "  pid: 1975\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047238827264318266\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06184571685792667\n",
            "    mean_inference_ms: 0.7303476651646489\n",
            "    mean_raw_obs_processing_ms: 0.13219267629502318\n",
            "  time_since_restore: 129.55330061912537\n",
            "  time_this_iter_s: 12.777368068695068\n",
            "  time_total_s: 256.2574031352997\n",
            "  timers:\n",
            "    learn_throughput: 3230.079\n",
            "    learn_time_ms: 3095.9\n",
            "    load_throughput: 1714024.642\n",
            "    load_time_ms: 5.834\n",
            "    sample_throughput: 1016.158\n",
            "    sample_time_ms: 9840.987\n",
            "    update_time_ms: 2.942\n",
            "  timestamp: 1624606114\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 200000\n",
            "  training_iteration: 20\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m 2021-06-25 07:28:39,493\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m 2021-06-25 07:28:39,493\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         125.33 </td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -307.72</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">                -492</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2080)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2080)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2080)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2080)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2080)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2080)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2080)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2080)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2080)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2080)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m 2021-06-25 07:28:47,427\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m 2021-06-25 07:28:47,498\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00005_5_num_sgd_iter=10,sgd_minibatch_size=512,train_batch_size=20000_2021-06-25_07-06-36/tmpvq087amcrestore_from_object/checkpoint-10\n",
            "\u001b[2m\u001b[36m(pid=2079)\u001b[0m 2021-06-25 07:28:47,499\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 10, '_timesteps_total': None, '_time_total': 126.70410251617432, '_episodes_total': 333}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 112000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-29-03\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -32.0\n",
            "  episode_reward_mean: -107.9\n",
            "  episode_reward_min: -166.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 373\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.3163384795188904\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003866669489070773\n",
            "          model: {}\n",
            "          policy_loss: -0.006007173098623753\n",
            "          total_loss: 107.63541412353516\n",
            "          vf_explained_var: 0.46383729577064514\n",
            "          vf_loss: 107.64066314697266\n",
            "    num_agent_steps_sampled: 112000\n",
            "    num_agent_steps_trained: 112000\n",
            "    num_steps_sampled: 112000\n",
            "    num_steps_trained: 112000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.72173913043479\n",
            "    ram_util_percent: 23.395652173913035\n",
            "  pid: 2079\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04765161146035682\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06121196862846878\n",
            "    mean_inference_ms: 0.722190199588877\n",
            "    mean_raw_obs_processing_ms: 0.13392580100848528\n",
            "  time_since_restore: 15.623934745788574\n",
            "  time_this_iter_s: 15.623934745788574\n",
            "  time_total_s: 142.3280372619629\n",
            "  timers:\n",
            "    learn_throughput: 3167.216\n",
            "    learn_time_ms: 3788.816\n",
            "    load_throughput: 434868.222\n",
            "    load_time_ms: 27.595\n",
            "    sample_throughput: 1018.962\n",
            "    sample_time_ms: 11776.688\n",
            "    update_time_ms: 2.239\n",
            "  timestamp: 1624606143\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 112000\n",
            "  training_iteration: 11\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2079</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         142.328</td><td style=\"text-align: right;\">112000</td><td style=\"text-align: right;\"> -107.9 </td><td style=\"text-align: right;\">                 -32</td><td style=\"text-align: right;\">                -166</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 124000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-29-18\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -32.0\n",
            "  episode_reward_mean: -108.1875\n",
            "  episode_reward_min: -208.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 413\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.3145381212234497\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003838192205876112\n",
            "          model: {}\n",
            "          policy_loss: -0.004922294057905674\n",
            "          total_loss: 110.84732055664062\n",
            "          vf_explained_var: 0.46151068806648254\n",
            "          vf_loss: 110.85185241699219\n",
            "    num_agent_steps_sampled: 124000\n",
            "    num_agent_steps_trained: 124000\n",
            "    num_steps_sampled: 124000\n",
            "    num_steps_trained: 124000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.9409090909091\n",
            "    ram_util_percent: 23.39999999999999\n",
            "  pid: 2079\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04748715849468012\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06087411249343594\n",
            "    mean_inference_ms: 0.7202251316530301\n",
            "    mean_raw_obs_processing_ms: 0.13314423153654392\n",
            "  time_since_restore: 30.863990306854248\n",
            "  time_this_iter_s: 15.240055561065674\n",
            "  time_total_s: 157.56809282302856\n",
            "  timers:\n",
            "    learn_throughput: 3226.915\n",
            "    learn_time_ms: 3718.722\n",
            "    load_throughput: 781256.178\n",
            "    load_time_ms: 15.36\n",
            "    sample_throughput: 1027.673\n",
            "    sample_time_ms: 11676.871\n",
            "    update_time_ms: 2.543\n",
            "  timestamp: 1624606158\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 124000\n",
            "  training_iteration: 12\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2079</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         157.568</td><td style=\"text-align: right;\">124000</td><td style=\"text-align: right;\">-108.188</td><td style=\"text-align: right;\">                 -32</td><td style=\"text-align: right;\">                -208</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -87.62 </td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -44.21 </td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-281.3  </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81 </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 136000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-29-34\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -32.0\n",
            "  episode_reward_mean: -105.05\n",
            "  episode_reward_min: -208.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 453\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.30442139506340027\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0046865143813192844\n",
            "          model: {}\n",
            "          policy_loss: -0.004919514525681734\n",
            "          total_loss: 99.73453521728516\n",
            "          vf_explained_var: 0.4831465184688568\n",
            "          vf_loss: 99.73920440673828\n",
            "    num_agent_steps_sampled: 136000\n",
            "    num_agent_steps_trained: 136000\n",
            "    num_steps_sampled: 136000\n",
            "    num_steps_trained: 136000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.41818181818183\n",
            "    ram_util_percent: 23.39999999999999\n",
            "  pid: 2079\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047517786109839595\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06085225137753124\n",
            "    mean_inference_ms: 0.7227673764996588\n",
            "    mean_raw_obs_processing_ms: 0.13307082346052024\n",
            "  time_since_restore: 46.57909679412842\n",
            "  time_this_iter_s: 15.71510648727417\n",
            "  time_total_s: 173.28319931030273\n",
            "  timers:\n",
            "    learn_throughput: 3248.084\n",
            "    learn_time_ms: 3694.486\n",
            "    load_throughput: 1051445.57\n",
            "    load_time_ms: 11.413\n",
            "    sample_throughput: 1016.688\n",
            "    sample_time_ms: 11803.026\n",
            "    update_time_ms: 2.567\n",
            "  timestamp: 1624606174\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 136000\n",
            "  training_iteration: 13\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2079</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         173.283</td><td style=\"text-align: right;\">136000</td><td style=\"text-align: right;\"> -105.05</td><td style=\"text-align: right;\">                 -32</td><td style=\"text-align: right;\">                -208</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 148000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-29-49\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -31.0\n",
            "  episode_reward_mean: -101.72\n",
            "  episode_reward_min: -208.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 493\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.2817140221595764\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005714858416467905\n",
            "          model: {}\n",
            "          policy_loss: -0.0066103506833314896\n",
            "          total_loss: 100.61406707763672\n",
            "          vf_explained_var: 0.48000413179397583\n",
            "          vf_loss: 100.62054443359375\n",
            "    num_agent_steps_sampled: 148000\n",
            "    num_agent_steps_trained: 148000\n",
            "    num_steps_sampled: 148000\n",
            "    num_steps_trained: 148000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.218181818181826\n",
            "    ram_util_percent: 23.39999999999999\n",
            "  pid: 2079\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047566011304543264\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06088952350363334\n",
            "    mean_inference_ms: 0.7253009243028604\n",
            "    mean_raw_obs_processing_ms: 0.13305222356873803\n",
            "  time_since_restore: 61.98201608657837\n",
            "  time_this_iter_s: 15.402919292449951\n",
            "  time_total_s: 188.68611860275269\n",
            "  timers:\n",
            "    learn_throughput: 3254.037\n",
            "    learn_time_ms: 3687.728\n",
            "    load_throughput: 1265504.576\n",
            "    load_time_ms: 9.482\n",
            "    sample_throughput: 1018.422\n",
            "    sample_time_ms: 11782.932\n",
            "    update_time_ms: 2.59\n",
            "  timestamp: 1624606189\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 148000\n",
            "  training_iteration: 14\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2079</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         188.686</td><td style=\"text-align: right;\">148000</td><td style=\"text-align: right;\"> -101.72</td><td style=\"text-align: right;\">                 -31</td><td style=\"text-align: right;\">                -208</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 160000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-30-04\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -31.0\n",
            "  episode_reward_mean: -103.05\n",
            "  episode_reward_min: -213.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 533\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.2771603763103485\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0045773861929774284\n",
            "          model: {}\n",
            "          policy_loss: -0.0049094450660049915\n",
            "          total_loss: 111.94918060302734\n",
            "          vf_explained_var: 0.45275169610977173\n",
            "          vf_loss: 111.9539794921875\n",
            "    num_agent_steps_sampled: 160000\n",
            "    num_agent_steps_trained: 160000\n",
            "    num_steps_sampled: 160000\n",
            "    num_steps_trained: 160000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.20454545454547\n",
            "    ram_util_percent: 23.39999999999999\n",
            "  pid: 2079\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0475818292843052\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060931589559749776\n",
            "    mean_inference_ms: 0.7260271640521435\n",
            "    mean_raw_obs_processing_ms: 0.13305633870947214\n",
            "  time_since_restore: 77.28361082077026\n",
            "  time_this_iter_s: 15.301594734191895\n",
            "  time_total_s: 203.98771333694458\n",
            "  timers:\n",
            "    learn_throughput: 3260.692\n",
            "    learn_time_ms: 3680.201\n",
            "    load_throughput: 1457485.782\n",
            "    load_time_ms: 8.233\n",
            "    sample_throughput: 1020.926\n",
            "    sample_time_ms: 11754.031\n",
            "    update_time_ms: 2.572\n",
            "  timestamp: 1624606204\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 160000\n",
            "  training_iteration: 15\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2079</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         203.988</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\"> -103.05</td><td style=\"text-align: right;\">                 -31</td><td style=\"text-align: right;\">                -213</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 172000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-30-20\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -31.0\n",
            "  episode_reward_mean: -101.35\n",
            "  episode_reward_min: -213.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 573\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.2725399434566498\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004334769211709499\n",
            "          model: {}\n",
            "          policy_loss: -0.004290630109608173\n",
            "          total_loss: 90.79936218261719\n",
            "          vf_explained_var: 0.5057303309440613\n",
            "          vf_loss: 90.8035888671875\n",
            "    num_agent_steps_sampled: 172000\n",
            "    num_agent_steps_trained: 172000\n",
            "    num_steps_sampled: 172000\n",
            "    num_steps_trained: 172000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.84545454545455\n",
            "    ram_util_percent: 23.39999999999999\n",
            "  pid: 2079\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0475428389058799\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06088702190599459\n",
            "    mean_inference_ms: 0.7250207846143895\n",
            "    mean_raw_obs_processing_ms: 0.13292439966246034\n",
            "  time_since_restore: 92.6567771434784\n",
            "  time_this_iter_s: 15.37316632270813\n",
            "  time_total_s: 219.3608796596527\n",
            "  timers:\n",
            "    learn_throughput: 3268.945\n",
            "    learn_time_ms: 3670.909\n",
            "    load_throughput: 1627697.044\n",
            "    load_time_ms: 7.372\n",
            "    sample_throughput: 1021.203\n",
            "    sample_time_ms: 11750.841\n",
            "    update_time_ms: 2.612\n",
            "  timestamp: 1624606220\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 172000\n",
            "  training_iteration: 16\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2079</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         219.361</td><td style=\"text-align: right;\">172000</td><td style=\"text-align: right;\"> -101.35</td><td style=\"text-align: right;\">                 -31</td><td style=\"text-align: right;\">                -213</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 184000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-30-35\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -26.0\n",
            "  episode_reward_mean: -94.72\n",
            "  episode_reward_min: -193.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 613\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.26325488090515137\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004125627223402262\n",
            "          model: {}\n",
            "          policy_loss: -0.004671833012253046\n",
            "          total_loss: 95.46041107177734\n",
            "          vf_explained_var: 0.49332013726234436\n",
            "          vf_loss: 95.46507263183594\n",
            "    num_agent_steps_sampled: 184000\n",
            "    num_agent_steps_trained: 184000\n",
            "    num_steps_sampled: 184000\n",
            "    num_steps_trained: 184000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.109090909090924\n",
            "    ram_util_percent: 23.39999999999999\n",
            "  pid: 2079\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04755344210125679\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060875662051711694\n",
            "    mean_inference_ms: 0.7245962596148859\n",
            "    mean_raw_obs_processing_ms: 0.1329290659998896\n",
            "  time_since_restore: 108.07938241958618\n",
            "  time_this_iter_s: 15.422605276107788\n",
            "  time_total_s: 234.7834849357605\n",
            "  timers:\n",
            "    learn_throughput: 3272.976\n",
            "    learn_time_ms: 3666.389\n",
            "    load_throughput: 1775662.045\n",
            "    load_time_ms: 6.758\n",
            "    sample_throughput: 1020.969\n",
            "    sample_time_ms: 11753.539\n",
            "    update_time_ms: 2.782\n",
            "  timestamp: 1624606235\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 184000\n",
            "  training_iteration: 17\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2079</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         234.783</td><td style=\"text-align: right;\">184000</td><td style=\"text-align: right;\">  -94.72</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 196000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-30-51\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -26.0\n",
            "  episode_reward_mean: -89.49\n",
            "  episode_reward_min: -193.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 653\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0031250000465661287\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.266845703125\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004130963236093521\n",
            "          model: {}\n",
            "          policy_loss: -0.004160761833190918\n",
            "          total_loss: 101.9156494140625\n",
            "          vf_explained_var: 0.47834229469299316\n",
            "          vf_loss: 101.91979217529297\n",
            "    num_agent_steps_sampled: 196000\n",
            "    num_agent_steps_trained: 196000\n",
            "    num_steps_sampled: 196000\n",
            "    num_steps_trained: 196000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.81818181818182\n",
            "    ram_util_percent: 23.39999999999999\n",
            "  pid: 2079\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04754583910233981\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06083321683858532\n",
            "    mean_inference_ms: 0.7243817816990321\n",
            "    mean_raw_obs_processing_ms: 0.13286672524333792\n",
            "  time_since_restore: 123.35542964935303\n",
            "  time_this_iter_s: 15.276047229766846\n",
            "  time_total_s: 250.05953216552734\n",
            "  timers:\n",
            "    learn_throughput: 3278.697\n",
            "    learn_time_ms: 3659.99\n",
            "    load_throughput: 1906348.372\n",
            "    load_time_ms: 6.295\n",
            "    sample_throughput: 1022.114\n",
            "    sample_time_ms: 11740.378\n",
            "    update_time_ms: 2.728\n",
            "  timestamp: 1624606251\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 196000\n",
            "  training_iteration: 18\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m 2021-06-25 07:30:55,878\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m 2021-06-25 07:30:55,878\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2185)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2185)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2185)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2185)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2185)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2185)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2185)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2185)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2185)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2185)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.228</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m 2021-06-25 07:31:03,886\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m 2021-06-25 07:31:03,963\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00001_1_num_sgd_iter=20,sgd_minibatch_size=512,train_batch_size=20000_2021-06-25_06-57-04/tmpslr726n5restore_from_object/checkpoint-6\n",
            "\u001b[2m\u001b[36m(pid=2184)\u001b[0m 2021-06-25 07:31:03,963\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 6, '_timesteps_total': None, '_time_total': 135.227956533432, '_episodes_total': 400}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 140000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-31-26\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -80.0\n",
            "  episode_reward_mean: -165.43939393939394\n",
            "  episode_reward_min: -308.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 466\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.35633939504623413\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.009675310924649239\n",
            "          model: {}\n",
            "          policy_loss: -0.0155715923756361\n",
            "          total_loss: 110.21192932128906\n",
            "          vf_explained_var: 0.4331495463848114\n",
            "          vf_loss: 110.2255630493164\n",
            "    num_agent_steps_sampled: 140000\n",
            "    num_agent_steps_trained: 140000\n",
            "    num_steps_sampled: 140000\n",
            "    num_steps_trained: 140000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.027272727272724\n",
            "    ram_util_percent: 23.403030303030302\n",
            "  pid: 2184\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04715980526733552\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06206411938924538\n",
            "    mean_inference_ms: 0.7238427637028791\n",
            "    mean_raw_obs_processing_ms: 0.13485662186540948\n",
            "  time_since_restore: 23.011310815811157\n",
            "  time_this_iter_s: 23.011310815811157\n",
            "  time_total_s: 158.23926734924316\n",
            "  timers:\n",
            "    learn_throughput: 6024.375\n",
            "    learn_time_ms: 3319.847\n",
            "    load_throughput: 653817.4\n",
            "    load_time_ms: 30.59\n",
            "    sample_throughput: 1017.842\n",
            "    sample_time_ms: 19649.413\n",
            "    update_time_ms: 2.857\n",
            "  timestamp: 1624606286\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 140000\n",
            "  training_iteration: 7\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:2184</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         158.239</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">-165.439</td><td style=\"text-align: right;\">                 -80</td><td style=\"text-align: right;\">                -308</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -87.62 </td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -44.21 </td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> -89.49 </td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-281.3  </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81 </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\">-242.99 </td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 160000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-31-50\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -31.0\n",
            "  episode_reward_mean: -136.03\n",
            "  episode_reward_min: -308.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 533\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.3297766149044037\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.007255179807543755\n",
            "          model: {}\n",
            "          policy_loss: -0.013120661489665508\n",
            "          total_loss: 67.21910858154297\n",
            "          vf_explained_var: 0.5915749669075012\n",
            "          vf_loss: 67.23078918457031\n",
            "    num_agent_steps_sampled: 160000\n",
            "    num_agent_steps_trained: 160000\n",
            "    num_steps_sampled: 160000\n",
            "    num_steps_trained: 160000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.25151515151516\n",
            "    ram_util_percent: 23.466666666666665\n",
            "  pid: 2184\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047535149206452305\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06245960814480142\n",
            "    mean_inference_ms: 0.7279283111208394\n",
            "    mean_raw_obs_processing_ms: 0.13577850339346817\n",
            "  time_since_restore: 46.15026831626892\n",
            "  time_this_iter_s: 23.138957500457764\n",
            "  time_total_s: 181.37822484970093\n",
            "  timers:\n",
            "    learn_throughput: 6183.312\n",
            "    learn_time_ms: 3234.512\n",
            "    load_throughput: 1135944.317\n",
            "    load_time_ms: 17.606\n",
            "    sample_throughput: 1009.697\n",
            "    sample_time_ms: 19807.928\n",
            "    update_time_ms: 4.426\n",
            "  timestamp: 1624606310\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 160000\n",
            "  training_iteration: 8\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:2184</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         181.378</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\"> -136.03</td><td style=\"text-align: right;\">                 -31</td><td style=\"text-align: right;\">                -308</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 180000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-32-13\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -29.0\n",
            "  episode_reward_mean: -107.41\n",
            "  episode_reward_min: -201.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 600\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.29656505584716797\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006221689283847809\n",
            "          model: {}\n",
            "          policy_loss: -0.015213260427117348\n",
            "          total_loss: 48.532318115234375\n",
            "          vf_explained_var: 0.6707590818405151\n",
            "          vf_loss: 48.54628372192383\n",
            "    num_agent_steps_sampled: 180000\n",
            "    num_agent_steps_trained: 180000\n",
            "    num_steps_sampled: 180000\n",
            "    num_steps_trained: 180000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.13333333333333\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2184\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04760407596393037\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06242485231390546\n",
            "    mean_inference_ms: 0.7299967562710438\n",
            "    mean_raw_obs_processing_ms: 0.1359299523922865\n",
            "  time_since_restore: 69.03757190704346\n",
            "  time_this_iter_s: 22.887303590774536\n",
            "  time_total_s: 204.26552844047546\n",
            "  timers:\n",
            "    learn_throughput: 6247.115\n",
            "    learn_time_ms: 3201.478\n",
            "    load_throughput: 1516369.75\n",
            "    load_time_ms: 13.189\n",
            "    sample_throughput: 1010.917\n",
            "    sample_time_ms: 19784.022\n",
            "    update_time_ms: 3.98\n",
            "  timestamp: 1624606333\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 180000\n",
            "  training_iteration: 9\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:2184</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         204.266</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\"> -107.41</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -201</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 200000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-32-35\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -16.0\n",
            "  episode_reward_mean: -84.16\n",
            "  episode_reward_min: -183.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 666\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.26887765526771545\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006008352153003216\n",
            "          model: {}\n",
            "          policy_loss: -0.013141925446689129\n",
            "          total_loss: 35.31950759887695\n",
            "          vf_explained_var: 0.7365210056304932\n",
            "          vf_loss: 35.33145523071289\n",
            "    num_agent_steps_sampled: 200000\n",
            "    num_agent_steps_trained: 200000\n",
            "    num_steps_sampled: 200000\n",
            "    num_steps_trained: 200000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.39696969696969\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2184\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04746275341049827\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06215918506769568\n",
            "    mean_inference_ms: 0.728957408440117\n",
            "    mean_raw_obs_processing_ms: 0.1355136249580078\n",
            "  time_since_restore: 91.76287579536438\n",
            "  time_this_iter_s: 22.725303888320923\n",
            "  time_total_s: 226.9908323287964\n",
            "  timers:\n",
            "    learn_throughput: 6278.188\n",
            "    learn_time_ms: 3185.633\n",
            "    load_throughput: 1813008.278\n",
            "    load_time_ms: 11.031\n",
            "    sample_throughput: 1013.624\n",
            "    sample_time_ms: 19731.178\n",
            "    update_time_ms: 3.559\n",
            "  timestamp: 1624606355\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 200000\n",
            "  training_iteration: 10\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:2184</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         226.991</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -84.16</td><td style=\"text-align: right;\">                 -16</td><td style=\"text-align: right;\">                -183</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 220000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-32-58\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -11.0\n",
            "  episode_reward_mean: -65.65\n",
            "  episode_reward_min: -154.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 733\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.24573077261447906\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004903010092675686\n",
            "          model: {}\n",
            "          policy_loss: -0.012848054990172386\n",
            "          total_loss: 30.85257339477539\n",
            "          vf_explained_var: 0.7590559720993042\n",
            "          vf_loss: 30.864439010620117\n",
            "    num_agent_steps_sampled: 220000\n",
            "    num_agent_steps_trained: 220000\n",
            "    num_steps_sampled: 220000\n",
            "    num_steps_trained: 220000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.01875\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2184\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047426822916170834\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06200642128461507\n",
            "    mean_inference_ms: 0.7283966005974696\n",
            "    mean_raw_obs_processing_ms: 0.13536483747857797\n",
            "  time_since_restore: 114.65752458572388\n",
            "  time_this_iter_s: 22.894648790359497\n",
            "  time_total_s: 249.88548111915588\n",
            "  timers:\n",
            "    learn_throughput: 6292.126\n",
            "    learn_time_ms: 3178.576\n",
            "    load_throughput: 2074826.863\n",
            "    load_time_ms: 9.639\n",
            "    sample_throughput: 1013.851\n",
            "    sample_time_ms: 19726.759\n",
            "    update_time_ms: 3.303\n",
            "  timestamp: 1624606378\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 220000\n",
            "  training_iteration: 11\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 7 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:2184</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         249.885</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">  -65.65</td><td style=\"text-align: right;\">                 -11</td><td style=\"text-align: right;\">                -154</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 240000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-33-21\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 24.0\n",
            "  episode_reward_mean: -55.76\n",
            "  episode_reward_min: -151.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 800\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.23244930803775787\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00422082981094718\n",
            "          model: {}\n",
            "          policy_loss: -0.01173129491508007\n",
            "          total_loss: 28.252437591552734\n",
            "          vf_explained_var: 0.7740146517753601\n",
            "          vf_loss: 28.263744354248047\n",
            "    num_agent_steps_sampled: 240000\n",
            "    num_agent_steps_trained: 240000\n",
            "    num_steps_sampled: 240000\n",
            "    num_steps_trained: 240000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.18181818181818\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2184\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04736990864336608\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061804752682286426\n",
            "    mean_inference_ms: 0.7277655086637081\n",
            "    mean_raw_obs_processing_ms: 0.13513665499897023\n",
            "  time_since_restore: 137.38608741760254\n",
            "  time_this_iter_s: 22.728562831878662\n",
            "  time_total_s: 272.61404395103455\n",
            "  timers:\n",
            "    learn_throughput: 6286.69\n",
            "    learn_time_ms: 3181.324\n",
            "    load_throughput: 2290227.741\n",
            "    load_time_ms: 8.733\n",
            "    sample_throughput: 1015.639\n",
            "    sample_time_ms: 19692.036\n",
            "    update_time_ms: 3.148\n",
            "  timestamp: 1624606401\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 240000\n",
            "  training_iteration: 12\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m 2021-06-25 07:33:26,151\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m 2021-06-25 07:33:26,151\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2284)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2284)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2284)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2284)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2284)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2284)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2284)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2284)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2284)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2284)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         135.451</td><td style=\"text-align: right;\">120000</td><td style=\"text-align: right;\"> -242.99</td><td style=\"text-align: right;\">                 -94</td><td style=\"text-align: right;\">                -429</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m 2021-06-25 07:33:34,241\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m 2021-06-25 07:33:34,314\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00000_0_num_sgd_iter=20,sgd_minibatch_size=512,train_batch_size=20000_2021-06-25_06-57-04/tmpnlvaf5nzrestore_from_object/checkpoint-6\n",
            "\u001b[2m\u001b[36m(pid=2283)\u001b[0m 2021-06-25 07:33:34,314\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 6, '_timesteps_total': None, '_time_total': 135.45145726203918, '_episodes_total': 400}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 140000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-33-57\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -80.0\n",
            "  episode_reward_mean: -165.43939393939394\n",
            "  episode_reward_min: -308.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 466\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.35622867941856384\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.009669340215623379\n",
            "          model: {}\n",
            "          policy_loss: -0.01559100579470396\n",
            "          total_loss: 110.2119140625\n",
            "          vf_explained_var: 0.43314942717552185\n",
            "          vf_loss: 110.2255630493164\n",
            "    num_agent_steps_sampled: 140000\n",
            "    num_agent_steps_trained: 140000\n",
            "    num_steps_sampled: 140000\n",
            "    num_steps_trained: 140000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.997058823529414\n",
            "    ram_util_percent: 23.476470588235294\n",
            "  pid: 2283\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047709261093799575\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06193496258185748\n",
            "    mean_inference_ms: 0.7371327905772681\n",
            "    mean_raw_obs_processing_ms: 0.13480144264423743\n",
            "  time_since_restore: 23.315058708190918\n",
            "  time_this_iter_s: 23.315058708190918\n",
            "  time_total_s: 158.7665159702301\n",
            "  timers:\n",
            "    learn_throughput: 5967.654\n",
            "    learn_time_ms: 3351.401\n",
            "    load_throughput: 552172.722\n",
            "    load_time_ms: 36.221\n",
            "    sample_throughput: 1004.26\n",
            "    sample_time_ms: 19915.162\n",
            "    update_time_ms: 2.87\n",
            "  timestamp: 1624606437\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 140000\n",
            "  training_iteration: 7\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:2283</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         158.767</td><td style=\"text-align: right;\">140000</td><td style=\"text-align: right;\">-165.439</td><td style=\"text-align: right;\">                 -80</td><td style=\"text-align: right;\">                -308</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76 </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -44.21 </td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> -89.49 </td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-281.3  </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81 </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -87.62 </td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 160000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-34-20\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -31.0\n",
            "  episode_reward_mean: -136.22\n",
            "  episode_reward_min: -308.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 533\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.32879868149757385\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006993843242526054\n",
            "          model: {}\n",
            "          policy_loss: -0.013087136670947075\n",
            "          total_loss: 67.7788314819336\n",
            "          vf_explained_var: 0.5894916653633118\n",
            "          vf_loss: 67.79053497314453\n",
            "    num_agent_steps_sampled: 160000\n",
            "    num_agent_steps_trained: 160000\n",
            "    num_steps_sampled: 160000\n",
            "    num_steps_trained: 160000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.015625\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2283\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04728874332473867\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061297876790940516\n",
            "    mean_inference_ms: 0.7339110810359907\n",
            "    mean_raw_obs_processing_ms: 0.13320845646752286\n",
            "  time_since_restore: 46.10727310180664\n",
            "  time_this_iter_s: 22.792214393615723\n",
            "  time_total_s: 181.55873036384583\n",
            "  timers:\n",
            "    learn_throughput: 6064.08\n",
            "    learn_time_ms: 3298.109\n",
            "    load_throughput: 984347.336\n",
            "    load_time_ms: 20.318\n",
            "    sample_throughput: 1014.054\n",
            "    sample_time_ms: 19722.815\n",
            "    update_time_ms: 2.896\n",
            "  timestamp: 1624606460\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 160000\n",
            "  training_iteration: 8\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:2283</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         181.559</td><td style=\"text-align: right;\">160000</td><td style=\"text-align: right;\"> -136.22</td><td style=\"text-align: right;\">                 -31</td><td style=\"text-align: right;\">                -308</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 180000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-34-43\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -29.0\n",
            "  episode_reward_mean: -108.06\n",
            "  episode_reward_min: -201.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 600\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.2958180606365204\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005932517349720001\n",
            "          model: {}\n",
            "          policy_loss: -0.014749256893992424\n",
            "          total_loss: 48.959068298339844\n",
            "          vf_explained_var: 0.6683332324028015\n",
            "          vf_loss: 48.972625732421875\n",
            "    num_agent_steps_sampled: 180000\n",
            "    num_agent_steps_trained: 180000\n",
            "    num_steps_sampled: 180000\n",
            "    num_steps_trained: 180000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.10294117647059\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2283\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047196264410829955\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06109311434526539\n",
            "    mean_inference_ms: 0.7347695130540598\n",
            "    mean_raw_obs_processing_ms: 0.13268751242941276\n",
            "  time_since_restore: 69.34302830696106\n",
            "  time_this_iter_s: 23.23575520515442\n",
            "  time_total_s: 204.79448556900024\n",
            "  timers:\n",
            "    learn_throughput: 6100.422\n",
            "    learn_time_ms: 3278.462\n",
            "    load_throughput: 1263687.144\n",
            "    load_time_ms: 15.827\n",
            "    sample_throughput: 1009.699\n",
            "    sample_time_ms: 19807.874\n",
            "    update_time_ms: 2.955\n",
            "  timestamp: 1624606483\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 180000\n",
            "  training_iteration: 9\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:2283</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         204.794</td><td style=\"text-align: right;\">180000</td><td style=\"text-align: right;\"> -108.06</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -201</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 200000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-35-06\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -15.0\n",
            "  episode_reward_mean: -84.14\n",
            "  episode_reward_min: -183.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 666\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.2702684998512268\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005728780757635832\n",
            "          model: {}\n",
            "          policy_loss: -0.012354478240013123\n",
            "          total_loss: 35.25431823730469\n",
            "          vf_explained_var: 0.7361574172973633\n",
            "          vf_loss: 35.26552963256836\n",
            "    num_agent_steps_sampled: 200000\n",
            "    num_agent_steps_trained: 200000\n",
            "    num_steps_sampled: 200000\n",
            "    num_steps_trained: 200000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.18787878787878\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2283\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04729236088096913\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06114766443281247\n",
            "    mean_inference_ms: 0.7365452240416087\n",
            "    mean_raw_obs_processing_ms: 0.13293282428580272\n",
            "  time_since_restore: 92.4575412273407\n",
            "  time_this_iter_s: 23.11451292037964\n",
            "  time_total_s: 227.90899848937988\n",
            "  timers:\n",
            "    learn_throughput: 6129.442\n",
            "    learn_time_ms: 3262.94\n",
            "    load_throughput: 1536923.993\n",
            "    load_time_ms: 13.013\n",
            "    sample_throughput: 1008.758\n",
            "    sample_time_ms: 19826.366\n",
            "    update_time_ms: 2.983\n",
            "  timestamp: 1624606506\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 200000\n",
            "  training_iteration: 10\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:2283</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         227.909</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -84.14</td><td style=\"text-align: right;\">                 -15</td><td style=\"text-align: right;\">                -183</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 220000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-35-29\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -9.0\n",
            "  episode_reward_mean: -65.3\n",
            "  episode_reward_min: -177.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 733\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.24580924212932587\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0051273261196911335\n",
            "          model: {}\n",
            "          policy_loss: -0.012953677214682102\n",
            "          total_loss: 31.09867286682129\n",
            "          vf_explained_var: 0.7574815154075623\n",
            "          vf_loss: 31.1106014251709\n",
            "    num_agent_steps_sampled: 220000\n",
            "    num_agent_steps_trained: 220000\n",
            "    num_steps_sampled: 220000\n",
            "    num_steps_trained: 220000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.040625\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2283\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047313495114264977\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06106525629083734\n",
            "    mean_inference_ms: 0.7361509079948755\n",
            "    mean_raw_obs_processing_ms: 0.13288127540635955\n",
            "  time_since_restore: 115.36185693740845\n",
            "  time_this_iter_s: 22.90431571006775\n",
            "  time_total_s: 250.81331419944763\n",
            "  timers:\n",
            "    learn_throughput: 6149.49\n",
            "    learn_time_ms: 3252.302\n",
            "    load_throughput: 1779373.658\n",
            "    load_time_ms: 11.24\n",
            "    sample_throughput: 1010.274\n",
            "    sample_time_ms: 19796.615\n",
            "    update_time_ms: 2.888\n",
            "  timestamp: 1624606529\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 220000\n",
            "  training_iteration: 11\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:2283</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         250.813</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">  -65.3 </td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">                -177</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 240000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-35-52\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 31.0\n",
            "  episode_reward_mean: -55.85\n",
            "  episode_reward_min: -167.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 800\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.23263119161128998\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003800179809331894\n",
            "          model: {}\n",
            "          policy_loss: -0.01153645571321249\n",
            "          total_loss: 27.912904739379883\n",
            "          vf_explained_var: 0.7767757773399353\n",
            "          vf_loss: 27.923681259155273\n",
            "    num_agent_steps_sampled: 240000\n",
            "    num_agent_steps_trained: 240000\n",
            "    num_steps_sampled: 240000\n",
            "    num_steps_trained: 240000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.303030303030305\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2283\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04729197217122719\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06093816826693309\n",
            "    mean_inference_ms: 0.7353630747821359\n",
            "    mean_raw_obs_processing_ms: 0.13269583396461734\n",
            "  time_since_restore: 138.23362255096436\n",
            "  time_this_iter_s: 22.871765613555908\n",
            "  time_total_s: 273.68507981300354\n",
            "  timers:\n",
            "    learn_throughput: 6174.728\n",
            "    learn_time_ms: 3239.009\n",
            "    load_throughput: 2002548.282\n",
            "    load_time_ms: 9.987\n",
            "    sample_throughput: 1011.392\n",
            "    sample_time_ms: 19774.727\n",
            "    update_time_ms: 2.85\n",
            "  timestamp: 1624606552\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 240000\n",
            "  training_iteration: 12\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m 2021-06-25 07:35:57,177\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m 2021-06-25 07:35:57,177\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2425)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2425)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2425)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2425)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2425)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2425)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2425)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2425)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2425)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2425)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         242.876</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -87.62</td><td style=\"text-align: right;\">                  -6</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m 2021-06-25 07:36:05,708\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m 2021-06-25 07:36:05,781\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00002_2_num_sgd_iter=20,sgd_minibatch_size=2048,train_batch_size=10000_2021-06-25_06-59-31/tmpkgm3kh5lrestore_from_object/checkpoint-24\n",
            "\u001b[2m\u001b[36m(pid=2400)\u001b[0m 2021-06-25 07:36:05,781\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 24, '_timesteps_total': None, '_time_total': 242.8761625289917, '_episodes_total': 800}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 250000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-36-16\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -31.0\n",
            "  episode_reward_mean: -76.84848484848484\n",
            "  episode_reward_min: -173.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 833\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.13963595032691956\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0018149102106690407\n",
            "          model: {}\n",
            "          policy_loss: -0.0064972140826284885\n",
            "          total_loss: 30.37747573852539\n",
            "          vf_explained_var: 0.7618035078048706\n",
            "          vf_loss: 30.383609771728516\n",
            "    num_agent_steps_sampled: 250000\n",
            "    num_agent_steps_trained: 250000\n",
            "    num_steps_sampled: 250000\n",
            "    num_steps_trained: 250000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.38666666666666\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046532483783176856\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06016275070033279\n",
            "    mean_inference_ms: 0.7249872728104997\n",
            "    mean_raw_obs_processing_ms: 0.13151477306035264\n",
            "  time_since_restore: 10.410089015960693\n",
            "  time_this_iter_s: 10.410089015960693\n",
            "  time_total_s: 253.2862515449524\n",
            "  timers:\n",
            "    learn_throughput: 17872.508\n",
            "    learn_time_ms: 559.519\n",
            "    load_throughput: 359590.881\n",
            "    load_time_ms: 27.809\n",
            "    sample_throughput: 1021.261\n",
            "    sample_time_ms: 9791.812\n",
            "    update_time_ms: 2.829\n",
            "  timestamp: 1624606576\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 250000\n",
            "  training_iteration: 25\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         253.286</td><td style=\"text-align: right;\">250000</td><td style=\"text-align: right;\"> -76.8485</td><td style=\"text-align: right;\">                 -31</td><td style=\"text-align: right;\">                -173</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85  </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76  </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53  </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -44.21  </td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> -89.49  </td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81  </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-281.3   </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 260000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-36-26\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -8.0\n",
            "  episode_reward_mean: -80.18181818181819\n",
            "  episode_reward_min: -195.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 866\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.1391456127166748\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0015134075656533241\n",
            "          model: {}\n",
            "          policy_loss: -0.0037233331240713596\n",
            "          total_loss: 33.22745132446289\n",
            "          vf_explained_var: 0.7470126152038574\n",
            "          vf_loss: 33.231021881103516\n",
            "    num_agent_steps_sampled: 260000\n",
            "    num_agent_steps_trained: 260000\n",
            "    num_steps_sampled: 260000\n",
            "    num_steps_trained: 260000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.39999999999999\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04658515479573572\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060128517535751214\n",
            "    mean_inference_ms: 0.7253451201147099\n",
            "    mean_raw_obs_processing_ms: 0.1310549260298035\n",
            "  time_since_restore: 20.557647228240967\n",
            "  time_this_iter_s: 10.147558212280273\n",
            "  time_total_s: 263.43380975723267\n",
            "  timers:\n",
            "    learn_throughput: 21167.654\n",
            "    learn_time_ms: 472.419\n",
            "    load_throughput: 651810.687\n",
            "    load_time_ms: 15.342\n",
            "    sample_throughput: 1023.493\n",
            "    sample_time_ms: 9770.458\n",
            "    update_time_ms: 2.931\n",
            "  timestamp: 1624606586\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 260000\n",
            "  training_iteration: 26\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         263.434</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\"> -80.1818</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -195</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85  </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76  </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53  </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -44.21  </td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> -89.49  </td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81  </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-281.3   </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 270000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-36-36\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -8.0\n",
            "  episode_reward_mean: -76.85\n",
            "  episode_reward_min: -196.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 900\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.13255774974822998\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0024776258505880833\n",
            "          model: {}\n",
            "          policy_loss: 0.001820229459553957\n",
            "          total_loss: 30.460723876953125\n",
            "          vf_explained_var: 0.7587670683860779\n",
            "          vf_loss: 30.458782196044922\n",
            "    num_agent_steps_sampled: 270000\n",
            "    num_agent_steps_trained: 270000\n",
            "    num_steps_sampled: 270000\n",
            "    num_steps_trained: 270000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.75333333333333\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04680275007680466\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06036531524408064\n",
            "    mean_inference_ms: 0.7275081568184217\n",
            "    mean_raw_obs_processing_ms: 0.1313996382616426\n",
            "  time_since_restore: 30.97578716278076\n",
            "  time_this_iter_s: 10.418139934539795\n",
            "  time_total_s: 273.85194969177246\n",
            "  timers:\n",
            "    learn_throughput: 22651.735\n",
            "    learn_time_ms: 441.467\n",
            "    load_throughput: 871700.67\n",
            "    load_time_ms: 11.472\n",
            "    sample_throughput: 1014.684\n",
            "    sample_time_ms: 9855.289\n",
            "    update_time_ms: 2.919\n",
            "  timestamp: 1624606596\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 270000\n",
            "  training_iteration: 27\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         273.852</td><td style=\"text-align: right;\">270000</td><td style=\"text-align: right;\">  -76.85</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -196</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 280000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-36-47\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -8.0\n",
            "  episode_reward_mean: -72.17\n",
            "  episode_reward_min: -196.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 933\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.1273556649684906\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.002125740284100175\n",
            "          model: {}\n",
            "          policy_loss: -0.005678740330040455\n",
            "          total_loss: 25.02476692199707\n",
            "          vf_explained_var: 0.79246985912323\n",
            "          vf_loss: 25.030391693115234\n",
            "    num_agent_steps_sampled: 280000\n",
            "    num_agent_steps_trained: 280000\n",
            "    num_steps_sampled: 280000\n",
            "    num_steps_trained: 280000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.83571428571428\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04700930355576656\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060592274386298384\n",
            "    mean_inference_ms: 0.7295858555519183\n",
            "    mean_raw_obs_processing_ms: 0.13151075819202052\n",
            "  time_since_restore: 41.18080425262451\n",
            "  time_this_iter_s: 10.20501708984375\n",
            "  time_total_s: 284.0569667816162\n",
            "  timers:\n",
            "    learn_throughput: 23430.207\n",
            "    learn_time_ms: 426.799\n",
            "    load_throughput: 1070521.695\n",
            "    load_time_ms: 9.341\n",
            "    sample_throughput: 1015.868\n",
            "    sample_time_ms: 9843.794\n",
            "    update_time_ms: 2.98\n",
            "  timestamp: 1624606607\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 280000\n",
            "  training_iteration: 28\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         284.057</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  -72.17</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -196</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 290000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-36-57\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -9.0\n",
            "  episode_reward_mean: -69.57\n",
            "  episode_reward_min: -196.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 966\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.1294427514076233\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0018513877876102924\n",
            "          model: {}\n",
            "          policy_loss: -0.0063585760071873665\n",
            "          total_loss: 31.147064208984375\n",
            "          vf_explained_var: 0.7555639743804932\n",
            "          vf_loss: 31.153400421142578\n",
            "    num_agent_steps_sampled: 290000\n",
            "    num_agent_steps_trained: 290000\n",
            "    num_steps_sampled: 290000\n",
            "    num_steps_trained: 290000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.099999999999994\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047174880605322746\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06073836901279608\n",
            "    mean_inference_ms: 0.7305662728186075\n",
            "    mean_raw_obs_processing_ms: 0.13176770974451119\n",
            "  time_since_restore: 51.23064565658569\n",
            "  time_this_iter_s: 10.049841403961182\n",
            "  time_total_s: 294.1068081855774\n",
            "  timers:\n",
            "    learn_throughput: 23998.705\n",
            "    learn_time_ms: 416.689\n",
            "    load_throughput: 1235355.588\n",
            "    load_time_ms: 8.095\n",
            "    sample_throughput: 1019.658\n",
            "    sample_time_ms: 9807.208\n",
            "    update_time_ms: 2.977\n",
            "  timestamp: 1624606617\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 290000\n",
            "  training_iteration: 29\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         294.107</td><td style=\"text-align: right;\">290000</td><td style=\"text-align: right;\">  -69.57</td><td style=\"text-align: right;\">                  -9</td><td style=\"text-align: right;\">                -196</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 300000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-37-07\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -8.0\n",
            "  episode_reward_mean: -70.98\n",
            "  episode_reward_min: -180.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 1000\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.12353160977363586\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0014358980115503073\n",
            "          model: {}\n",
            "          policy_loss: -0.005845922511070967\n",
            "          total_loss: 31.2447566986084\n",
            "          vf_explained_var: 0.7534288167953491\n",
            "          vf_loss: 31.250593185424805\n",
            "    num_agent_steps_sampled: 300000\n",
            "    num_agent_steps_trained: 300000\n",
            "    num_steps_sampled: 300000\n",
            "    num_steps_trained: 300000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.9\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047117505757158396\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060618332743552245\n",
            "    mean_inference_ms: 0.731595135077088\n",
            "    mean_raw_obs_processing_ms: 0.13151433739785848\n",
            "  time_since_restore: 61.787155628204346\n",
            "  time_this_iter_s: 10.556509971618652\n",
            "  time_total_s: 304.66331815719604\n",
            "  timers:\n",
            "    learn_throughput: 24253.383\n",
            "    learn_time_ms: 412.314\n",
            "    load_throughput: 1377160.838\n",
            "    load_time_ms: 7.261\n",
            "    sample_throughput: 1013.725\n",
            "    sample_time_ms: 9864.608\n",
            "    update_time_ms: 2.92\n",
            "  timestamp: 1624606627\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 300000\n",
            "  training_iteration: 30\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         304.663</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -70.98</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -180</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 310000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-37-17\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -8.0\n",
            "  episode_reward_mean: -71.56\n",
            "  episode_reward_min: -180.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 1033\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0031250000465661287\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.12135932594537735\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0021090335212647915\n",
            "          model: {}\n",
            "          policy_loss: -0.005861436948180199\n",
            "          total_loss: 24.632434844970703\n",
            "          vf_explained_var: 0.7966188192367554\n",
            "          vf_loss: 24.638290405273438\n",
            "    num_agent_steps_sampled: 310000\n",
            "    num_agent_steps_trained: 310000\n",
            "    num_steps_sampled: 310000\n",
            "    num_steps_trained: 310000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.9\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04705491549767754\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060476665147665074\n",
            "    mean_inference_ms: 0.7321395408173622\n",
            "    mean_raw_obs_processing_ms: 0.13125934158614178\n",
            "  time_since_restore: 71.88285541534424\n",
            "  time_this_iter_s: 10.095699787139893\n",
            "  time_total_s: 314.75901794433594\n",
            "  timers:\n",
            "    learn_throughput: 24543.816\n",
            "    learn_time_ms: 407.435\n",
            "    load_throughput: 1506126.461\n",
            "    load_time_ms: 6.64\n",
            "    sample_throughput: 1016.087\n",
            "    sample_time_ms: 9841.675\n",
            "    update_time_ms: 2.878\n",
            "  timestamp: 1624606637\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 310000\n",
            "  training_iteration: 31\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         314.759</td><td style=\"text-align: right;\">310000</td><td style=\"text-align: right;\">  -71.56</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -180</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 320000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-37-27\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 2.0\n",
            "  episode_reward_mean: -66.84\n",
            "  episode_reward_min: -180.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 1066\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0015625000232830644\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.1168479472398758\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0036720677744597197\n",
            "          model: {}\n",
            "          policy_loss: -0.010630277916789055\n",
            "          total_loss: 27.088930130004883\n",
            "          vf_explained_var: 0.7775009274482727\n",
            "          vf_loss: 27.09955406188965\n",
            "    num_agent_steps_sampled: 320000\n",
            "    num_agent_steps_trained: 320000\n",
            "    num_steps_sampled: 320000\n",
            "    num_steps_trained: 320000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.626666666666665\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04692848508870294\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060376773834546656\n",
            "    mean_inference_ms: 0.7327644712059527\n",
            "    mean_raw_obs_processing_ms: 0.13100969055146952\n",
            "  time_since_restore: 81.83780765533447\n",
            "  time_this_iter_s: 9.954952239990234\n",
            "  time_total_s: 324.7139701843262\n",
            "  timers:\n",
            "    learn_throughput: 24842.671\n",
            "    learn_time_ms: 402.533\n",
            "    load_throughput: 1619164.515\n",
            "    load_time_ms: 6.176\n",
            "    sample_throughput: 1019.536\n",
            "    sample_time_ms: 9808.379\n",
            "    update_time_ms: 2.833\n",
            "  timestamp: 1624606647\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 320000\n",
            "  training_iteration: 32\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         324.714</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">  -66.84</td><td style=\"text-align: right;\">                   2</td><td style=\"text-align: right;\">                -180</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 330000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-37-37\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 18.0\n",
            "  episode_reward_mean: -55.64\n",
            "  episode_reward_min: -130.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 1100\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0007812500116415322\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.11113771796226501\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003372343024238944\n",
            "          model: {}\n",
            "          policy_loss: -0.010838380083441734\n",
            "          total_loss: 23.136363983154297\n",
            "          vf_explained_var: 0.8022021055221558\n",
            "          vf_loss: 23.147197723388672\n",
            "    num_agent_steps_sampled: 330000\n",
            "    num_agent_steps_trained: 330000\n",
            "    num_steps_sampled: 330000\n",
            "    num_steps_trained: 330000\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.45714285714285\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04680697464223272\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06027322401694155\n",
            "    mean_inference_ms: 0.7310898322773579\n",
            "    mean_raw_obs_processing_ms: 0.13074101285265502\n",
            "  time_since_restore: 91.95226573944092\n",
            "  time_this_iter_s: 10.114458084106445\n",
            "  time_total_s: 334.8284282684326\n",
            "  timers:\n",
            "    learn_throughput: 24948.6\n",
            "    learn_time_ms: 400.824\n",
            "    load_throughput: 1720732.259\n",
            "    load_time_ms: 5.811\n",
            "    sample_throughput: 1020.614\n",
            "    sample_time_ms: 9798.027\n",
            "    update_time_ms: 2.821\n",
            "  timestamp: 1624606657\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 330000\n",
            "  training_iteration: 33\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         334.828</td><td style=\"text-align: right;\">330000</td><td style=\"text-align: right;\">  -55.64</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -130</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 340000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-37-48\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 18.0\n",
            "  episode_reward_mean: -57.64\n",
            "  episode_reward_min: -137.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 1133\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0003906250058207661\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.11619820445775986\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0016131876036524773\n",
            "          model: {}\n",
            "          policy_loss: -0.006752708461135626\n",
            "          total_loss: 35.417964935302734\n",
            "          vf_explained_var: 0.7319352626800537\n",
            "          vf_loss: 35.42471694946289\n",
            "    num_agent_steps_sampled: 340000\n",
            "    num_agent_steps_trained: 340000\n",
            "    num_steps_sampled: 340000\n",
            "    num_steps_trained: 340000\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.00666666666666\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04672659022471329\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06019073658450081\n",
            "    mean_inference_ms: 0.7299826092062495\n",
            "    mean_raw_obs_processing_ms: 0.1305892841957516\n",
            "  time_since_restore: 102.13832759857178\n",
            "  time_this_iter_s: 10.18606185913086\n",
            "  time_total_s: 345.0144901275635\n",
            "  timers:\n",
            "    learn_throughput: 25019.549\n",
            "    learn_time_ms: 399.687\n",
            "    load_throughput: 1824983.139\n",
            "    load_time_ms: 5.48\n",
            "    sample_throughput: 1020.755\n",
            "    sample_time_ms: 9796.672\n",
            "    update_time_ms: 2.83\n",
            "  timestamp: 1624606668\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 340000\n",
            "  training_iteration: 34\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         345.014</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">  -57.64</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 350000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-37-58\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 18.0\n",
            "  episode_reward_mean: -54.07\n",
            "  episode_reward_min: -137.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 1166\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.00019531250291038305\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.11615869402885437\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0016592692118138075\n",
            "          model: {}\n",
            "          policy_loss: 0.0005344606470316648\n",
            "          total_loss: 28.695999145507812\n",
            "          vf_explained_var: 0.7656974792480469\n",
            "          vf_loss: 28.695466995239258\n",
            "    num_agent_steps_sampled: 350000\n",
            "    num_agent_steps_trained: 350000\n",
            "    num_steps_sampled: 350000\n",
            "    num_steps_trained: 350000\n",
            "  iterations_since_restore: 11\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.48571428571428\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04670940478224221\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06013935861573734\n",
            "    mean_inference_ms: 0.729348734294077\n",
            "    mean_raw_obs_processing_ms: 0.13052932588455055\n",
            "  time_since_restore: 112.20551419258118\n",
            "  time_this_iter_s: 10.0671865940094\n",
            "  time_total_s: 355.0816767215729\n",
            "  timers:\n",
            "    learn_throughput: 26072.231\n",
            "    learn_time_ms: 383.55\n",
            "    load_throughput: 3377273.898\n",
            "    load_time_ms: 2.961\n",
            "    sample_throughput: 1022.159\n",
            "    sample_time_ms: 9783.209\n",
            "    update_time_ms: 2.824\n",
            "  timestamp: 1624606678\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 350000\n",
            "  training_iteration: 35\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 8 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>172.28.0.2:2400</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         355.082</td><td style=\"text-align: right;\">350000</td><td style=\"text-align: right;\">  -54.07</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00002:\n",
            "  agent_timesteps_total: 360000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-38-08\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 7.0\n",
            "  episode_reward_mean: -55.74\n",
            "  episode_reward_min: -137.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 1200\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 9.765625145519152e-05\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.11244623363018036\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0027910054195672274\n",
            "          model: {}\n",
            "          policy_loss: -0.0068937670439481735\n",
            "          total_loss: 28.04749870300293\n",
            "          vf_explained_var: 0.7671847343444824\n",
            "          vf_loss: 28.054393768310547\n",
            "    num_agent_steps_sampled: 360000\n",
            "    num_agent_steps_trained: 360000\n",
            "    num_steps_sampled: 360000\n",
            "    num_steps_trained: 360000\n",
            "  iterations_since_restore: 12\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.57142857142858\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2400\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046684937647509306\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06006995169296681\n",
            "    mean_inference_ms: 0.7286419758644894\n",
            "    mean_raw_obs_processing_ms: 0.13041642536878004\n",
            "  time_since_restore: 122.22810935974121\n",
            "  time_this_iter_s: 10.022595167160034\n",
            "  time_total_s: 365.1042718887329\n",
            "  timers:\n",
            "    learn_throughput: 26057.43\n",
            "    learn_time_ms: 383.768\n",
            "    load_throughput: 3403334.929\n",
            "    load_time_ms: 2.938\n",
            "    sample_throughput: 1023.474\n",
            "    sample_time_ms: 9770.641\n",
            "    update_time_ms: 2.777\n",
            "  timestamp: 1624606688\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 360000\n",
            "  training_iteration: 36\n",
            "  trial_id: 8c324_00002\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m 2021-06-25 07:38:13,496\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m 2021-06-25 07:38:13,496\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2501)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2501)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2501)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2501)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2501)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2501)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2501)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2501)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2501)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2501)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.8/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         243.01 </td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -281.3 </td><td style=\"text-align: right;\">                 -96</td><td style=\"text-align: right;\">                -523</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m 2021-06-25 07:38:21,547\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m 2021-06-25 07:38:21,624\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00006_6_num_sgd_iter=30,sgd_minibatch_size=128,train_batch_size=20000_2021-06-25_07-09-08/tmp787whu2grestore_from_object/checkpoint-27\n",
            "\u001b[2m\u001b[36m(pid=2500)\u001b[0m 2021-06-25 07:38:21,624\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 27, '_timesteps_total': None, '_time_total': 243.00979471206665, '_episodes_total': 800}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 248000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-38-29\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -178.0\n",
            "  episode_reward_mean: -323.9230769230769\n",
            "  episode_reward_min: -589.0\n",
            "  episodes_this_iter: 26\n",
            "  episodes_total: 826\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24603581428527832\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0030827687587589025\n",
            "          model: {}\n",
            "          policy_loss: 0.0042757438495755196\n",
            "          total_loss: 7558387990528.0\n",
            "          vf_explained_var: 2.6673078536987305e-06\n",
            "          vf_loss: 7558387990528.0\n",
            "    num_agent_steps_sampled: 248000\n",
            "    num_agent_steps_trained: 248000\n",
            "    num_steps_sampled: 248000\n",
            "    num_steps_trained: 248000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.324999999999996\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04610152948410746\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0607177713873565\n",
            "    mean_inference_ms: 0.7124071403706524\n",
            "    mean_raw_obs_processing_ms: 0.12840641809841824\n",
            "  time_since_restore: 8.273427486419678\n",
            "  time_this_iter_s: 8.273427486419678\n",
            "  time_total_s: 251.28322219848633\n",
            "  timers:\n",
            "    learn_throughput: 15783.198\n",
            "    learn_time_ms: 506.868\n",
            "    load_throughput: 299927.884\n",
            "    load_time_ms: 26.673\n",
            "    sample_throughput: 1037.575\n",
            "    sample_time_ms: 7710.286\n",
            "    update_time_ms: 2.325\n",
            "  timestamp: 1624606709\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 248000\n",
            "  training_iteration: 28\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         251.283</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\">-323.923</td><td style=\"text-align: right;\">                -178</td><td style=\"text-align: right;\">                -589</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85 </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76 </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -55.74 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -44.21 </td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81 </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> -89.49 </td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 256000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-38-37\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -122.0\n",
            "  episode_reward_mean: -321.64150943396226\n",
            "  episode_reward_min: -589.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 853\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.25397413969039917\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0030501126311719418\n",
            "          model: {}\n",
            "          policy_loss: -0.012168316170573235\n",
            "          total_loss: 7558077087744.0\n",
            "          vf_explained_var: 1.2069940567016602e-06\n",
            "          vf_loss: 7558077087744.0\n",
            "    num_agent_steps_sampled: 256000\n",
            "    num_agent_steps_trained: 256000\n",
            "    num_steps_sampled: 256000\n",
            "    num_steps_trained: 256000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.033333333333324\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046054857134999794\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060867844270243054\n",
            "    mean_inference_ms: 0.7108815500810688\n",
            "    mean_raw_obs_processing_ms: 0.1284277522869714\n",
            "  time_since_restore: 16.211228370666504\n",
            "  time_this_iter_s: 7.937800884246826\n",
            "  time_total_s: 259.22102308273315\n",
            "  timers:\n",
            "    learn_throughput: 19919.922\n",
            "    learn_time_ms: 401.608\n",
            "    load_throughput: 546974.627\n",
            "    load_time_ms: 14.626\n",
            "    sample_throughput: 1043.029\n",
            "    sample_time_ms: 7669.966\n",
            "    update_time_ms: 2.378\n",
            "  timestamp: 1624606717\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 256000\n",
            "  training_iteration: 29\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         259.221</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">-321.642</td><td style=\"text-align: right;\">                -122</td><td style=\"text-align: right;\">                -589</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85 </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76 </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -55.74 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -44.21 </td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81 </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> -89.49 </td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 264000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-38-46\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -122.0\n",
            "  episode_reward_mean: -329.325\n",
            "  episode_reward_min: -589.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 880\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.2532358169555664\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003296754788607359\n",
            "          model: {}\n",
            "          policy_loss: -0.015973877161741257\n",
            "          total_loss: 16155378974720.0\n",
            "          vf_explained_var: 1.296401023864746e-06\n",
            "          vf_loss: 16155378974720.0\n",
            "    num_agent_steps_sampled: 264000\n",
            "    num_agent_steps_trained: 264000\n",
            "    num_steps_sampled: 264000\n",
            "    num_steps_trained: 264000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.22499999999999\n",
            "    ram_util_percent: 23.59166666666667\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04640282946960299\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061354942894368346\n",
            "    mean_inference_ms: 0.7144498204905503\n",
            "    mean_raw_obs_processing_ms: 0.12942825667729285\n",
            "  time_since_restore: 24.611531972885132\n",
            "  time_this_iter_s: 8.400303602218628\n",
            "  time_total_s: 267.6213266849518\n",
            "  timers:\n",
            "    learn_throughput: 21728.284\n",
            "    learn_time_ms: 368.184\n",
            "    load_throughput: 750692.022\n",
            "    load_time_ms: 10.657\n",
            "    sample_throughput: 1024.619\n",
            "    sample_time_ms: 7807.781\n",
            "    update_time_ms: 3.703\n",
            "  timestamp: 1624606726\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 264000\n",
            "  training_iteration: 30\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         267.621</td><td style=\"text-align: right;\">264000</td><td style=\"text-align: right;\">-329.325</td><td style=\"text-align: right;\">                -122</td><td style=\"text-align: right;\">                -589</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85 </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76 </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -55.74 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -44.21 </td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81 </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\"> -89.49 </td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 272000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-38-54\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -122.0\n",
            "  episode_reward_mean: -321.5\n",
            "  episode_reward_min: -589.0\n",
            "  episodes_this_iter: 26\n",
            "  episodes_total: 906\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24545469880104065\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004658743739128113\n",
            "          model: {}\n",
            "          policy_loss: -0.00553049286827445\n",
            "          total_loss: 10857616506880.0\n",
            "          vf_explained_var: 1.2069940567016602e-06\n",
            "          vf_loss: 10857616506880.0\n",
            "    num_agent_steps_sampled: 272000\n",
            "    num_agent_steps_trained: 272000\n",
            "    num_steps_sampled: 272000\n",
            "    num_steps_trained: 272000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.22727272727272\n",
            "    ram_util_percent: 23.518181818181816\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04662812195997475\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06168129140736602\n",
            "    mean_inference_ms: 0.7162861982293905\n",
            "    mean_raw_obs_processing_ms: 0.13008463649774915\n",
            "  time_since_restore: 32.72018051147461\n",
            "  time_this_iter_s: 8.108648538589478\n",
            "  time_total_s: 275.72997522354126\n",
            "  timers:\n",
            "    learn_throughput: 22820.086\n",
            "    learn_time_ms: 350.568\n",
            "    load_throughput: 931879.885\n",
            "    load_time_ms: 8.585\n",
            "    sample_throughput: 1024.893\n",
            "    sample_time_ms: 7805.689\n",
            "    update_time_ms: 3.425\n",
            "  timestamp: 1624606734\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 272000\n",
            "  training_iteration: 31\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         275.73 </td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\"> -321.5 </td><td style=\"text-align: right;\">                -122</td><td style=\"text-align: right;\">                -589</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 280000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-39-02\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -148.0\n",
            "  episode_reward_mean: -332.28\n",
            "  episode_reward_min: -587.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 933\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24302060902118683\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0044419365003705025\n",
            "          model: {}\n",
            "          policy_loss: -0.002400647848844528\n",
            "          total_loss: 12052877803520.0\n",
            "          vf_explained_var: 1.9818544387817383e-06\n",
            "          vf_loss: 12052877803520.0\n",
            "    num_agent_steps_sampled: 280000\n",
            "    num_agent_steps_trained: 280000\n",
            "    num_steps_sampled: 280000\n",
            "    num_steps_trained: 280000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.08333333333332\n",
            "    ram_util_percent: 23.59166666666667\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046967805905035014\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.062171123751941906\n",
            "    mean_inference_ms: 0.7194061844186078\n",
            "    mean_raw_obs_processing_ms: 0.13106593144840978\n",
            "  time_since_restore: 40.93201541900635\n",
            "  time_this_iter_s: 8.211834907531738\n",
            "  time_total_s: 283.941810131073\n",
            "  timers:\n",
            "    learn_throughput: 23557.61\n",
            "    learn_time_ms: 339.593\n",
            "    load_throughput: 1090938.506\n",
            "    load_time_ms: 7.333\n",
            "    sample_throughput: 1022.294\n",
            "    sample_time_ms: 7825.535\n",
            "    update_time_ms: 3.255\n",
            "  timestamp: 1624606742\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 280000\n",
            "  training_iteration: 32\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">         283.942</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\"> -332.28</td><td style=\"text-align: right;\">                -148</td><td style=\"text-align: right;\">                -587</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 288000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-39-10\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -148.0\n",
            "  episode_reward_mean: -328.46\n",
            "  episode_reward_min: -530.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 960\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.24308818578720093\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004132123664021492\n",
            "          model: {}\n",
            "          policy_loss: -0.007561863865703344\n",
            "          total_loss: 17899295080448.0\n",
            "          vf_explained_var: 5.662441253662109e-07\n",
            "          vf_loss: 17899295080448.0\n",
            "    num_agent_steps_sampled: 288000\n",
            "    num_agent_steps_trained: 288000\n",
            "    num_steps_sampled: 288000\n",
            "    num_steps_trained: 288000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.275\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047249599004557934\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06249543041943964\n",
            "    mean_inference_ms: 0.7221608198455648\n",
            "    mean_raw_obs_processing_ms: 0.13199695432296982\n",
            "  time_since_restore: 49.0708167552948\n",
            "  time_this_iter_s: 8.138801336288452\n",
            "  time_total_s: 292.08061146736145\n",
            "  timers:\n",
            "    learn_throughput: 23954.023\n",
            "    learn_time_ms: 333.973\n",
            "    load_throughput: 1229467.863\n",
            "    load_time_ms: 6.507\n",
            "    sample_throughput: 1022.381\n",
            "    sample_time_ms: 7824.872\n",
            "    update_time_ms: 3.168\n",
            "  timestamp: 1624606750\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 288000\n",
            "  training_iteration: 33\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">         292.081</td><td style=\"text-align: right;\">288000</td><td style=\"text-align: right;\"> -328.46</td><td style=\"text-align: right;\">                -148</td><td style=\"text-align: right;\">                -530</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 296000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-39-19\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -148.0\n",
            "  episode_reward_mean: -331.59\n",
            "  episode_reward_min: -581.0\n",
            "  episodes_this_iter: 26\n",
            "  episodes_total: 986\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0031250000465661287\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.23755212128162384\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0032711492385715246\n",
            "          model: {}\n",
            "          policy_loss: -0.0027957013808190823\n",
            "          total_loss: 18931160973312.0\n",
            "          vf_explained_var: 1.7881393432617188e-07\n",
            "          vf_loss: 18931160973312.0\n",
            "    num_agent_steps_sampled: 296000\n",
            "    num_agent_steps_trained: 296000\n",
            "    num_steps_sampled: 296000\n",
            "    num_steps_trained: 296000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.45833333333332\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04734222223770519\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06258166228243785\n",
            "    mean_inference_ms: 0.7229049065224841\n",
            "    mean_raw_obs_processing_ms: 0.13242264272020526\n",
            "  time_since_restore: 57.33144497871399\n",
            "  time_this_iter_s: 8.26062822341919\n",
            "  time_total_s: 300.34123969078064\n",
            "  timers:\n",
            "    learn_throughput: 24295.385\n",
            "    learn_time_ms: 329.281\n",
            "    load_throughput: 1338536.461\n",
            "    load_time_ms: 5.977\n",
            "    sample_throughput: 1020.106\n",
            "    sample_time_ms: 7842.321\n",
            "    update_time_ms: 3.096\n",
            "  timestamp: 1624606759\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 296000\n",
            "  training_iteration: 34\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    34</td><td style=\"text-align: right;\">         300.341</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\"> -331.59</td><td style=\"text-align: right;\">                -148</td><td style=\"text-align: right;\">                -581</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 304000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-39-27\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -172.0\n",
            "  episode_reward_mean: -351.75\n",
            "  episode_reward_min: -612.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 1013\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0015625000232830644\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.2519265413284302\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003724359441548586\n",
            "          model: {}\n",
            "          policy_loss: -0.00370788830332458\n",
            "          total_loss: 21666384052224.0\n",
            "          vf_explained_var: 1.2814998626708984e-06\n",
            "          vf_loss: 21666384052224.0\n",
            "    num_agent_steps_sampled: 304000\n",
            "    num_agent_steps_trained: 304000\n",
            "    num_steps_sampled: 304000\n",
            "    num_steps_trained: 304000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.1090909090909\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0474002566032461\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06262466907728997\n",
            "    mean_inference_ms: 0.7237477205262063\n",
            "    mean_raw_obs_processing_ms: 0.13277582757362613\n",
            "  time_since_restore: 65.52787661552429\n",
            "  time_this_iter_s: 8.196431636810303\n",
            "  time_total_s: 308.53767132759094\n",
            "  timers:\n",
            "    learn_throughput: 24437.647\n",
            "    learn_time_ms: 327.364\n",
            "    load_throughput: 1443356.576\n",
            "    load_time_ms: 5.543\n",
            "    sample_throughput: 1019.658\n",
            "    sample_time_ms: 7845.769\n",
            "    update_time_ms: 3.115\n",
            "  timestamp: 1624606767\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 304000\n",
            "  training_iteration: 35\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         308.538</td><td style=\"text-align: right;\">304000</td><td style=\"text-align: right;\"> -351.75</td><td style=\"text-align: right;\">                -172</td><td style=\"text-align: right;\">                -612</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 312000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-39-35\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -180.0\n",
            "  episode_reward_mean: -390.48\n",
            "  episode_reward_min: -797.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 1040\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0007812500116415322\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.2535555958747864\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0030607995577156544\n",
            "          model: {}\n",
            "          policy_loss: -0.002031183335930109\n",
            "          total_loss: 16781013942272.0\n",
            "          vf_explained_var: 1.1920928955078125e-06\n",
            "          vf_loss: 16781013942272.0\n",
            "    num_agent_steps_sampled: 312000\n",
            "    num_agent_steps_trained: 312000\n",
            "    num_steps_sampled: 312000\n",
            "    num_steps_trained: 312000\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.24166666666667\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04741917793430831\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0626229243350082\n",
            "    mean_inference_ms: 0.7240558102728076\n",
            "    mean_raw_obs_processing_ms: 0.1329640046316053\n",
            "  time_since_restore: 73.63733148574829\n",
            "  time_this_iter_s: 8.109454870223999\n",
            "  time_total_s: 316.64712619781494\n",
            "  timers:\n",
            "    learn_throughput: 24565.658\n",
            "    learn_time_ms: 325.658\n",
            "    load_throughput: 1536703.447\n",
            "    load_time_ms: 5.206\n",
            "    sample_throughput: 1020.544\n",
            "    sample_time_ms: 7838.955\n",
            "    update_time_ms: 3.073\n",
            "  timestamp: 1624606775\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 312000\n",
            "  training_iteration: 36\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         316.647</td><td style=\"text-align: right;\">312000</td><td style=\"text-align: right;\"> -390.48</td><td style=\"text-align: right;\">                -180</td><td style=\"text-align: right;\">                -797</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 320000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-39-43\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -166.0\n",
            "  episode_reward_mean: -404.38\n",
            "  episode_reward_min: -797.0\n",
            "  episodes_this_iter: 26\n",
            "  episodes_total: 1066\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0003906250058207661\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.23516197502613068\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0049521648325026035\n",
            "          model: {}\n",
            "          policy_loss: -0.011434557847678661\n",
            "          total_loss: 21285690146816.0\n",
            "          vf_explained_var: -2.2351741790771484e-07\n",
            "          vf_loss: 21285690146816.0\n",
            "    num_agent_steps_sampled: 320000\n",
            "    num_agent_steps_trained: 320000\n",
            "    num_steps_sampled: 320000\n",
            "    num_steps_trained: 320000\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.86666666666665\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047434646969631726\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06263662263853799\n",
            "    mean_inference_ms: 0.7247598743082782\n",
            "    mean_raw_obs_processing_ms: 0.1330163969894435\n",
            "  time_since_restore: 81.94068741798401\n",
            "  time_this_iter_s: 8.303355932235718\n",
            "  time_total_s: 324.95048213005066\n",
            "  timers:\n",
            "    learn_throughput: 24637.542\n",
            "    learn_time_ms: 324.708\n",
            "    load_throughput: 1626266.527\n",
            "    load_time_ms: 4.919\n",
            "    sample_throughput: 1018.773\n",
            "    sample_time_ms: 7852.584\n",
            "    update_time_ms: 3.035\n",
            "  timestamp: 1624606783\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 320000\n",
            "  training_iteration: 37\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         324.95 </td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\"> -404.38</td><td style=\"text-align: right;\">                -166</td><td style=\"text-align: right;\">                -797</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 328000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-39-52\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -135.0\n",
            "  episode_reward_mean: -408.76\n",
            "  episode_reward_min: -797.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 1093\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.00019531250291038305\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.23335197567939758\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0069267963990569115\n",
            "          model: {}\n",
            "          policy_loss: -0.01365822646766901\n",
            "          total_loss: 22569293971456.0\n",
            "          vf_explained_var: -2.384185791015625e-07\n",
            "          vf_loss: 22569293971456.0\n",
            "    num_agent_steps_sampled: 328000\n",
            "    num_agent_steps_trained: 328000\n",
            "    num_steps_sampled: 328000\n",
            "    num_steps_trained: 328000\n",
            "  iterations_since_restore: 11\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.199999999999996\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047422048925083754\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06263986103257511\n",
            "    mean_inference_ms: 0.7252571709507464\n",
            "    mean_raw_obs_processing_ms: 0.13298723968806286\n",
            "  time_since_restore: 90.13629746437073\n",
            "  time_this_iter_s: 8.195610046386719\n",
            "  time_total_s: 333.1460921764374\n",
            "  timers:\n",
            "    learn_throughput: 26395.419\n",
            "    learn_time_ms: 303.083\n",
            "    load_throughput: 3211780.269\n",
            "    load_time_ms: 2.491\n",
            "    sample_throughput: 1016.411\n",
            "    sample_time_ms: 7870.833\n",
            "    update_time_ms: 3.07\n",
            "  timestamp: 1624606792\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 328000\n",
            "  training_iteration: 38\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    38</td><td style=\"text-align: right;\">         333.146</td><td style=\"text-align: right;\">328000</td><td style=\"text-align: right;\"> -408.76</td><td style=\"text-align: right;\">                -135</td><td style=\"text-align: right;\">                -797</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 336000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-40-00\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -135.0\n",
            "  episode_reward_mean: -396.12\n",
            "  episode_reward_min: -797.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 1120\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.00019531250291038305\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.23466116189956665\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005699086003005505\n",
            "          model: {}\n",
            "          policy_loss: -0.009571928530931473\n",
            "          total_loss: 16395219763200.0\n",
            "          vf_explained_var: 1.043081283569336e-07\n",
            "          vf_loss: 16395219763200.0\n",
            "    num_agent_steps_sampled: 336000\n",
            "    num_agent_steps_trained: 336000\n",
            "    num_steps_sampled: 336000\n",
            "    num_steps_trained: 336000\n",
            "  iterations_since_restore: 12\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.881818181818176\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04740445510379935\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06263715615241044\n",
            "    mean_inference_ms: 0.7254082493336889\n",
            "    mean_raw_obs_processing_ms: 0.1329835575211195\n",
            "  time_since_restore: 98.21119832992554\n",
            "  time_this_iter_s: 8.07490086555481\n",
            "  time_total_s: 341.2209930419922\n",
            "  timers:\n",
            "    learn_throughput: 26194.232\n",
            "    learn_time_ms: 305.411\n",
            "    load_throughput: 3236033.562\n",
            "    load_time_ms: 2.472\n",
            "    sample_throughput: 1014.945\n",
            "    sample_time_ms: 7882.197\n",
            "    update_time_ms: 3.095\n",
            "  timestamp: 1624606800\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 336000\n",
            "  training_iteration: 39\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         341.221</td><td style=\"text-align: right;\">336000</td><td style=\"text-align: right;\"> -396.12</td><td style=\"text-align: right;\">                -135</td><td style=\"text-align: right;\">                -797</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 344000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-40-08\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -135.0\n",
            "  episode_reward_mean: -370.93\n",
            "  episode_reward_min: -632.0\n",
            "  episodes_this_iter: 26\n",
            "  episodes_total: 1146\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.00019531250291038305\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.22789278626441956\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003230142407119274\n",
            "          model: {}\n",
            "          policy_loss: -0.001526630250737071\n",
            "          total_loss: 17785769951232.0\n",
            "          vf_explained_var: -3.5762786865234375e-07\n",
            "          vf_loss: 17785769951232.0\n",
            "    num_agent_steps_sampled: 344000\n",
            "    num_agent_steps_trained: 344000\n",
            "    num_steps_sampled: 344000\n",
            "    num_steps_trained: 344000\n",
            "  iterations_since_restore: 13\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.12500000000001\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04738169628401389\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06262277908070614\n",
            "    mean_inference_ms: 0.7253995481718585\n",
            "    mean_raw_obs_processing_ms: 0.13293797969241405\n",
            "  time_since_restore: 106.2601854801178\n",
            "  time_this_iter_s: 8.04898715019226\n",
            "  time_total_s: 349.26998019218445\n",
            "  timers:\n",
            "    learn_throughput: 26148.903\n",
            "    learn_time_ms: 305.94\n",
            "    load_throughput: 3297441.209\n",
            "    load_time_ms: 2.426\n",
            "    sample_throughput: 1019.499\n",
            "    sample_time_ms: 7846.993\n",
            "    update_time_ms: 2.737\n",
            "  timestamp: 1624606808\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 344000\n",
            "  training_iteration: 40\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         349.27 </td><td style=\"text-align: right;\">344000</td><td style=\"text-align: right;\"> -370.93</td><td style=\"text-align: right;\">                -135</td><td style=\"text-align: right;\">                -632</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 352000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-40-16\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -135.0\n",
            "  episode_reward_mean: -365.01\n",
            "  episode_reward_min: -632.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 1173\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 9.765625145519152e-05\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.2331620454788208\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.007295326795428991\n",
            "          model: {}\n",
            "          policy_loss: -0.00673207500949502\n",
            "          total_loss: 12566824747008.0\n",
            "          vf_explained_var: 2.130866050720215e-06\n",
            "          vf_loss: 12566824747008.0\n",
            "    num_agent_steps_sampled: 352000\n",
            "    num_agent_steps_trained: 352000\n",
            "    num_steps_sampled: 352000\n",
            "    num_steps_trained: 352000\n",
            "  iterations_since_restore: 14\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.27272727272727\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04734390885657074\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06258053411603212\n",
            "    mean_inference_ms: 0.7249535569554639\n",
            "    mean_raw_obs_processing_ms: 0.13285245276304425\n",
            "  time_since_restore: 114.3735101222992\n",
            "  time_this_iter_s: 8.113324642181396\n",
            "  time_total_s: 357.38330483436584\n",
            "  timers:\n",
            "    learn_throughput: 25983.204\n",
            "    learn_time_ms: 307.891\n",
            "    load_throughput: 3289682.448\n",
            "    load_time_ms: 2.432\n",
            "    sample_throughput: 1019.684\n",
            "    sample_time_ms: 7845.569\n",
            "    update_time_ms: 2.74\n",
            "  timestamp: 1624606816\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 352000\n",
            "  training_iteration: 41\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 3 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:2500</td><td style=\"text-align: right;\">            16</td><td style=\"text-align: right;\">                1638</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">         357.383</td><td style=\"text-align: right;\">352000</td><td style=\"text-align: right;\"> -365.01</td><td style=\"text-align: right;\">                -135</td><td style=\"text-align: right;\">                -632</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-25 07:40:24,548\tINFO pbt.py:543 -- [exploit] transferring weights from trial PPO_WasteNetEnv_8c324_00004 (score -44.21) -> PPO_WasteNetEnv_8c324_00006 (score -357.29)\n",
            "2021-06-25 07:40:24,550\tINFO pbt.py:558 -- [explore] perturbed config from {'lambda': 0.9, 'clip_param': 0.3, 'lr': 5e-05, 'num_sgd_iter': 10, 'sgd_minibatch_size': 128, 'train_batch_size': 10000} -> {'lambda': 0.7200000000000001, 'clip_param': 0.35738641637099167, 'lr': 0.0001, 'num_sgd_iter': 8, 'sgd_minibatch_size': 153, 'train_batch_size': 12000}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 360000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-40-24\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -188.0\n",
            "  episode_reward_mean: -357.29\n",
            "  episode_reward_min: -550.0\n",
            "  episodes_this_iter: 27\n",
            "  episodes_total: 1200\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 9.765625145519152e-05\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.2153930813074112\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006840641610324383\n",
            "          model: {}\n",
            "          policy_loss: -0.006671345792710781\n",
            "          total_loss: 15853088145408.0\n",
            "          vf_explained_var: 5.960464477539063e-08\n",
            "          vf_loss: 15853088145408.0\n",
            "    num_agent_steps_sampled: 360000\n",
            "    num_agent_steps_trained: 360000\n",
            "    num_steps_sampled: 360000\n",
            "    num_steps_trained: 360000\n",
            "  iterations_since_restore: 15\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.166666666666664\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2500\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047310137475325933\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06252876770394585\n",
            "    mean_inference_ms: 0.7245110166474672\n",
            "    mean_raw_obs_processing_ms: 0.13274676007537012\n",
            "  time_since_restore: 122.51315379142761\n",
            "  time_this_iter_s: 8.139643669128418\n",
            "  time_total_s: 365.52294850349426\n",
            "  timers:\n",
            "    learn_throughput: 25957.263\n",
            "    learn_time_ms: 308.199\n",
            "    load_throughput: 3270157.493\n",
            "    load_time_ms: 2.446\n",
            "    sample_throughput: 1020.661\n",
            "    sample_time_ms: 7838.058\n",
            "    update_time_ms: 2.772\n",
            "  timestamp: 1624606824\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 360000\n",
            "  training_iteration: 42\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m 2021-06-25 07:40:29,200\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m 2021-06-25 07:40:29,200\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         250.06 </td><td style=\"text-align: right;\">196000</td><td style=\"text-align: right;\">  -89.49</td><td style=\"text-align: right;\">                 -26</td><td style=\"text-align: right;\">                -193</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2589)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2589)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2589)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2589)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2589)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2589)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2589)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2589)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2589)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2589)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m 2021-06-25 07:40:37,262\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m 2021-06-25 07:40:37,341\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00006_6_num_sgd_iter=30,sgd_minibatch_size=128,train_batch_size=20000_2021-06-25_07-09-08/tmproggv39qrestore_from_object/checkpoint-20\n",
            "\u001b[2m\u001b[36m(pid=2590)\u001b[0m 2021-06-25 07:40:37,341\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 20, '_timesteps_total': None, '_time_total': 256.2574031352997, '_episodes_total': 666}\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m 2021-06-25 07:40:41,970\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m 2021-06-25 07:40:41,970\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=2683)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2683)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2683)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2683)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2683)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2683)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2683)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2683)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2683)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2683)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m 2021-06-25 07:40:49,912\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m 2021-06-25 07:40:49,984\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00005_5_num_sgd_iter=10,sgd_minibatch_size=512,train_batch_size=20000_2021-06-25_07-06-36/tmpxezkbe9orestore_from_object/checkpoint-18\n",
            "\u001b[2m\u001b[36m(pid=2682)\u001b[0m 2021-06-25 07:40:49,985\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 18, '_timesteps_total': None, '_time_total': 250.05953216552734, '_episodes_total': 653}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 208000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-41-05\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -18.0\n",
            "  episode_reward_mean: -84.225\n",
            "  episode_reward_min: -183.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 693\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.2637111246585846\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0024498605635017157\n",
            "          model: {}\n",
            "          policy_loss: -0.004683133214712143\n",
            "          total_loss: 91.53360748291016\n",
            "          vf_explained_var: 0.510103702545166\n",
            "          vf_loss: 91.53778839111328\n",
            "    num_agent_steps_sampled: 208000\n",
            "    num_agent_steps_trained: 208000\n",
            "    num_steps_sampled: 208000\n",
            "    num_steps_trained: 208000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.77391304347826\n",
            "    ram_util_percent: 23.582608695652183\n",
            "  pid: 2682\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04622527196321693\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059920960133815336\n",
            "    mean_inference_ms: 0.7229657900670142\n",
            "    mean_raw_obs_processing_ms: 0.1310282831896882\n",
            "  time_since_restore: 15.557543277740479\n",
            "  time_this_iter_s: 15.557543277740479\n",
            "  time_total_s: 265.6170754432678\n",
            "  timers:\n",
            "    learn_throughput: 3159.358\n",
            "    learn_time_ms: 3798.24\n",
            "    load_throughput: 385258.014\n",
            "    load_time_ms: 31.148\n",
            "    sample_throughput: 1025.824\n",
            "    sample_time_ms: 11697.911\n",
            "    update_time_ms: 2.584\n",
            "  timestamp: 1624606865\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 208000\n",
            "  training_iteration: 19\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2682</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         265.617</td><td style=\"text-align: right;\">208000</td><td style=\"text-align: right;\"> -84.225</td><td style=\"text-align: right;\">                 -18</td><td style=\"text-align: right;\">                -183</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85 </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76 </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -55.74 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -44.21 </td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">-357.29 </td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -81.81 </td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 220000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-41-20\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -16.0\n",
            "  episode_reward_mean: -84.6\n",
            "  episode_reward_min: -183.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 733\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.2663273215293884\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00283845909871161\n",
            "          model: {}\n",
            "          policy_loss: -0.0036030621267855167\n",
            "          total_loss: 87.67797088623047\n",
            "          vf_explained_var: 0.5211643576622009\n",
            "          vf_loss: 87.68128967285156\n",
            "    num_agent_steps_sampled: 220000\n",
            "    num_agent_steps_trained: 220000\n",
            "    num_steps_sampled: 220000\n",
            "    num_steps_trained: 220000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.400000000000006\n",
            "    ram_util_percent: 23.60000000000001\n",
            "  pid: 2682\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04611410838354828\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059848028578489566\n",
            "    mean_inference_ms: 0.7220718089955118\n",
            "    mean_raw_obs_processing_ms: 0.13075448860426025\n",
            "  time_since_restore: 30.82410740852356\n",
            "  time_this_iter_s: 15.266564130783081\n",
            "  time_total_s: 280.8836395740509\n",
            "  timers:\n",
            "    learn_throughput: 3221.194\n",
            "    learn_time_ms: 3725.326\n",
            "    load_throughput: 694948.54\n",
            "    load_time_ms: 17.267\n",
            "    sample_throughput: 1030.148\n",
            "    sample_time_ms: 11648.812\n",
            "    update_time_ms: 2.707\n",
            "  timestamp: 1624606880\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 220000\n",
            "  training_iteration: 20\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2682</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         280.884</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\">  -84.6 </td><td style=\"text-align: right;\">                 -16</td><td style=\"text-align: right;\">                -183</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 232000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-41-36\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -16.0\n",
            "  episode_reward_mean: -78.99\n",
            "  episode_reward_min: -183.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 773\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.2640016973018646\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0040636686608195305\n",
            "          model: {}\n",
            "          policy_loss: -0.004085289314389229\n",
            "          total_loss: 86.08482360839844\n",
            "          vf_explained_var: 0.5220287442207336\n",
            "          vf_loss: 86.08870697021484\n",
            "    num_agent_steps_sampled: 232000\n",
            "    num_agent_steps_trained: 232000\n",
            "    num_steps_sampled: 232000\n",
            "    num_steps_trained: 232000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.32727272727273\n",
            "    ram_util_percent: 23.60000000000001\n",
            "  pid: 2682\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046075163970729624\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06004086399534781\n",
            "    mean_inference_ms: 0.7224643830565382\n",
            "    mean_raw_obs_processing_ms: 0.13092174920945243\n",
            "  time_since_restore: 46.237287282943726\n",
            "  time_this_iter_s: 15.413179874420166\n",
            "  time_total_s: 296.29681944847107\n",
            "  timers:\n",
            "    learn_throughput: 3249.313\n",
            "    learn_time_ms: 3693.088\n",
            "    load_throughput: 958357.308\n",
            "    load_time_ms: 12.521\n",
            "    sample_throughput: 1026.524\n",
            "    sample_time_ms: 11689.932\n",
            "    update_time_ms: 2.698\n",
            "  timestamp: 1624606896\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 232000\n",
            "  training_iteration: 21\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2682</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         296.297</td><td style=\"text-align: right;\">232000</td><td style=\"text-align: right;\">  -78.99</td><td style=\"text-align: right;\">                 -16</td><td style=\"text-align: right;\">                -183</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 244000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-41-51\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -16.0\n",
            "  episode_reward_mean: -77.44\n",
            "  episode_reward_min: -192.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 813\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.2559605538845062\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0031575553584843874\n",
            "          model: {}\n",
            "          policy_loss: -0.004790177568793297\n",
            "          total_loss: 95.31621551513672\n",
            "          vf_explained_var: 0.49904969334602356\n",
            "          vf_loss: 95.3209228515625\n",
            "    num_agent_steps_sampled: 244000\n",
            "    num_agent_steps_trained: 244000\n",
            "    num_steps_sampled: 244000\n",
            "    num_steps_trained: 244000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.24545454545456\n",
            "    ram_util_percent: 23.527272727272734\n",
            "  pid: 2682\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046082340815361604\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06022670412296188\n",
            "    mean_inference_ms: 0.7227992149619328\n",
            "    mean_raw_obs_processing_ms: 0.13111825168846727\n",
            "  time_since_restore: 61.55573487281799\n",
            "  time_this_iter_s: 15.318447589874268\n",
            "  time_total_s: 311.61526703834534\n",
            "  timers:\n",
            "    learn_throughput: 3259.541\n",
            "    learn_time_ms: 3681.5\n",
            "    load_throughput: 1174998.494\n",
            "    load_time_ms: 10.213\n",
            "    sample_throughput: 1027.253\n",
            "    sample_time_ms: 11681.638\n",
            "    update_time_ms: 2.728\n",
            "  timestamp: 1624606911\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 244000\n",
            "  training_iteration: 22\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2682</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         311.615</td><td style=\"text-align: right;\">244000</td><td style=\"text-align: right;\">  -77.44</td><td style=\"text-align: right;\">                 -16</td><td style=\"text-align: right;\">                -192</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 256000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-42-06\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -18.0\n",
            "  episode_reward_mean: -81.38\n",
            "  episode_reward_min: -192.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 853\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.24306797981262207\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0029917436186224222\n",
            "          model: {}\n",
            "          policy_loss: -0.004172564949840307\n",
            "          total_loss: 95.38359832763672\n",
            "          vf_explained_var: 0.4966568946838379\n",
            "          vf_loss: 95.38773345947266\n",
            "    num_agent_steps_sampled: 256000\n",
            "    num_agent_steps_trained: 256000\n",
            "    num_steps_sampled: 256000\n",
            "    num_steps_trained: 256000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.95238095238096\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 2682\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0460895523960367\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060253634141092416\n",
            "    mean_inference_ms: 0.7225789357436685\n",
            "    mean_raw_obs_processing_ms: 0.13136304712841912\n",
            "  time_since_restore: 76.81439352035522\n",
            "  time_this_iter_s: 15.258658647537231\n",
            "  time_total_s: 326.87392568588257\n",
            "  timers:\n",
            "    learn_throughput: 3266.408\n",
            "    learn_time_ms: 3673.76\n",
            "    load_throughput: 1369099.248\n",
            "    load_time_ms: 8.765\n",
            "    sample_throughput: 1028.649\n",
            "    sample_time_ms: 11665.792\n",
            "    update_time_ms: 2.774\n",
            "  timestamp: 1624606926\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 256000\n",
            "  training_iteration: 23\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2682</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         326.874</td><td style=\"text-align: right;\">256000</td><td style=\"text-align: right;\">  -81.38</td><td style=\"text-align: right;\">                 -18</td><td style=\"text-align: right;\">                -192</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 268000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-42-22\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 1.0\n",
            "  episode_reward_mean: -78.34\n",
            "  episode_reward_min: -192.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 893\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.24203728139400482\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0035891712177544832\n",
            "          model: {}\n",
            "          policy_loss: -0.003958388697355986\n",
            "          total_loss: 77.91348266601562\n",
            "          vf_explained_var: 0.5467802882194519\n",
            "          vf_loss: 77.91741180419922\n",
            "    num_agent_steps_sampled: 268000\n",
            "    num_agent_steps_trained: 268000\n",
            "    num_steps_sampled: 268000\n",
            "    num_steps_trained: 268000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.06363636363637\n",
            "    ram_util_percent: 23.563636363636366\n",
            "  pid: 2682\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04608163104033834\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060197756344543635\n",
            "    mean_inference_ms: 0.7222631163960762\n",
            "    mean_raw_obs_processing_ms: 0.13143740255521266\n",
            "  time_since_restore: 92.13307881355286\n",
            "  time_this_iter_s: 15.318685293197632\n",
            "  time_total_s: 342.1926109790802\n",
            "  timers:\n",
            "    learn_throughput: 3277.477\n",
            "    learn_time_ms: 3661.352\n",
            "    load_throughput: 1483250.923\n",
            "    load_time_ms: 8.09\n",
            "    sample_throughput: 1028.066\n",
            "    sample_time_ms: 11672.399\n",
            "    update_time_ms: 2.766\n",
            "  timestamp: 1624606942\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 268000\n",
            "  training_iteration: 24\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2682</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         342.193</td><td style=\"text-align: right;\">268000</td><td style=\"text-align: right;\">  -78.34</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -192</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 280000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-42-37\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 1.0\n",
            "  episode_reward_mean: -72.01\n",
            "  episode_reward_min: -152.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 933\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0031250000465661287\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.23015770316123962\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004265558440238237\n",
            "          model: {}\n",
            "          policy_loss: -0.003908710088580847\n",
            "          total_loss: 78.2353515625\n",
            "          vf_explained_var: 0.5475552678108215\n",
            "          vf_loss: 78.23924255371094\n",
            "    num_agent_steps_sampled: 280000\n",
            "    num_agent_steps_trained: 280000\n",
            "    num_steps_sampled: 280000\n",
            "    num_steps_trained: 280000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.309090909090905\n",
            "    ram_util_percent: 23.60000000000001\n",
            "  pid: 2682\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04606914117051672\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060185470027698494\n",
            "    mean_inference_ms: 0.7220988094548031\n",
            "    mean_raw_obs_processing_ms: 0.13139026466709727\n",
            "  time_since_restore: 107.41070413589478\n",
            "  time_this_iter_s: 15.277625322341919\n",
            "  time_total_s: 357.4702363014221\n",
            "  timers:\n",
            "    learn_throughput: 3277.622\n",
            "    learn_time_ms: 3661.191\n",
            "    load_throughput: 1634910.306\n",
            "    load_time_ms: 7.34\n",
            "    sample_throughput: 1028.913\n",
            "    sample_time_ms: 11662.795\n",
            "    update_time_ms: 2.723\n",
            "  timestamp: 1624606957\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 280000\n",
            "  training_iteration: 25\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>RUNNING </td><td>172.28.0.2:2682</td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         357.47 </td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  -72.01</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -152</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00005:\n",
            "  agent_timesteps_total: 292000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-42-52\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 1.0\n",
            "  episode_reward_mean: -70.83\n",
            "  episode_reward_min: -161.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 973\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0015625000232830644\n",
            "          cur_lr: 9.999999747378752e-06\n",
            "          entropy: 0.2336738258600235\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0039175087586045265\n",
            "          model: {}\n",
            "          policy_loss: -0.003086480777710676\n",
            "          total_loss: 99.79649353027344\n",
            "          vf_explained_var: 0.48704788088798523\n",
            "          vf_loss: 99.79956817626953\n",
            "    num_agent_steps_sampled: 292000\n",
            "    num_agent_steps_trained: 292000\n",
            "    num_steps_sampled: 292000\n",
            "    num_steps_trained: 292000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.00000000000001\n",
            "    ram_util_percent: 23.504545454545454\n",
            "  pid: 2682\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046088437673938304\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060178463396650485\n",
            "    mean_inference_ms: 0.7223176668455369\n",
            "    mean_raw_obs_processing_ms: 0.13128606389318706\n",
            "  time_since_restore: 122.74876594543457\n",
            "  time_this_iter_s: 15.338061809539795\n",
            "  time_total_s: 372.8082981109619\n",
            "  timers:\n",
            "    learn_throughput: 3284.619\n",
            "    learn_time_ms: 3653.392\n",
            "    load_throughput: 1756730.557\n",
            "    load_time_ms: 6.831\n",
            "    sample_throughput: 1028.217\n",
            "    sample_time_ms: 11670.694\n",
            "    update_time_ms: 2.699\n",
            "  timestamp: 1624606972\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 292000\n",
            "  training_iteration: 26\n",
            "  trial_id: 8c324_00005\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m 2021-06-25 07:42:57,745\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m 2021-06-25 07:42:57,745\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2787)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2787)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2787)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2787)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2787)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2787)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2787)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2787)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2787)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2787)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         253.054</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -81.81</td><td style=\"text-align: right;\">                  -8</td><td style=\"text-align: right;\">                -176</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m 2021-06-25 07:43:05,835\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m 2021-06-25 07:43:05,914\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00007_7_num_sgd_iter=10,sgd_minibatch_size=128,train_batch_size=20000_2021-06-25_07-11-27/tmplcgm3xb4restore_from_object/checkpoint-10\n",
            "\u001b[2m\u001b[36m(pid=2786)\u001b[0m 2021-06-25 07:43:05,914\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 10, '_timesteps_total': None, '_time_total': 253.05354356765747, '_episodes_total': 666}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 220000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-43-32\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 15.0\n",
            "  episode_reward_mean: -59.621212121212125\n",
            "  episode_reward_min: -160.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 732\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.24601790308952332\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0048147751949727535\n",
            "          model: {}\n",
            "          policy_loss: -0.010642724111676216\n",
            "          total_loss: 38.07937240600586\n",
            "          vf_explained_var: 0.7237065434455872\n",
            "          vf_loss: 38.08905029296875\n",
            "    num_agent_steps_sampled: 220000\n",
            "    num_agent_steps_trained: 220000\n",
            "    num_steps_sampled: 220000\n",
            "    num_steps_trained: 220000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.505263157894746\n",
            "    ram_util_percent: 23.5\n",
            "  pid: 2786\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0483852989357368\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06121744198129448\n",
            "    mean_inference_ms: 0.7331634865934316\n",
            "    mean_raw_obs_processing_ms: 0.13501878607470386\n",
            "  time_since_restore: 26.122655391693115\n",
            "  time_this_iter_s: 26.122655391693115\n",
            "  time_total_s: 279.1761989593506\n",
            "  timers:\n",
            "    learn_throughput: 3215.444\n",
            "    learn_time_ms: 6219.98\n",
            "    load_throughput: 664818.076\n",
            "    load_time_ms: 30.083\n",
            "    sample_throughput: 1007.922\n",
            "    sample_time_ms: 19842.797\n",
            "    update_time_ms: 2.667\n",
            "  timestamp: 1624607012\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 220000\n",
            "  training_iteration: 11\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:2786</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         279.176</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\"> -59.6212</td><td style=\"text-align: right;\">                  15</td><td style=\"text-align: right;\">                -160</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85  </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76  </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -55.74  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53  </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> -70.83  </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">-357.29  </td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\"> -44.21  </td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 240000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-43-57\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 8.0\n",
            "  episode_reward_mean: -56.73\n",
            "  episode_reward_min: -160.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 799\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.22959434986114502\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004059096332639456\n",
            "          model: {}\n",
            "          policy_loss: -0.009662024676799774\n",
            "          total_loss: 38.229713439941406\n",
            "          vf_explained_var: 0.722580075263977\n",
            "          vf_loss: 38.23896789550781\n",
            "    num_agent_steps_sampled: 240000\n",
            "    num_agent_steps_trained: 240000\n",
            "    num_steps_sampled: 240000\n",
            "    num_steps_trained: 240000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.602777777777774\n",
            "    ram_util_percent: 23.525000000000002\n",
            "  pid: 2786\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04817650319352449\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06079955849565995\n",
            "    mean_inference_ms: 0.7303817685267154\n",
            "    mean_raw_obs_processing_ms: 0.13386795803810794\n",
            "  time_since_restore: 51.64800667762756\n",
            "  time_this_iter_s: 25.52535128593445\n",
            "  time_total_s: 304.70155024528503\n",
            "  timers:\n",
            "    learn_throughput: 3277.273\n",
            "    learn_time_ms: 6102.634\n",
            "    load_throughput: 1131287.238\n",
            "    load_time_ms: 17.679\n",
            "    sample_throughput: 1016.153\n",
            "    sample_time_ms: 19682.082\n",
            "    update_time_ms: 3.383\n",
            "  timestamp: 1624607037\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 240000\n",
            "  training_iteration: 12\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:2786</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         304.702</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -56.73</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">                -160</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 260000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-44-23\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 8.0\n",
            "  episode_reward_mean: -48.67\n",
            "  episode_reward_min: -171.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 866\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.21051636338233948\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003421811619773507\n",
            "          model: {}\n",
            "          policy_loss: -0.009081044234335423\n",
            "          total_loss: 32.54161834716797\n",
            "          vf_explained_var: 0.7532615661621094\n",
            "          vf_loss: 32.55052947998047\n",
            "    num_agent_steps_sampled: 260000\n",
            "    num_agent_steps_trained: 260000\n",
            "    num_steps_sampled: 260000\n",
            "    num_steps_trained: 260000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.405405405405396\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 2786\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047818234308248025\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06037541919003983\n",
            "    mean_inference_ms: 0.7275143580583173\n",
            "    mean_raw_obs_processing_ms: 0.13289904979300865\n",
            "  time_since_restore: 77.13706016540527\n",
            "  time_this_iter_s: 25.48905348777771\n",
            "  time_total_s: 330.19060373306274\n",
            "  timers:\n",
            "    learn_throughput: 3290.484\n",
            "    learn_time_ms: 6078.132\n",
            "    load_throughput: 1506033.752\n",
            "    load_time_ms: 13.28\n",
            "    sample_throughput: 1020.262\n",
            "    sample_time_ms: 19602.815\n",
            "    update_time_ms: 3.17\n",
            "  timestamp: 1624607063\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 260000\n",
            "  training_iteration: 13\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:2786</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         330.191</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">  -48.67</td><td style=\"text-align: right;\">                   8</td><td style=\"text-align: right;\">                -171</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 280000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-44-48\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 17.0\n",
            "  episode_reward_mean: -39.95\n",
            "  episode_reward_min: -171.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 932\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.19347266852855682\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004058466292917728\n",
            "          model: {}\n",
            "          policy_loss: -0.0077718510292470455\n",
            "          total_loss: 28.225360870361328\n",
            "          vf_explained_var: 0.7766689658164978\n",
            "          vf_loss: 28.233028411865234\n",
            "    num_agent_steps_sampled: 280000\n",
            "    num_agent_steps_trained: 280000\n",
            "    num_steps_sampled: 280000\n",
            "    num_steps_trained: 280000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.39444444444444\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 2786\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047615464594342356\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06019471850924086\n",
            "    mean_inference_ms: 0.72550503464949\n",
            "    mean_raw_obs_processing_ms: 0.1324915027926689\n",
            "  time_since_restore: 102.58423209190369\n",
            "  time_this_iter_s: 25.447171926498413\n",
            "  time_total_s: 355.63777565956116\n",
            "  timers:\n",
            "    learn_throughput: 3295.24\n",
            "    learn_time_ms: 6069.362\n",
            "    load_throughput: 1805282.889\n",
            "    load_time_ms: 11.079\n",
            "    sample_throughput: 1023.07\n",
            "    sample_time_ms: 19549.011\n",
            "    update_time_ms: 2.975\n",
            "  timestamp: 1624607088\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 280000\n",
            "  training_iteration: 14\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 9 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>RUNNING </td><td>172.28.0.2:2786</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         355.638</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  -39.95</td><td style=\"text-align: right;\">                  17</td><td style=\"text-align: right;\">                -171</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00007:\n",
            "  agent_timesteps_total: 300000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-45-14\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 27.0\n",
            "  episode_reward_mean: -28.27\n",
            "  episode_reward_min: -112.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 999\n",
            "  experiment_id: 3f76d40dd1a742148c2f454fc19b1738\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.17786677181720734\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0045411051250994205\n",
            "          model: {}\n",
            "          policy_loss: -0.006938084494322538\n",
            "          total_loss: 26.015443801879883\n",
            "          vf_explained_var: 0.7914947867393494\n",
            "          vf_loss: 26.02232551574707\n",
            "    num_agent_steps_sampled: 300000\n",
            "    num_agent_steps_trained: 300000\n",
            "    num_steps_sampled: 300000\n",
            "    num_steps_trained: 300000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.35675675675675\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 2786\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04753582905559061\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06007635113091554\n",
            "    mean_inference_ms: 0.7249402459630425\n",
            "    mean_raw_obs_processing_ms: 0.13227800037182522\n",
            "  time_since_restore: 128.15693068504333\n",
            "  time_this_iter_s: 25.57269859313965\n",
            "  time_total_s: 381.2104742527008\n",
            "  timers:\n",
            "    learn_throughput: 3298.782\n",
            "    learn_time_ms: 6062.844\n",
            "    load_throughput: 2030943.25\n",
            "    load_time_ms: 9.848\n",
            "    sample_throughput: 1023.366\n",
            "    sample_time_ms: 19543.357\n",
            "    update_time_ms: 2.889\n",
            "  timestamp: 1624607114\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 300000\n",
            "  training_iteration: 15\n",
            "  trial_id: 8c324_00007\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m 2021-06-25 07:45:18,966\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m 2021-06-25 07:45:18,967\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2894)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=2894)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=2894)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=2894)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2894)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2894)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2894)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2894)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2894)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2894)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         256.257</td><td style=\"text-align: right;\">200000</td><td style=\"text-align: right;\">  -44.21</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m 2021-06-25 07:45:27,091\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m 2021-06-25 07:45:27,165\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00004_4_num_sgd_iter=10,sgd_minibatch_size=128,train_batch_size=10000_2021-06-25_07-04-14/tmpd3i8p_45restore_from_object/checkpoint-20\n",
            "\u001b[2m\u001b[36m(pid=2893)\u001b[0m 2021-06-25 07:45:27,166\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 20, '_timesteps_total': None, '_time_total': 256.2574031352997, '_episodes_total': 666}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 210000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-45-40\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 9.0\n",
            "  episode_reward_mean: -43.696969696969695\n",
            "  episode_reward_min: -111.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 699\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.19153904914855957\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00361314183101058\n",
            "          model: {}\n",
            "          policy_loss: -0.010286861099302769\n",
            "          total_loss: 30.43012237548828\n",
            "          vf_explained_var: 0.7634334564208984\n",
            "          vf_loss: 30.43968391418457\n",
            "    num_agent_steps_sampled: 210000\n",
            "    num_agent_steps_trained: 210000\n",
            "    num_steps_sampled: 210000\n",
            "    num_steps_trained: 210000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.76315789473684\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 2893\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04597735779248003\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05997477644813643\n",
            "    mean_inference_ms: 0.7261257984080132\n",
            "    mean_raw_obs_processing_ms: 0.13179383794256072\n",
            "  time_since_restore: 13.049577236175537\n",
            "  time_this_iter_s: 13.049577236175537\n",
            "  time_total_s: 269.3069803714752\n",
            "  timers:\n",
            "    learn_throughput: 3129.498\n",
            "    learn_time_ms: 3195.401\n",
            "    load_throughput: 362841.621\n",
            "    load_time_ms: 27.56\n",
            "    sample_throughput: 1020.704\n",
            "    sample_time_ms: 9797.162\n",
            "    update_time_ms: 2.792\n",
            "  timestamp: 1624607140\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 210000\n",
            "  training_iteration: 21\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         269.307</td><td style=\"text-align: right;\">210000</td><td style=\"text-align: right;\"> -43.697</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">                -111</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85 </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76 </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -55.74 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> -70.83 </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\"> -28.27 </td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">-357.29 </td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 220000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-45-53\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 15.0\n",
            "  episode_reward_mean: -42.303030303030305\n",
            "  episode_reward_min: -185.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 732\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.18513628840446472\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00294350553303957\n",
            "          model: {}\n",
            "          policy_loss: -0.009525533765554428\n",
            "          total_loss: 29.14851188659668\n",
            "          vf_explained_var: 0.7715215682983398\n",
            "          vf_loss: 29.157745361328125\n",
            "    num_agent_steps_sampled: 220000\n",
            "    num_agent_steps_trained: 220000\n",
            "    num_steps_sampled: 220000\n",
            "    num_steps_trained: 220000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.6\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 2893\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046021247522706754\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060096414818102906\n",
            "    mean_inference_ms: 0.7272075781127919\n",
            "    mean_raw_obs_processing_ms: 0.13215712667851584\n",
            "  time_since_restore: 25.91336464881897\n",
            "  time_this_iter_s: 12.863787412643433\n",
            "  time_total_s: 282.17076778411865\n",
            "  timers:\n",
            "    learn_throughput: 3219.635\n",
            "    learn_time_ms: 3105.942\n",
            "    load_throughput: 569754.401\n",
            "    load_time_ms: 17.551\n",
            "    sample_throughput: 1019.004\n",
            "    sample_time_ms: 9813.501\n",
            "    update_time_ms: 2.824\n",
            "  timestamp: 1624607153\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 220000\n",
            "  training_iteration: 22\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         282.171</td><td style=\"text-align: right;\">220000</td><td style=\"text-align: right;\"> -42.303</td><td style=\"text-align: right;\">                  15</td><td style=\"text-align: right;\">                -185</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85 </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76 </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -55.74 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53 </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> -70.83 </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\"> -28.27 </td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">-357.29 </td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 230000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-46-06\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 20.0\n",
            "  episode_reward_mean: -37.79\n",
            "  episode_reward_min: -185.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 766\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.18119406700134277\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0038007439579814672\n",
            "          model: {}\n",
            "          policy_loss: -0.008175271563231945\n",
            "          total_loss: 23.048377990722656\n",
            "          vf_explained_var: 0.8105949759483337\n",
            "          vf_loss: 23.056364059448242\n",
            "    num_agent_steps_sampled: 230000\n",
            "    num_agent_steps_trained: 230000\n",
            "    num_steps_sampled: 230000\n",
            "    num_steps_trained: 230000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.099999999999994\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 2893\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046058099644119055\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06015313478578801\n",
            "    mean_inference_ms: 0.7281497887566408\n",
            "    mean_raw_obs_processing_ms: 0.13233032335628858\n",
            "  time_since_restore: 38.771040201187134\n",
            "  time_this_iter_s: 12.857675552368164\n",
            "  time_total_s: 295.0284433364868\n",
            "  timers:\n",
            "    learn_throughput: 3258.522\n",
            "    learn_time_ms: 3068.876\n",
            "    load_throughput: 779412.417\n",
            "    load_time_ms: 12.83\n",
            "    sample_throughput: 1017.778\n",
            "    sample_time_ms: 9825.328\n",
            "    update_time_ms: 3.141\n",
            "  timestamp: 1624607166\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 230000\n",
            "  training_iteration: 23\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         295.028</td><td style=\"text-align: right;\">230000</td><td style=\"text-align: right;\">  -37.79</td><td style=\"text-align: right;\">                  20</td><td style=\"text-align: right;\">                -185</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 240000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-46-18\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 20.0\n",
            "  episode_reward_mean: -30.33\n",
            "  episode_reward_min: -185.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 799\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.1702214926481247\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.002113469410687685\n",
            "          model: {}\n",
            "          policy_loss: -0.005730117671191692\n",
            "          total_loss: 22.19415283203125\n",
            "          vf_explained_var: 0.8150312304496765\n",
            "          vf_loss: 22.199832916259766\n",
            "    num_agent_steps_sampled: 240000\n",
            "    num_agent_steps_trained: 240000\n",
            "    num_steps_sampled: 240000\n",
            "    num_steps_trained: 240000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.17222222222223\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 2893\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04606043343297245\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06015808677633371\n",
            "    mean_inference_ms: 0.7284395604984277\n",
            "    mean_raw_obs_processing_ms: 0.1324236733140488\n",
            "  time_since_restore: 51.43646311759949\n",
            "  time_this_iter_s: 12.665422916412354\n",
            "  time_total_s: 307.69386625289917\n",
            "  timers:\n",
            "    learn_throughput: 3276.789\n",
            "    learn_time_ms: 3051.768\n",
            "    load_throughput: 968063.379\n",
            "    load_time_ms: 10.33\n",
            "    sample_throughput: 1022.337\n",
            "    sample_time_ms: 9781.513\n",
            "    update_time_ms: 2.977\n",
            "  timestamp: 1624607178\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 240000\n",
            "  training_iteration: 24\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         307.694</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -30.33</td><td style=\"text-align: right;\">                  20</td><td style=\"text-align: right;\">                -185</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 250000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-46-31\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 25.0\n",
            "  episode_reward_mean: -28.16\n",
            "  episode_reward_min: -105.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 832\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.163206547498703\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0029078759253025055\n",
            "          model: {}\n",
            "          policy_loss: -0.008103658445179462\n",
            "          total_loss: 25.529541015625\n",
            "          vf_explained_var: 0.7951465249061584\n",
            "          vf_loss: 25.53761100769043\n",
            "    num_agent_steps_sampled: 250000\n",
            "    num_agent_steps_trained: 250000\n",
            "    num_steps_sampled: 250000\n",
            "    num_steps_trained: 250000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.50526315789473\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 2893\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04602664707055831\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060092801534122955\n",
            "    mean_inference_ms: 0.7281778397833091\n",
            "    mean_raw_obs_processing_ms: 0.13229320987364496\n",
            "  time_since_restore: 64.30043125152588\n",
            "  time_this_iter_s: 12.863968133926392\n",
            "  time_total_s: 320.55783438682556\n",
            "  timers:\n",
            "    learn_throughput: 3276.853\n",
            "    learn_time_ms: 3051.708\n",
            "    load_throughput: 1141692.435\n",
            "    load_time_ms: 8.759\n",
            "    sample_throughput: 1021.943\n",
            "    sample_time_ms: 9785.285\n",
            "    update_time_ms: 3.011\n",
            "  timestamp: 1624607191\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 250000\n",
            "  training_iteration: 25\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         320.558</td><td style=\"text-align: right;\">250000</td><td style=\"text-align: right;\">  -28.16</td><td style=\"text-align: right;\">                  25</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 260000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-46-44\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 29.0\n",
            "  episode_reward_mean: -30.02\n",
            "  episode_reward_min: -140.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 866\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.15913569927215576\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0032146996818482876\n",
            "          model: {}\n",
            "          policy_loss: -0.007030483800917864\n",
            "          total_loss: 24.587663650512695\n",
            "          vf_explained_var: 0.7994334697723389\n",
            "          vf_loss: 24.594675064086914\n",
            "    num_agent_steps_sampled: 260000\n",
            "    num_agent_steps_trained: 260000\n",
            "    num_steps_sampled: 260000\n",
            "    num_steps_trained: 260000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.083333333333336\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 2893\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04594563674308331\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05996916432585218\n",
            "    mean_inference_ms: 0.7270060532001611\n",
            "    mean_raw_obs_processing_ms: 0.13207546855966654\n",
            "  time_since_restore: 77.0578625202179\n",
            "  time_this_iter_s: 12.757431268692017\n",
            "  time_total_s: 333.3152656555176\n",
            "  timers:\n",
            "    learn_throughput: 3277.534\n",
            "    learn_time_ms: 3051.074\n",
            "    load_throughput: 1284881.829\n",
            "    load_time_ms: 7.783\n",
            "    sample_throughput: 1023.47\n",
            "    sample_time_ms: 9770.682\n",
            "    update_time_ms: 2.921\n",
            "  timestamp: 1624607204\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 260000\n",
            "  training_iteration: 26\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         333.315</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">  -30.02</td><td style=\"text-align: right;\">                  29</td><td style=\"text-align: right;\">                -140</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 270000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-46-57\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 29.0\n",
            "  episode_reward_mean: -28.47\n",
            "  episode_reward_min: -140.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 899\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0031250000465661287\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.15152128040790558\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004560107830911875\n",
            "          model: {}\n",
            "          policy_loss: -0.006715354043990374\n",
            "          total_loss: 18.593738555908203\n",
            "          vf_explained_var: 0.840807318687439\n",
            "          vf_loss: 18.600440979003906\n",
            "    num_agent_steps_sampled: 270000\n",
            "    num_agent_steps_trained: 270000\n",
            "    num_steps_sampled: 270000\n",
            "    num_steps_trained: 270000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.14444444444444\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 2893\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04588682866379568\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05988618195725002\n",
            "    mean_inference_ms: 0.7264377317570812\n",
            "    mean_raw_obs_processing_ms: 0.131948090459724\n",
            "  time_since_restore: 89.69653010368347\n",
            "  time_this_iter_s: 12.638667583465576\n",
            "  time_total_s: 345.95393323898315\n",
            "  timers:\n",
            "    learn_throughput: 3286.438\n",
            "    learn_time_ms: 3042.808\n",
            "    load_throughput: 1418946.331\n",
            "    load_time_ms: 7.047\n",
            "    sample_throughput: 1025.558\n",
            "    sample_time_ms: 9750.791\n",
            "    update_time_ms: 3.152\n",
            "  timestamp: 1624607217\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 270000\n",
            "  training_iteration: 27\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         345.954</td><td style=\"text-align: right;\">270000</td><td style=\"text-align: right;\">  -28.47</td><td style=\"text-align: right;\">                  29</td><td style=\"text-align: right;\">                -140</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 280000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-47-10\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 29.0\n",
            "  episode_reward_mean: -26.43\n",
            "  episode_reward_min: -162.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 932\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0015625000232830644\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.14547719061374664\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0037600381765514612\n",
            "          model: {}\n",
            "          policy_loss: -0.007014420349150896\n",
            "          total_loss: 22.34916877746582\n",
            "          vf_explained_var: 0.8115224838256836\n",
            "          vf_loss: 22.35618019104004\n",
            "    num_agent_steps_sampled: 280000\n",
            "    num_agent_steps_trained: 280000\n",
            "    num_steps_sampled: 280000\n",
            "    num_steps_trained: 280000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 64.37368421052632\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 2893\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0458605682667591\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05982287994287181\n",
            "    mean_inference_ms: 0.7269830658879658\n",
            "    mean_raw_obs_processing_ms: 0.13191859095851874\n",
            "  time_since_restore: 102.80926012992859\n",
            "  time_this_iter_s: 13.112730026245117\n",
            "  time_total_s: 359.06666326522827\n",
            "  timers:\n",
            "    learn_throughput: 3291.505\n",
            "    learn_time_ms: 3038.123\n",
            "    load_throughput: 1487552.844\n",
            "    load_time_ms: 6.722\n",
            "    sample_throughput: 1021.085\n",
            "    sample_time_ms: 9793.505\n",
            "    update_time_ms: 3.182\n",
            "  timestamp: 1624607230\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 280000\n",
            "  training_iteration: 28\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         359.067</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  -26.43</td><td style=\"text-align: right;\">                  29</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 290000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-47-23\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 26.0\n",
            "  episode_reward_mean: -22.59\n",
            "  episode_reward_min: -162.0\n",
            "  episodes_this_iter: 34\n",
            "  episodes_total: 966\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0007812500116415322\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.13708697259426117\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003427869640290737\n",
            "          model: {}\n",
            "          policy_loss: -0.008383032865822315\n",
            "          total_loss: 22.906333923339844\n",
            "          vf_explained_var: 0.8094704151153564\n",
            "          vf_loss: 22.914714813232422\n",
            "    num_agent_steps_sampled: 290000\n",
            "    num_agent_steps_trained: 290000\n",
            "    num_steps_sampled: 290000\n",
            "    num_steps_trained: 290000\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.98888888888889\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 2893\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.045861445748644966\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05981283744087468\n",
            "    mean_inference_ms: 0.7280582160097581\n",
            "    mean_raw_obs_processing_ms: 0.13195917154535974\n",
            "  time_since_restore: 115.66211247444153\n",
            "  time_this_iter_s: 12.85285234451294\n",
            "  time_total_s: 371.9195156097412\n",
            "  timers:\n",
            "    learn_throughput: 3298.321\n",
            "    learn_time_ms: 3031.846\n",
            "    load_throughput: 1601646.93\n",
            "    load_time_ms: 6.244\n",
            "    sample_throughput: 1020.316\n",
            "    sample_time_ms: 9800.881\n",
            "    update_time_ms: 3.074\n",
            "  timestamp: 1624607243\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 290000\n",
            "  training_iteration: 29\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 10 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>RUNNING </td><td>172.28.0.2:2893</td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         371.92 </td><td style=\"text-align: right;\">290000</td><td style=\"text-align: right;\">  -22.59</td><td style=\"text-align: right;\">                  26</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00004:\n",
            "  agent_timesteps_total: 300000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-47-35\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 34.0\n",
            "  episode_reward_mean: -22.91\n",
            "  episode_reward_min: -162.0\n",
            "  episodes_this_iter: 33\n",
            "  episodes_total: 999\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0003906250058207661\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.1383640468120575\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0038483100943267345\n",
            "          model: {}\n",
            "          policy_loss: -0.007691402453929186\n",
            "          total_loss: 21.305761337280273\n",
            "          vf_explained_var: 0.8198278546333313\n",
            "          vf_loss: 21.31344985961914\n",
            "    num_agent_steps_sampled: 300000\n",
            "    num_agent_steps_trained: 300000\n",
            "    num_steps_sampled: 300000\n",
            "    num_steps_trained: 300000\n",
            "  iterations_since_restore: 10\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.27777777777778\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 2893\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04589235587153317\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05986354315521785\n",
            "    mean_inference_ms: 0.7294563705448661\n",
            "    mean_raw_obs_processing_ms: 0.13212942797566674\n",
            "  time_since_restore: 128.46764016151428\n",
            "  time_this_iter_s: 12.805527687072754\n",
            "  time_total_s: 384.72504329681396\n",
            "  timers:\n",
            "    learn_throughput: 3301.399\n",
            "    learn_time_ms: 3029.019\n",
            "    load_throughput: 1688698.138\n",
            "    load_time_ms: 5.922\n",
            "    sample_throughput: 1020.458\n",
            "    sample_time_ms: 9799.517\n",
            "    update_time_ms: 3.016\n",
            "  timestamp: 1624607255\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 300000\n",
            "  training_iteration: 30\n",
            "  trial_id: 8c324_00004\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 11 checkpoints, 4 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m 2021-06-25 07:47:41,277\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m 2021-06-25 07:47:41,277\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 11 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    42</td><td style=\"text-align: right;\">         365.523</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -357.29</td><td style=\"text-align: right;\">                -188</td><td style=\"text-align: right;\">                -550</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3009)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3009)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3009)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3009)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3009)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3009)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3009)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3009)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3009)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3009)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m 2021-06-25 07:47:49,350\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m 2021-06-25 07:47:49,422\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00006_6_num_sgd_iter=30,sgd_minibatch_size=128,train_batch_size=20000_2021-06-25_07-09-08/tmpt8qy079wrestore_from_object/checkpoint-20\n",
            "\u001b[2m\u001b[36m(pid=3008)\u001b[0m 2021-06-25 07:47:49,423\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 20, '_timesteps_total': None, '_time_total': 256.2574031352997, '_episodes_total': 666}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 212000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-48-03\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 9.0\n",
            "  episode_reward_mean: -41.65\n",
            "  episode_reward_min: -111.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 706\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.18569055199623108\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.007160291541367769\n",
            "          model: {}\n",
            "          policy_loss: -0.017464809119701385\n",
            "          total_loss: 12.712672233581543\n",
            "          vf_explained_var: 0.8839251399040222\n",
            "          vf_loss: 12.728704452514648\n",
            "    num_agent_steps_sampled: 212000\n",
            "    num_agent_steps_trained: 212000\n",
            "    num_steps_sampled: 212000\n",
            "    num_steps_trained: 212000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.733333333333334\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 3008\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0464818088444717\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.058986437180649984\n",
            "    mean_inference_ms: 0.7106485828520128\n",
            "    mean_raw_obs_processing_ms: 0.13146586402655938\n",
            "  time_since_restore: 14.19649887084961\n",
            "  time_this_iter_s: 14.19649887084961\n",
            "  time_total_s: 270.4539020061493\n",
            "  timers:\n",
            "    learn_throughput: 4589.674\n",
            "    learn_time_ms: 2614.565\n",
            "    load_throughput: 421188.864\n",
            "    load_time_ms: 28.491\n",
            "    sample_throughput: 1039.517\n",
            "    sample_time_ms: 11543.826\n",
            "    update_time_ms: 2.671\n",
            "  timestamp: 1624607283\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 212000\n",
            "  training_iteration: 21\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 11 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:3008</td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         270.454</td><td style=\"text-align: right;\">212000</td><td style=\"text-align: right;\">  -41.65</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">                -111</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 224000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-48-17\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 27.0\n",
            "  episode_reward_mean: -40.6625\n",
            "  episode_reward_min: -156.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 746\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.17149735987186432\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004865134134888649\n",
            "          model: {}\n",
            "          policy_loss: -0.01293201744556427\n",
            "          total_loss: 12.832085609436035\n",
            "          vf_explained_var: 0.8845498561859131\n",
            "          vf_loss: 12.84404468536377\n",
            "    num_agent_steps_sampled: 224000\n",
            "    num_agent_steps_trained: 224000\n",
            "    num_steps_sampled: 224000\n",
            "    num_steps_trained: 224000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.285000000000004\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 3008\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04677768370266509\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05941634959223403\n",
            "    mean_inference_ms: 0.7134997797700056\n",
            "    mean_raw_obs_processing_ms: 0.13220376067696119\n",
            "  time_since_restore: 28.422823429107666\n",
            "  time_this_iter_s: 14.226324558258057\n",
            "  time_total_s: 284.68022656440735\n",
            "  timers:\n",
            "    learn_throughput: 4723.447\n",
            "    learn_time_ms: 2540.518\n",
            "    load_throughput: 735197.897\n",
            "    load_time_ms: 16.322\n",
            "    sample_throughput: 1031.367\n",
            "    sample_time_ms: 11635.039\n",
            "    update_time_ms: 2.658\n",
            "  timestamp: 1624607297\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 224000\n",
            "  training_iteration: 22\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 11 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">   reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:3008</td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         284.68 </td><td style=\"text-align: right;\">224000</td><td style=\"text-align: right;\"> -40.6625</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -156</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85  </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76  </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -55.74  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\"> -22.91  </td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> -70.83  </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\"> -28.27  </td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\">-125.53  </td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 236000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-48-32\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 27.0\n",
            "  episode_reward_mean: -31.49\n",
            "  episode_reward_min: -156.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 786\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.1576613485813141\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006038513500243425\n",
            "          model: {}\n",
            "          policy_loss: -0.011503388173878193\n",
            "          total_loss: 10.721055030822754\n",
            "          vf_explained_var: 0.9005508422851562\n",
            "          vf_loss: 10.731955528259277\n",
            "    num_agent_steps_sampled: 236000\n",
            "    num_agent_steps_trained: 236000\n",
            "    num_steps_sampled: 236000\n",
            "    num_steps_trained: 236000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.23\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 3008\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04701997513395227\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059683881217607426\n",
            "    mean_inference_ms: 0.7153568505358002\n",
            "    mean_raw_obs_processing_ms: 0.13270997001977197\n",
            "  time_since_restore: 42.54063177108765\n",
            "  time_this_iter_s: 14.11780834197998\n",
            "  time_total_s: 298.79803490638733\n",
            "  timers:\n",
            "    learn_throughput: 4777.85\n",
            "    learn_time_ms: 2511.59\n",
            "    load_throughput: 981327.787\n",
            "    load_time_ms: 12.228\n",
            "    sample_throughput: 1030.943\n",
            "    sample_time_ms: 11639.824\n",
            "    update_time_ms: 2.648\n",
            "  timestamp: 1624607312\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 236000\n",
            "  training_iteration: 23\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 11 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:3008</td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">         298.798</td><td style=\"text-align: right;\">236000</td><td style=\"text-align: right;\">  -31.49</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -156</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 248000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-48-46\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 37.0\n",
            "  episode_reward_mean: -29.76\n",
            "  episode_reward_min: -156.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 826\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.1497696191072464\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005287510342895985\n",
            "          model: {}\n",
            "          policy_loss: -0.014539270661771297\n",
            "          total_loss: 13.041147232055664\n",
            "          vf_explained_var: 0.8856202363967896\n",
            "          vf_loss: 13.055155754089355\n",
            "    num_agent_steps_sampled: 248000\n",
            "    num_agent_steps_trained: 248000\n",
            "    num_steps_sampled: 248000\n",
            "    num_steps_trained: 248000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.45238095238095\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 3008\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047273186599525514\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05995650443594621\n",
            "    mean_inference_ms: 0.7175301382505209\n",
            "    mean_raw_obs_processing_ms: 0.13343793799186013\n",
            "  time_since_restore: 56.82113170623779\n",
            "  time_this_iter_s: 14.280499935150146\n",
            "  time_total_s: 313.0785348415375\n",
            "  timers:\n",
            "    learn_throughput: 4799.462\n",
            "    learn_time_ms: 2500.28\n",
            "    load_throughput: 1192177.506\n",
            "    load_time_ms: 10.066\n",
            "    sample_throughput: 1027.394\n",
            "    sample_time_ms: 11680.04\n",
            "    update_time_ms: 2.62\n",
            "  timestamp: 1624607326\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 248000\n",
            "  training_iteration: 24\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 11 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:3008</td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    24</td><td style=\"text-align: right;\">         313.079</td><td style=\"text-align: right;\">248000</td><td style=\"text-align: right;\">  -29.76</td><td style=\"text-align: right;\">                  37</td><td style=\"text-align: right;\">                -156</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 260000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-49-00\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 37.0\n",
            "  episode_reward_mean: -28.21\n",
            "  episode_reward_min: -151.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 866\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.1370258629322052\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.004610737320035696\n",
            "          model: {}\n",
            "          policy_loss: -0.012086671777069569\n",
            "          total_loss: 11.235773086547852\n",
            "          vf_explained_var: 0.897825300693512\n",
            "          vf_loss: 11.24739933013916\n",
            "    num_agent_steps_sampled: 260000\n",
            "    num_agent_steps_trained: 260000\n",
            "    num_steps_sampled: 260000\n",
            "    num_steps_trained: 260000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.93000000000001\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 3008\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04737320396990867\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06001116026589294\n",
            "    mean_inference_ms: 0.7181344367387004\n",
            "    mean_raw_obs_processing_ms: 0.13377383429406625\n",
            "  time_since_restore: 70.84809756278992\n",
            "  time_this_iter_s: 14.026965856552124\n",
            "  time_total_s: 327.1055006980896\n",
            "  timers:\n",
            "    learn_throughput: 4833.958\n",
            "    learn_time_ms: 2482.438\n",
            "    load_throughput: 1350286.199\n",
            "    load_time_ms: 8.887\n",
            "    sample_throughput: 1028.793\n",
            "    sample_time_ms: 11664.16\n",
            "    update_time_ms: 2.797\n",
            "  timestamp: 1624607340\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 260000\n",
            "  training_iteration: 25\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 11 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:3008</td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         327.106</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">  -28.21</td><td style=\"text-align: right;\">                  37</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 272000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-49-14\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 34.0\n",
            "  episode_reward_mean: -28.32\n",
            "  episode_reward_min: -151.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 906\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.13142737746238708\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.005982597824186087\n",
            "          model: {}\n",
            "          policy_loss: -0.008572033606469631\n",
            "          total_loss: 10.692255973815918\n",
            "          vf_explained_var: 0.901116669178009\n",
            "          vf_loss: 10.700529098510742\n",
            "    num_agent_steps_sampled: 272000\n",
            "    num_agent_steps_trained: 272000\n",
            "    num_steps_sampled: 272000\n",
            "    num_steps_trained: 272000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.05999999999999\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 3008\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047372901677502716\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.060000563136626515\n",
            "    mean_inference_ms: 0.7180694943006969\n",
            "    mean_raw_obs_processing_ms: 0.1338091328872663\n",
            "  time_since_restore: 84.90917158126831\n",
            "  time_this_iter_s: 14.061074018478394\n",
            "  time_total_s: 341.166574716568\n",
            "  timers:\n",
            "    learn_throughput: 4847.272\n",
            "    learn_time_ms: 2475.619\n",
            "    load_throughput: 1515488.551\n",
            "    load_time_ms: 7.918\n",
            "    sample_throughput: 1029.662\n",
            "    sample_time_ms: 11654.315\n",
            "    update_time_ms: 2.849\n",
            "  timestamp: 1624607354\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 272000\n",
            "  training_iteration: 26\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 11 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:3008</td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         341.167</td><td style=\"text-align: right;\">272000</td><td style=\"text-align: right;\">  -28.32</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 284000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-49-28\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 38.0\n",
            "  episode_reward_mean: -23.38\n",
            "  episode_reward_min: -118.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 946\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.11703968048095703\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.006948629394173622\n",
            "          model: {}\n",
            "          policy_loss: -0.009688643738627434\n",
            "          total_loss: 10.029151916503906\n",
            "          vf_explained_var: 0.9070084691047668\n",
            "          vf_loss: 10.038494110107422\n",
            "    num_agent_steps_sampled: 284000\n",
            "    num_agent_steps_trained: 284000\n",
            "    num_steps_sampled: 284000\n",
            "    num_steps_trained: 284000\n",
            "  iterations_since_restore: 7\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.20000000000001\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 3008\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047335596353770944\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05995438101785256\n",
            "    mean_inference_ms: 0.7176601580579701\n",
            "    mean_raw_obs_processing_ms: 0.13367655717858706\n",
            "  time_since_restore: 98.99332571029663\n",
            "  time_this_iter_s: 14.08415412902832\n",
            "  time_total_s: 355.2507288455963\n",
            "  timers:\n",
            "    learn_throughput: 4854.922\n",
            "    learn_time_ms: 2471.719\n",
            "    load_throughput: 1652276.541\n",
            "    load_time_ms: 7.263\n",
            "    sample_throughput: 1030.048\n",
            "    sample_time_ms: 11649.944\n",
            "    update_time_ms: 2.792\n",
            "  timestamp: 1624607368\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 284000\n",
            "  training_iteration: 27\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 11 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:3008</td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">         355.251</td><td style=\"text-align: right;\">284000</td><td style=\"text-align: right;\">  -23.38</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                -118</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 296000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-49-42\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 38.0\n",
            "  episode_reward_mean: -19.58\n",
            "  episode_reward_min: -97.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 986\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.11398895829916\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.00599390035495162\n",
            "          model: {}\n",
            "          policy_loss: -0.010935189202427864\n",
            "          total_loss: 10.020110130310059\n",
            "          vf_explained_var: 0.9087626338005066\n",
            "          vf_loss: 10.030744552612305\n",
            "    num_agent_steps_sampled: 296000\n",
            "    num_agent_steps_trained: 296000\n",
            "    num_steps_sampled: 296000\n",
            "    num_steps_trained: 296000\n",
            "  iterations_since_restore: 8\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.539999999999985\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 3008\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04731924875428082\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05992402237492951\n",
            "    mean_inference_ms: 0.7175516212415376\n",
            "    mean_raw_obs_processing_ms: 0.13362460001725757\n",
            "  time_since_restore: 113.12754893302917\n",
            "  time_this_iter_s: 14.134223222732544\n",
            "  time_total_s: 369.38495206832886\n",
            "  timers:\n",
            "    learn_throughput: 4859.175\n",
            "    learn_time_ms: 2469.555\n",
            "    load_throughput: 1777749.647\n",
            "    load_time_ms: 6.75\n",
            "    sample_throughput: 1029.903\n",
            "    sample_time_ms: 11651.585\n",
            "    update_time_ms: 3.019\n",
            "  timestamp: 1624607382\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 296000\n",
            "  training_iteration: 28\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 11 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>RUNNING </td><td>172.28.0.2:3008</td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         369.385</td><td style=\"text-align: right;\">296000</td><td style=\"text-align: right;\">  -19.58</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -97</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00006:\n",
            "  agent_timesteps_total: 308000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-49-57\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 38.0\n",
            "  episode_reward_mean: -16.52\n",
            "  episode_reward_min: -85.0\n",
            "  episodes_this_iter: 40\n",
            "  episodes_total: 1026\n",
            "  experiment_id: 15e9dba8cc4d491bb0c6ac701a911b06\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.11062435060739517\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0064040543511509895\n",
            "          model: {}\n",
            "          policy_loss: -0.012051939964294434\n",
            "          total_loss: 9.677984237670898\n",
            "          vf_explained_var: 0.9103075861930847\n",
            "          vf_loss: 9.689715385437012\n",
            "    num_agent_steps_sampled: 308000\n",
            "    num_agent_steps_trained: 308000\n",
            "    num_steps_sampled: 308000\n",
            "    num_steps_trained: 308000\n",
            "  iterations_since_restore: 9\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.471428571428575\n",
            "    ram_util_percent: 23.600000000000005\n",
            "  pid: 3008\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047370408719349416\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059960698691849806\n",
            "    mean_inference_ms: 0.7181556473445468\n",
            "    mean_raw_obs_processing_ms: 0.1337686383095816\n",
            "  time_since_restore: 127.48780012130737\n",
            "  time_this_iter_s: 14.360251188278198\n",
            "  time_total_s: 383.74520325660706\n",
            "  timers:\n",
            "    learn_throughput: 4860.041\n",
            "    learn_time_ms: 2469.115\n",
            "    load_throughput: 1811569.768\n",
            "    load_time_ms: 6.624\n",
            "    sample_throughput: 1027.666\n",
            "    sample_time_ms: 11676.942\n",
            "    update_time_ms: 2.936\n",
            "  timestamp: 1624607397\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 308000\n",
            "  training_iteration: 29\n",
            "  trial_id: 8c324_00006\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 4 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m 2021-06-25 07:50:01,826\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m 2021-06-25 07:50:01,826\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m 2021-06-25 07:50:01,827\tWARNING ppo.py:143 -- `train_batch_size` (28086) cannot be achieved with your other settings (num_workers=1 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 28086.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.4/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         259.495</td><td style=\"text-align: right;\">260430</td><td style=\"text-align: right;\"> -125.53</td><td style=\"text-align: right;\">                 -61</td><td style=\"text-align: right;\">                -243</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3117)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3117)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3117)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3117)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3117)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3117)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3117)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3117)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3117)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3117)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m 2021-06-25 07:50:09,930\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m 2021-06-25 07:50:10,004\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00003_3_num_sgd_iter=10,sgd_minibatch_size=2048,train_batch_size=10000_2021-06-25_07-01-59/tmpaj6sjc0wrestore_from_object/checkpoint-17\n",
            "\u001b[2m\u001b[36m(pid=3118)\u001b[0m 2021-06-25 07:50:10,004\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 17, '_timesteps_total': None, '_time_total': 259.4951138496399, '_episodes_total': 868}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 288516\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-50-37\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -63.0\n",
            "  episode_reward_mean: -116.26881720430107\n",
            "  episode_reward_min: -199.0\n",
            "  episodes_this_iter: 93\n",
            "  episodes_total: 961\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.17094029486179352\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0036215768195688725\n",
            "          model: {}\n",
            "          policy_loss: -0.00594819150865078\n",
            "          total_loss: 99.448486328125\n",
            "          vf_explained_var: 0.48912596702575684\n",
            "          vf_loss: 99.45370483398438\n",
            "    num_agent_steps_sampled: 288516\n",
            "    num_agent_steps_trained: 288516\n",
            "    num_steps_sampled: 288516\n",
            "    num_steps_trained: 288516\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.120000000000005\n",
            "    ram_util_percent: 23.744999999999997\n",
            "  pid: 3118\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04728894619594189\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.061507850984070876\n",
            "    mean_inference_ms: 0.7155942955917558\n",
            "    mean_raw_obs_processing_ms: 0.1318982052651094\n",
            "  time_since_restore: 27.81763505935669\n",
            "  time_this_iter_s: 27.81763505935669\n",
            "  time_total_s: 287.3127489089966\n",
            "  timers:\n",
            "    learn_throughput: 37339.663\n",
            "    learn_time_ms: 752.176\n",
            "    load_throughput: 915330.636\n",
            "    load_time_ms: 30.684\n",
            "    sample_throughput: 1040.074\n",
            "    sample_time_ms: 27003.841\n",
            "    update_time_ms: 2.438\n",
            "  timestamp: 1624607437\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 288516\n",
            "  training_iteration: 18\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:3118</td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         287.313</td><td style=\"text-align: right;\">288516</td><td style=\"text-align: right;\">-116.269</td><td style=\"text-align: right;\">                 -63</td><td style=\"text-align: right;\">                -199</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.85 </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\"> -55.74 </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\"> -22.91 </td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\"> -70.83 </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\"> -16.52 </td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\"> -28.27 </td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\"> -55.76 </td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 316602\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-51-05\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -46.0\n",
            "  episode_reward_mean: -114.7\n",
            "  episode_reward_min: -209.0\n",
            "  episodes_this_iter: 94\n",
            "  episodes_total: 1055\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.16293972730636597\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0028604513499885798\n",
            "          model: {}\n",
            "          policy_loss: -0.004366498440504074\n",
            "          total_loss: 95.93584442138672\n",
            "          vf_explained_var: 0.4981040060520172\n",
            "          vf_loss: 95.93992614746094\n",
            "    num_agent_steps_sampled: 316602\n",
            "    num_agent_steps_trained: 316602\n",
            "    num_steps_sampled: 316602\n",
            "    num_steps_trained: 316602\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.0\n",
            "    ram_util_percent: 23.8076923076923\n",
            "  pid: 3118\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04707338004406985\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06128756357348573\n",
            "    mean_inference_ms: 0.713921902455725\n",
            "    mean_raw_obs_processing_ms: 0.13091697513729195\n",
            "  time_since_restore: 55.21607780456543\n",
            "  time_this_iter_s: 27.39844274520874\n",
            "  time_total_s: 314.7111916542053\n",
            "  timers:\n",
            "    learn_throughput: 41813.517\n",
            "    learn_time_ms: 671.697\n",
            "    load_throughput: 1471862.138\n",
            "    load_time_ms: 19.082\n",
            "    sample_throughput: 1044.287\n",
            "    sample_time_ms: 26894.918\n",
            "    update_time_ms: 2.56\n",
            "  timestamp: 1624607465\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 316602\n",
            "  training_iteration: 19\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:3118</td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         314.711</td><td style=\"text-align: right;\">316602</td><td style=\"text-align: right;\"> -114.7 </td><td style=\"text-align: right;\">                 -46</td><td style=\"text-align: right;\">                -209</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 344688\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-51-32\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -43.0\n",
            "  episode_reward_mean: -100.73\n",
            "  episode_reward_min: -170.0\n",
            "  episodes_this_iter: 93\n",
            "  episodes_total: 1148\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.1579618752002716\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0030286009423434734\n",
            "          model: {}\n",
            "          policy_loss: -0.0044959294609725475\n",
            "          total_loss: 81.97824096679688\n",
            "          vf_explained_var: 0.5288386344909668\n",
            "          vf_loss: 81.98257446289062\n",
            "    num_agent_steps_sampled: 344688\n",
            "    num_agent_steps_trained: 344688\n",
            "    num_steps_sampled: 344688\n",
            "    num_steps_trained: 344688\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.9375\n",
            "    ram_util_percent: 23.9\n",
            "  pid: 3118\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04721262549697989\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06150894085870081\n",
            "    mean_inference_ms: 0.7151326495968167\n",
            "    mean_raw_obs_processing_ms: 0.13109059191274344\n",
            "  time_since_restore: 82.89059281349182\n",
            "  time_this_iter_s: 27.67451500892639\n",
            "  time_total_s: 342.3857066631317\n",
            "  timers:\n",
            "    learn_throughput: 43294.136\n",
            "    learn_time_ms: 648.725\n",
            "    load_throughput: 1891649.671\n",
            "    load_time_ms: 14.847\n",
            "    sample_throughput: 1042.233\n",
            "    sample_time_ms: 26947.916\n",
            "    update_time_ms: 2.804\n",
            "  timestamp: 1624607492\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 344688\n",
            "  training_iteration: 20\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:3118</td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         342.386</td><td style=\"text-align: right;\">344688</td><td style=\"text-align: right;\"> -100.73</td><td style=\"text-align: right;\">                 -43</td><td style=\"text-align: right;\">                -170</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 372774\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-52-00\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -37.0\n",
            "  episode_reward_mean: -94.23\n",
            "  episode_reward_min: -197.0\n",
            "  episodes_this_iter: 94\n",
            "  episodes_total: 1242\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.14906863868236542\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003601935226470232\n",
            "          model: {}\n",
            "          policy_loss: -0.005031559616327286\n",
            "          total_loss: 81.82023620605469\n",
            "          vf_explained_var: 0.5288276672363281\n",
            "          vf_loss: 81.82518005371094\n",
            "    num_agent_steps_sampled: 372774\n",
            "    num_agent_steps_trained: 372774\n",
            "    num_steps_sampled: 372774\n",
            "    num_steps_trained: 372774\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.071794871794864\n",
            "    ram_util_percent: 23.899999999999995\n",
            "  pid: 3118\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047083362873550215\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06133398771120376\n",
            "    mean_inference_ms: 0.7144245924642704\n",
            "    mean_raw_obs_processing_ms: 0.13081992669808284\n",
            "  time_since_restore: 110.24295663833618\n",
            "  time_this_iter_s: 27.35236382484436\n",
            "  time_total_s: 369.7380704879761\n",
            "  timers:\n",
            "    learn_throughput: 44623.61\n",
            "    learn_time_ms: 629.398\n",
            "    load_throughput: 2260040.522\n",
            "    load_time_ms: 12.427\n",
            "    sample_throughput: 1044.015\n",
            "    sample_time_ms: 26901.916\n",
            "    update_time_ms: 3.001\n",
            "  timestamp: 1624607520\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 372774\n",
            "  training_iteration: 21\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 4 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>RUNNING </td><td>172.28.0.2:3118</td><td style=\"text-align: right;\">            24</td><td style=\"text-align: right;\">               14043</td><td style=\"text-align: right;\">             28086</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         369.738</td><td style=\"text-align: right;\">372774</td><td style=\"text-align: right;\">  -94.23</td><td style=\"text-align: right;\">                 -37</td><td style=\"text-align: right;\">                -197</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-25 07:52:27,990\tINFO pbt.py:543 -- [exploit] transferring weights from trial PPO_WasteNetEnv_8c324_00006 (score -16.52) -> PPO_WasteNetEnv_8c324_00003 (score -89.58)\n",
            "2021-06-25 07:52:27,992\tINFO pbt.py:558 -- [explore] perturbed config from {'lambda': 0.7200000000000001, 'clip_param': 0.35738641637099167, 'lr': 0.0001, 'num_sgd_iter': 8, 'sgd_minibatch_size': 153, 'train_batch_size': 12000} -> {'lambda': 0.5760000000000001, 'clip_param': 0.26925647901362854, 'lr': 5e-05, 'num_sgd_iter': 6, 'sgd_minibatch_size': 122, 'train_batch_size': 14400}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00003:\n",
            "  agent_timesteps_total: 400860\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-52-27\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -29.0\n",
            "  episode_reward_mean: -89.58\n",
            "  episode_reward_min: -175.0\n",
            "  episodes_this_iter: 94\n",
            "  episodes_total: 1336\n",
            "  experiment_id: d836959d0f864d29893a693a78425543\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 9.999999747378752e-05\n",
            "          entropy: 0.14309294521808624\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0033971548546105623\n",
            "          model: {}\n",
            "          policy_loss: -0.0039706360548734665\n",
            "          total_loss: 75.17327880859375\n",
            "          vf_explained_var: 0.5503721237182617\n",
            "          vf_loss: 75.17721557617188\n",
            "    num_agent_steps_sampled: 400860\n",
            "    num_agent_steps_trained: 400860\n",
            "    num_steps_sampled: 400860\n",
            "    num_steps_trained: 400860\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 61.9923076923077\n",
            "    ram_util_percent: 23.899999999999995\n",
            "  pid: 3118\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047075152356131494\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.06131138472271962\n",
            "    mean_inference_ms: 0.7150681328544343\n",
            "    mean_raw_obs_processing_ms: 0.13082096541170116\n",
            "  time_since_restore: 137.86265540122986\n",
            "  time_this_iter_s: 27.619698762893677\n",
            "  time_total_s: 397.35776925086975\n",
            "  timers:\n",
            "    learn_throughput: 45040.494\n",
            "    learn_time_ms: 623.572\n",
            "    load_throughput: 2448041.424\n",
            "    load_time_ms: 11.473\n",
            "    sample_throughput: 1043.255\n",
            "    sample_time_ms: 26921.498\n",
            "    update_time_ms: 3.009\n",
            "  timestamp: 1624607547\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 400860\n",
            "  training_iteration: 22\n",
            "  trial_id: 8c324_00003\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 5 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-06-25 07:52:32,898\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-06-25 07:52:32,898\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3261)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3261)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3261)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3261)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3261)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3261)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3261)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3261)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3261)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3261)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         272.614</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.76</td><td style=\"text-align: right;\">                  24</td><td style=\"text-align: right;\">                -151</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-06-25 07:52:41,032\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-06-25 07:52:41,117\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00003_3_num_sgd_iter=10,sgd_minibatch_size=2048,train_batch_size=10000_2021-06-25_07-01-59/tmpivd5xd4krestore_from_object/checkpoint-29\n",
            "\u001b[2m\u001b[36m(pid=3257)\u001b[0m 2021-06-25 07:52:41,118\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 29, '_timesteps_total': None, '_time_total': 383.74520325660706, '_episodes_total': 1026}\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m 2021-06-25 07:52:45,839\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m 2021-06-25 07:52:45,840\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=3348)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3348)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3348)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3348)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3348)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3348)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3348)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3348)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3348)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3348)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m 2021-06-25 07:52:53,721\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m 2021-06-25 07:52:53,800\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00001_1_num_sgd_iter=20,sgd_minibatch_size=512,train_batch_size=20000_2021-06-25_06-57-04/tmppa2i1wk7restore_from_object/checkpoint-12\n",
            "\u001b[2m\u001b[36m(pid=3347)\u001b[0m 2021-06-25 07:52:53,801\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 12, '_timesteps_total': None, '_time_total': 272.61404395103455, '_episodes_total': 800}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 260000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-53-16\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 19.0\n",
            "  episode_reward_mean: -54.13636363636363\n",
            "  episode_reward_min: -159.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 866\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.22176547348499298\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0033552406821399927\n",
            "          model: {}\n",
            "          policy_loss: -0.01111614890396595\n",
            "          total_loss: 31.901126861572266\n",
            "          vf_explained_var: 0.756003201007843\n",
            "          vf_loss: 31.911571502685547\n",
            "    num_agent_steps_sampled: 260000\n",
            "    num_agent_steps_trained: 260000\n",
            "    num_steps_sampled: 260000\n",
            "    num_steps_trained: 260000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.84848484848485\n",
            "    ram_util_percent: 23.8\n",
            "  pid: 3347\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04723144646829548\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05964232494780901\n",
            "    mean_inference_ms: 0.7162211412287053\n",
            "    mean_raw_obs_processing_ms: 0.1313752528697418\n",
            "  time_since_restore: 22.800771236419678\n",
            "  time_this_iter_s: 22.800771236419678\n",
            "  time_total_s: 295.4148151874542\n",
            "  timers:\n",
            "    learn_throughput: 5952.015\n",
            "    learn_time_ms: 3360.207\n",
            "    load_throughput: 654904.637\n",
            "    load_time_ms: 30.539\n",
            "    sample_throughput: 1032.254\n",
            "    sample_time_ms: 19375.071\n",
            "    update_time_ms: 2.934\n",
            "  timestamp: 1624607596\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 260000\n",
            "  training_iteration: 13\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:3347</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         295.415</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">-54.1364</td><td style=\"text-align: right;\">                  19</td><td style=\"text-align: right;\">                -159</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">-55.74  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">-89.58  </td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">-22.91  </td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">-70.83  </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">-16.52  </td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">-28.27  </td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">-55.85  </td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 280000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-53-39\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 19.0\n",
            "  episode_reward_mean: -40.91\n",
            "  episode_reward_min: -143.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 933\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.20842640101909637\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0032525998540222645\n",
            "          model: {}\n",
            "          policy_loss: -0.009586693719029427\n",
            "          total_loss: 24.48183822631836\n",
            "          vf_explained_var: 0.8004802465438843\n",
            "          vf_loss: 24.4910945892334\n",
            "    num_agent_steps_sampled: 280000\n",
            "    num_agent_steps_trained: 280000\n",
            "    num_steps_sampled: 280000\n",
            "    num_steps_trained: 280000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.04375\n",
            "    ram_util_percent: 23.8\n",
            "  pid: 3347\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047091429890528\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05953717905770443\n",
            "    mean_inference_ms: 0.7165778808491997\n",
            "    mean_raw_obs_processing_ms: 0.1309246284553416\n",
            "  time_since_restore: 45.29740381240845\n",
            "  time_this_iter_s: 22.49663257598877\n",
            "  time_total_s: 317.911447763443\n",
            "  timers:\n",
            "    learn_throughput: 6128.045\n",
            "    learn_time_ms: 3263.683\n",
            "    load_throughput: 1115358.064\n",
            "    load_time_ms: 17.931\n",
            "    sample_throughput: 1033.919\n",
            "    sample_time_ms: 19343.882\n",
            "    update_time_ms: 2.792\n",
            "  timestamp: 1624607619\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 280000\n",
            "  training_iteration: 14\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:3347</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         317.911</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  -40.91</td><td style=\"text-align: right;\">                  19</td><td style=\"text-align: right;\">                -143</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 300000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-54-01\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 25.0\n",
            "  episode_reward_mean: -36.7\n",
            "  episode_reward_min: -178.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 1000\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.19259105622768402\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0034473431296646595\n",
            "          model: {}\n",
            "          policy_loss: -0.009896846488118172\n",
            "          total_loss: 24.02016258239746\n",
            "          vf_explained_var: 0.802767813205719\n",
            "          vf_loss: 24.029888153076172\n",
            "    num_agent_steps_sampled: 300000\n",
            "    num_agent_steps_trained: 300000\n",
            "    num_steps_sampled: 300000\n",
            "    num_steps_trained: 300000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.065625000000004\n",
            "    ram_util_percent: 23.8125\n",
            "  pid: 3347\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04691321547562675\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05944202397112855\n",
            "    mean_inference_ms: 0.7165852171864279\n",
            "    mean_raw_obs_processing_ms: 0.13040270913552618\n",
            "  time_since_restore: 67.7151083946228\n",
            "  time_this_iter_s: 22.417704582214355\n",
            "  time_total_s: 340.32915234565735\n",
            "  timers:\n",
            "    learn_throughput: 6207.514\n",
            "    learn_time_ms: 3221.902\n",
            "    load_throughput: 1459184.414\n",
            "    load_time_ms: 13.706\n",
            "    sample_throughput: 1035.361\n",
            "    sample_time_ms: 19316.925\n",
            "    update_time_ms: 2.791\n",
            "  timestamp: 1624607641\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 300000\n",
            "  training_iteration: 15\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:3347</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         340.329</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -36.7 </td><td style=\"text-align: right;\">                  25</td><td style=\"text-align: right;\">                -178</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 320000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-54-24\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 33.0\n",
            "  episode_reward_mean: -34.03\n",
            "  episode_reward_min: -178.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 1066\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.1825794130563736\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0027918173000216484\n",
            "          model: {}\n",
            "          policy_loss: -0.0078194048255682\n",
            "          total_loss: 23.333370208740234\n",
            "          vf_explained_var: 0.8065547943115234\n",
            "          vf_loss: 23.34111976623535\n",
            "    num_agent_steps_sampled: 320000\n",
            "    num_agent_steps_trained: 320000\n",
            "    num_steps_sampled: 320000\n",
            "    num_steps_trained: 320000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.20909090909091\n",
            "    ram_util_percent: 23.8\n",
            "  pid: 3347\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0468916357181403\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0593950654263163\n",
            "    mean_inference_ms: 0.7171886453635767\n",
            "    mean_raw_obs_processing_ms: 0.13023738974586713\n",
            "  time_since_restore: 90.2565188407898\n",
            "  time_this_iter_s: 22.541410446166992\n",
            "  time_total_s: 362.87056279182434\n",
            "  timers:\n",
            "    learn_throughput: 6249.958\n",
            "    learn_time_ms: 3200.022\n",
            "    load_throughput: 1762673.657\n",
            "    load_time_ms: 11.346\n",
            "    sample_throughput: 1034.382\n",
            "    sample_time_ms: 19335.208\n",
            "    update_time_ms: 2.717\n",
            "  timestamp: 1624607664\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 320000\n",
            "  training_iteration: 16\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:3347</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         362.871</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">  -34.03</td><td style=\"text-align: right;\">                  33</td><td style=\"text-align: right;\">                -178</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 340000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-54-46\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 33.0\n",
            "  episode_reward_mean: -25.9\n",
            "  episode_reward_min: -134.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 1133\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.17305752635002136\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0030481978319585323\n",
            "          model: {}\n",
            "          policy_loss: -0.00737231457605958\n",
            "          total_loss: 20.486425399780273\n",
            "          vf_explained_var: 0.8275449872016907\n",
            "          vf_loss: 20.49376106262207\n",
            "    num_agent_steps_sampled: 340000\n",
            "    num_agent_steps_trained: 340000\n",
            "    num_steps_sampled: 340000\n",
            "    num_steps_trained: 340000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.346875000000004\n",
            "    ram_util_percent: 23.8\n",
            "  pid: 3347\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04698244866053072\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05950084052078854\n",
            "    mean_inference_ms: 0.718666174106356\n",
            "    mean_raw_obs_processing_ms: 0.13040253429819804\n",
            "  time_since_restore: 113.02634501457214\n",
            "  time_this_iter_s: 22.76982617378235\n",
            "  time_total_s: 385.6403889656067\n",
            "  timers:\n",
            "    learn_throughput: 6245.911\n",
            "    learn_time_ms: 3202.095\n",
            "    load_throughput: 1972870.992\n",
            "    load_time_ms: 10.138\n",
            "    sample_throughput: 1032.155\n",
            "    sample_time_ms: 19376.937\n",
            "    update_time_ms: 2.595\n",
            "  timestamp: 1624607686\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 340000\n",
            "  training_iteration: 17\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 12 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>RUNNING </td><td>172.28.0.2:3347</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         385.64 </td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">  -25.9 </td><td style=\"text-align: right;\">                  33</td><td style=\"text-align: right;\">                -134</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00001:\n",
            "  agent_timesteps_total: 360000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-55-09\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 27.0\n",
            "  episode_reward_mean: -21.23\n",
            "  episode_reward_min: -105.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 1200\n",
            "  experiment_id: 05aca3ff1f2b4512964a978c066636af\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.1669168323278427\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0031135790050029755\n",
            "          model: {}\n",
            "          policy_loss: -0.00817768182605505\n",
            "          total_loss: 21.83722496032715\n",
            "          vf_explained_var: 0.8188683390617371\n",
            "          vf_loss: 21.845382690429688\n",
            "    num_agent_steps_sampled: 360000\n",
            "    num_agent_steps_trained: 360000\n",
            "    num_steps_sampled: 360000\n",
            "    num_steps_trained: 360000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.109375\n",
            "    ram_util_percent: 23.8\n",
            "  pid: 3347\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046948278305248385\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05944874610185998\n",
            "    mean_inference_ms: 0.718262425990296\n",
            "    mean_raw_obs_processing_ms: 0.13018623070530333\n",
            "  time_since_restore: 135.3090922832489\n",
            "  time_this_iter_s: 22.282747268676758\n",
            "  time_total_s: 407.92313623428345\n",
            "  timers:\n",
            "    learn_throughput: 6260.122\n",
            "    learn_time_ms: 3194.826\n",
            "    load_throughput: 2181049.712\n",
            "    load_time_ms: 9.17\n",
            "    sample_throughput: 1034.541\n",
            "    sample_time_ms: 19332.249\n",
            "    update_time_ms: 2.67\n",
            "  timestamp: 1624607709\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 360000\n",
            "  training_iteration: 18\n",
            "  trial_id: 8c324_00001\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -21.23</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m 2021-06-25 07:55:14,260\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m 2021-06-25 07:55:14,260\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -21.23</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3473)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3473)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3473)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3473)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3473)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3473)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3473)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3473)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3473)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3473)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.9/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    12</td><td style=\"text-align: right;\">         273.685</td><td style=\"text-align: right;\">240000</td><td style=\"text-align: right;\">  -55.85</td><td style=\"text-align: right;\">                  31</td><td style=\"text-align: right;\">                -167</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -21.23</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m 2021-06-25 07:55:22,481\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m 2021-06-25 07:55:22,558\tINFO trainable.py:378 -- Restored on 172.28.0.2 from checkpoint: /content/ray_results/wastenet_ppo_tune/PPO_WasteNetEnv_8c324_00000_0_num_sgd_iter=20,sgd_minibatch_size=512,train_batch_size=20000_2021-06-25_06-57-04/tmpzhu5l7txrestore_from_object/checkpoint-12\n",
            "\u001b[2m\u001b[36m(pid=3475)\u001b[0m 2021-06-25 07:55:22,558\tINFO trainable.py:385 -- Current state after restoring: {'_iteration': 12, '_timesteps_total': None, '_time_total': 273.68507981300354, '_episodes_total': 800}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 260000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-55-45\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 19.0\n",
            "  episode_reward_mean: -46.27272727272727\n",
            "  episode_reward_min: -149.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 866\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.21910513937473297\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0033637864980846643\n",
            "          model: {}\n",
            "          policy_loss: -0.010359002277255058\n",
            "          total_loss: 27.367115020751953\n",
            "          vf_explained_var: 0.7801476716995239\n",
            "          vf_loss: 27.376802444458008\n",
            "    num_agent_steps_sampled: 260000\n",
            "    num_agent_steps_trained: 260000\n",
            "    num_steps_sampled: 260000\n",
            "    num_steps_trained: 260000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.7090909090909\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 3475\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04696943755030876\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.059492689008432874\n",
            "    mean_inference_ms: 0.7087292119769011\n",
            "    mean_raw_obs_processing_ms: 0.13107511080668505\n",
            "  time_since_restore: 22.6033034324646\n",
            "  time_this_iter_s: 22.6033034324646\n",
            "  time_total_s: 296.28838324546814\n",
            "  timers:\n",
            "    learn_throughput: 6012.914\n",
            "    learn_time_ms: 3326.174\n",
            "    load_throughput: 655980.106\n",
            "    load_time_ms: 30.489\n",
            "    sample_throughput: 1040.821\n",
            "    sample_time_ms: 19215.596\n",
            "    update_time_ms: 2.734\n",
            "  timestamp: 1624607745\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 260000\n",
            "  training_iteration: 13\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:3475</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         296.288</td><td style=\"text-align: right;\">260000</td><td style=\"text-align: right;\">-46.2727</td><td style=\"text-align: right;\">                  19</td><td style=\"text-align: right;\">                -149</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">-21.23  </td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">-89.58  </td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">-22.91  </td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">-70.83  </td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">-16.52  </td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">-28.27  </td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">-55.74  </td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 280000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-56-07\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 21.0\n",
            "  episode_reward_mean: -41.84\n",
            "  episode_reward_min: -149.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 933\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.10000000149011612\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.20801791548728943\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0031978939659893513\n",
            "          model: {}\n",
            "          policy_loss: -0.00948968157172203\n",
            "          total_loss: 25.699951171875\n",
            "          vf_explained_var: 0.7911882400512695\n",
            "          vf_loss: 25.709123611450195\n",
            "    num_agent_steps_sampled: 280000\n",
            "    num_agent_steps_trained: 280000\n",
            "    num_steps_sampled: 280000\n",
            "    num_steps_trained: 280000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.146875\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 3475\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.046920262699136434\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05949157297144993\n",
            "    mean_inference_ms: 0.7083150897305143\n",
            "    mean_raw_obs_processing_ms: 0.1310384383870924\n",
            "  time_since_restore: 44.923447132110596\n",
            "  time_this_iter_s: 22.320143699645996\n",
            "  time_total_s: 318.60852694511414\n",
            "  timers:\n",
            "    learn_throughput: 6157.985\n",
            "    learn_time_ms: 3247.816\n",
            "    load_throughput: 1098409.464\n",
            "    load_time_ms: 18.208\n",
            "    sample_throughput: 1043.045\n",
            "    sample_time_ms: 19174.622\n",
            "    update_time_ms: 2.67\n",
            "  timestamp: 1624607767\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 280000\n",
            "  training_iteration: 14\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:3475</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    14</td><td style=\"text-align: right;\">         318.609</td><td style=\"text-align: right;\">280000</td><td style=\"text-align: right;\">  -41.84</td><td style=\"text-align: right;\">                  21</td><td style=\"text-align: right;\">                -149</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -21.23</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 300000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-56-30\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 21.0\n",
            "  episode_reward_mean: -36.46\n",
            "  episode_reward_min: -153.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 1000\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.05000000074505806\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.194907084107399\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003489319235086441\n",
            "          model: {}\n",
            "          policy_loss: -0.010363240726292133\n",
            "          total_loss: 24.595304489135742\n",
            "          vf_explained_var: 0.7981825470924377\n",
            "          vf_loss: 24.60549545288086\n",
            "    num_agent_steps_sampled: 300000\n",
            "    num_agent_steps_trained: 300000\n",
            "    num_steps_sampled: 300000\n",
            "    num_steps_trained: 300000\n",
            "  iterations_since_restore: 3\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.1125\n",
            "    ram_util_percent: 23.706249999999997\n",
            "  pid: 3475\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047008414715670035\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05962347855026856\n",
            "    mean_inference_ms: 0.709128789912802\n",
            "    mean_raw_obs_processing_ms: 0.13124403343058963\n",
            "  time_since_restore: 67.38154029846191\n",
            "  time_this_iter_s: 22.45809316635132\n",
            "  time_total_s: 341.06662011146545\n",
            "  timers:\n",
            "    learn_throughput: 6217.596\n",
            "    learn_time_ms: 3216.677\n",
            "    load_throughput: 1465139.61\n",
            "    load_time_ms: 13.651\n",
            "    sample_throughput: 1041.007\n",
            "    sample_time_ms: 19212.172\n",
            "    update_time_ms: 2.678\n",
            "  timestamp: 1624607790\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 300000\n",
            "  training_iteration: 15\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:3475</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         341.067</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -36.46</td><td style=\"text-align: right;\">                  21</td><td style=\"text-align: right;\">                -153</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -21.23</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 320000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-56-52\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 19.0\n",
            "  episode_reward_mean: -35.18\n",
            "  episode_reward_min: -153.0\n",
            "  episodes_this_iter: 66\n",
            "  episodes_total: 1066\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.02500000037252903\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.18253228068351746\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0023180863354355097\n",
            "          model: {}\n",
            "          policy_loss: -0.007743495516479015\n",
            "          total_loss: 23.988557815551758\n",
            "          vf_explained_var: 0.8014258146286011\n",
            "          vf_loss: 23.99624252319336\n",
            "    num_agent_steps_sampled: 320000\n",
            "    num_agent_steps_trained: 320000\n",
            "    num_steps_sampled: 320000\n",
            "    num_steps_trained: 320000\n",
            "  iterations_since_restore: 4\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.984375\n",
            "    ram_util_percent: 23.8\n",
            "  pid: 3475\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04707607033852989\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.05967191906134314\n",
            "    mean_inference_ms: 0.7103505432449174\n",
            "    mean_raw_obs_processing_ms: 0.1314121951982479\n",
            "  time_since_restore: 89.8234350681305\n",
            "  time_this_iter_s: 22.44189476966858\n",
            "  time_total_s: 363.50851488113403\n",
            "  timers:\n",
            "    learn_throughput: 6255.546\n",
            "    learn_time_ms: 3197.163\n",
            "    load_throughput: 1785304.02\n",
            "    load_time_ms: 11.203\n",
            "    sample_throughput: 1039.966\n",
            "    sample_time_ms: 19231.4\n",
            "    update_time_ms: 2.628\n",
            "  timestamp: 1624607812\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 320000\n",
            "  training_iteration: 16\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:3475</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         363.509</td><td style=\"text-align: right;\">320000</td><td style=\"text-align: right;\">  -35.18</td><td style=\"text-align: right;\">                  19</td><td style=\"text-align: right;\">                -153</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -21.23</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 340000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-57-15\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 25.0\n",
            "  episode_reward_mean: -29.84\n",
            "  episode_reward_min: -112.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 1133\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.012500000186264515\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.17349490523338318\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.003071987070143223\n",
            "          model: {}\n",
            "          policy_loss: -0.008360577747225761\n",
            "          total_loss: 23.019790649414062\n",
            "          vf_explained_var: 0.8102847933769226\n",
            "          vf_loss: 23.02811050415039\n",
            "    num_agent_steps_sampled: 340000\n",
            "    num_agent_steps_trained: 340000\n",
            "    num_steps_sampled: 340000\n",
            "    num_steps_trained: 340000\n",
            "  iterations_since_restore: 5\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 63.696875000000006\n",
            "    ram_util_percent: 23.706249999999997\n",
            "  pid: 3475\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.0470249673213031\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0596225454798569\n",
            "    mean_inference_ms: 0.7121343912143279\n",
            "    mean_raw_obs_processing_ms: 0.13140090807493662\n",
            "  time_since_restore: 112.40774512290955\n",
            "  time_this_iter_s: 22.584310054779053\n",
            "  time_total_s: 386.0928249359131\n",
            "  timers:\n",
            "    learn_throughput: 6271.169\n",
            "    learn_time_ms: 3189.198\n",
            "    load_throughput: 2008929.846\n",
            "    load_time_ms: 9.956\n",
            "    sample_throughput: 1038.022\n",
            "    sample_time_ms: 19267.419\n",
            "    update_time_ms: 2.576\n",
            "  timestamp: 1624607835\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 340000\n",
            "  training_iteration: 17\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>RUNNING </td><td>172.28.0.2:3475</td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         386.093</td><td style=\"text-align: right;\">340000</td><td style=\"text-align: right;\">  -29.84</td><td style=\"text-align: right;\">                  25</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -21.23</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_WasteNetEnv_8c324_00000:\n",
            "  agent_timesteps_total: 360000\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-25_07-57-37\n",
            "  done: false\n",
            "  episode_len_mean: 300.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: 29.0\n",
            "  episode_reward_mean: -22.56\n",
            "  episode_reward_min: -106.0\n",
            "  episodes_this_iter: 67\n",
            "  episodes_total: 1200\n",
            "  experiment_id: 819930c5485f4fcdb4a26d5014668a4f\n",
            "  hostname: c5de5901e1d0\n",
            "  info:\n",
            "    learner:\n",
            "      default_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.0062500000931322575\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.16453750431537628\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0036028986796736717\n",
            "          model: {}\n",
            "          policy_loss: -0.008074185810983181\n",
            "          total_loss: 20.57709503173828\n",
            "          vf_explained_var: 0.8261702060699463\n",
            "          vf_loss: 20.58514976501465\n",
            "    num_agent_steps_sampled: 360000\n",
            "    num_agent_steps_trained: 360000\n",
            "    num_steps_sampled: 360000\n",
            "    num_steps_trained: 360000\n",
            "  iterations_since_restore: 6\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 62.853125\n",
            "    ram_util_percent: 23.7\n",
            "  pid: 3475\n",
            "  policy_reward_max: {}\n",
            "  policy_reward_mean: {}\n",
            "  policy_reward_min: {}\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.047039856030013816\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.0597414276458575\n",
            "    mean_inference_ms: 0.7131268803686379\n",
            "    mean_raw_obs_processing_ms: 0.13164592627613625\n",
            "  time_since_restore: 134.97731804847717\n",
            "  time_this_iter_s: 22.569572925567627\n",
            "  time_total_s: 408.6623978614807\n",
            "  timers:\n",
            "    learn_throughput: 6284.105\n",
            "    learn_time_ms: 3182.633\n",
            "    load_throughput: 2207935.146\n",
            "    load_time_ms: 9.058\n",
            "    sample_throughput: 1036.801\n",
            "    sample_time_ms: 19290.103\n",
            "    update_time_ms: 2.69\n",
            "  timestamp: 1624607857\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 360000\n",
            "  training_iteration: 18\n",
            "  trial_id: 8c324_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (7 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         408.662</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -22.56</td><td style=\"text-align: right;\">                  29</td><td style=\"text-align: right;\">                -106</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -21.23</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "\u001b[2m\u001b[33m(raylet)\u001b[0m   \"update your install command.\", FutureWarning)\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m 2021-06-25 07:57:42,500\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m 2021-06-25 07:57:42,500\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         408.662</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -22.56</td><td style=\"text-align: right;\">                  29</td><td style=\"text-align: right;\">                -106</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -21.23</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3590)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3590)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3590)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3590)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3590)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3590)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3590)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3590)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3590)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3590)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m   <tf.Variable 'default_policy/log_std:0' shape=(1,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=3593)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.0/12.7 GiB<br>PopulationBasedTraining: 13 checkpoints, 5 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.3 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:P4)<br>Result logdir: /content/ray_results/wastenet_ppo_tune<br>Number of trials: 8/8 (6 PAUSED, 1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                 </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                2048</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         365.104</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -55.74</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                -137</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         408.662</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -22.56</td><td style=\"text-align: right;\">                  29</td><td style=\"text-align: right;\">                -106</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00001</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         407.923</td><td style=\"text-align: right;\">360000</td><td style=\"text-align: right;\">  -21.23</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -105</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00003</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             6</td><td style=\"text-align: right;\">                 122</td><td style=\"text-align: right;\">             14400</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         397.358</td><td style=\"text-align: right;\">400860</td><td style=\"text-align: right;\">  -89.58</td><td style=\"text-align: right;\">                 -29</td><td style=\"text-align: right;\">                -175</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00004</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             10000</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         384.725</td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -22.91</td><td style=\"text-align: right;\">                  34</td><td style=\"text-align: right;\">                -162</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00006</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">             8</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         383.745</td><td style=\"text-align: right;\">308000</td><td style=\"text-align: right;\">  -16.52</td><td style=\"text-align: right;\">                  38</td><td style=\"text-align: right;\">                 -85</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00007</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             20000</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         381.21 </td><td style=\"text-align: right;\">300000</td><td style=\"text-align: right;\">  -28.27</td><td style=\"text-align: right;\">                  27</td><td style=\"text-align: right;\">                -112</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "<tr><td>PPO_WasteNetEnv_8c324_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            12</td><td style=\"text-align: right;\">                 153</td><td style=\"text-align: right;\">             12000</td><td style=\"text-align: right;\">    26</td><td style=\"text-align: right;\">         372.808</td><td style=\"text-align: right;\">292000</td><td style=\"text-align: right;\">  -70.83</td><td style=\"text-align: right;\">                   1</td><td style=\"text-align: right;\">                -161</td><td style=\"text-align: right;\">               300</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjOOMnKkZ3Jg"
      },
      "source": [
        "best_config = {\n",
        "    \"observation_filter\": \"MeanStdFilter\",\n",
        "    \"model\": {\"free_log_std\": True},\n",
        "    \"num_sgd_iter\": 10,\n",
        "    \"sgd_minibatch_size\": 128,\n",
        "    \"lambda\": 0.731396,\n",
        "    \"clip_param\": 0.317651,\n",
        "    \"lr\": 5e-05,\n",
        "    \"train_batch_size\": 18812,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyptyrNeTgnA"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsi17r9uSE-2"
      },
      "source": [
        "ppo = PPOAgent(\"wastenet_ppo_train\", best_config, WasteNetEnv, {})\n",
        "ppo.train(num_iter=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE5CrWozRLDS"
      },
      "source": [
        "policy = ppo.agent.get_policy()\n",
        "model = policy.model\n",
        "print(model.base_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P4Tl-1zsU2h"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_hBOp4kVTQ5"
      },
      "source": [
        "# ppo = PPOAgent(\"wastenet_ppo_test\", best_config, WasteNetEnv, {})\n",
        "# ppo.load(\"checkpoints/checkpoint-best\")\n",
        "ppo.test(num_episodes=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVaoPUTNToBF"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St6gMyOST3_y"
      },
      "source": [
        "!zip -r /content/ray_results.zip /content/ray_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qdEKhi5sWoX"
      },
      "source": [
        "%load_ext tensorboard \n",
        "%tensorboard --logdir=\"/content/ray_results/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}