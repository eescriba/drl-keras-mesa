{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.7 64-bit ('mesa-keras-rl': pipenv)",
      "metadata": {
        "interpreter": {
          "hash": "02f89b5465a516aeca281cdc6934ff926772e9d915d9e8c15a08f584e0cc5517"
        }
      }
    },
    "colab": {
      "name": "taxinet.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu_Vfvki_I7f",
        "outputId": "cffaf201-1b4c-4e3b-e44c-1921c9ee1020",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -r smart-cities-drl\n",
        "!git clone https://github.com/eescriba/smart-cities-drl\n",
        "!cd smart-cities-drl/ && pip install -e .\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'smart-cities-drl'...\n",
            "remote: Enumerating objects: 573, done.\u001b[K\n",
            "remote: Counting objects: 100% (573/573), done.\u001b[K\n",
            "remote: Compressing objects: 100% (401/401), done.\u001b[K\n",
            "remote: Total 573 (delta 200), reused 501 (delta 137), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (573/573), 860.17 KiB | 28.67 MiB/s, done.\n",
            "Resolving deltas: 100% (200/200), done.\n",
            "Obtaining file:///content/smart-cities-drl\n",
            "Requirement already satisfied: mesa in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (0.8.8.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (3.2.2)\n",
            "Requirement already satisfied: keras-rl2 in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (1.0.4)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (0.17.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (2.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (7.1.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (0.11.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (1.1.5)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (5.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (7.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (2.5)\n",
            "Requirement already satisfied: cookiecutter in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (1.7.2)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->smart-cities-drl==0.1.0) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->smart-cities-drl==0.1.0) (5.2.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->smart-cities-drl==0.1.0) (7.6.3)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->smart-cities-drl==0.1.0) (5.0.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->smart-cities-drl==0.1.0) (5.6.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->smart-cities-drl==0.1.0) (4.10.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smart-cities-drl==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smart-cities-drl==0.1.0) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smart-cities-drl==0.1.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->smart-cities-drl==0.1.0) (2.4.7)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from keras-rl2->smart-cities-drl==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->smart-cities-drl==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->smart-cities-drl==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->smart-cities-drl==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->smart-cities-drl==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->mesa->smart-cities-drl==0.1.0) (2018.9)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->mesa->smart-cities-drl==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: python-slugify>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (4.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (2.11.3)\n",
            "Requirement already satisfied: poyo>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: binaryornot>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (0.4.4)\n",
            "Requirement already satisfied: jinja2-time>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe<2.0.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (2.23.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->smart-cities-drl==0.1.0) (0.9.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->smart-cities-drl==0.1.0) (4.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->smart-cities-drl==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->smart-cities-drl==0.1.0) (5.3.5)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->smart-cities-drl==0.1.0) (5.1.2)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->smart-cities-drl==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->smart-cities-drl==0.1.0) (5.0.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->smart-cities-drl==0.1.0) (5.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->smart-cities-drl==0.1.0) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->smart-cities-drl==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->smart-cities-drl==0.1.0) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->smart-cities-drl==0.1.0) (3.5.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->smart-cities-drl==0.1.0) (1.9.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->smart-cities-drl==0.1.0) (22.0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->smart-cities-drl==0.1.0) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->smart-cities-drl==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->smart-cities-drl==0.1.0) (1.4.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->smart-cities-drl==0.1.0) (0.4.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->smart-cities-drl==0.1.0) (0.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->smart-cities-drl==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (0.12.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (1.32.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (0.36.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->smart-cities-drl==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify>=4.0.0->cookiecutter->mesa->smart-cities-drl==0.1.0) (1.3)\n",
            "Requirement already satisfied: chardet>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from binaryornot>=0.4.4->cookiecutter->mesa->smart-cities-drl==0.1.0) (3.0.4)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.7/dist-packages (from jinja2-time>=0.2.0->cookiecutter->mesa->smart-cities-drl==0.1.0) (1.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->cookiecutter->mesa->smart-cities-drl==0.1.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->cookiecutter->mesa->smart-cities-drl==0.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->cookiecutter->mesa->smart-cities-drl==0.1.0) (1.24.3)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->smart-cities-drl==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->smart-cities-drl==0.1.0) (2.6.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->smart-cities-drl==0.1.0) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->smart-cities-drl==0.1.0) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->smart-cities-drl==0.1.0) (54.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->smart-cities-drl==0.1.0) (0.7.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->smart-cities-drl==0.1.0) (0.2.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->smart-cities-drl==0.1.0) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->smart-cities-drl==0.1.0) (0.5.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (1.28.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (0.4.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (3.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.1.0->keras-rl2->smart-cities-drl==0.1.0) (3.1.0)\n",
            "Installing collected packages: smart-cities-drl\n",
            "  Found existing installation: smart-cities-drl 0.1.0\n",
            "    Can't uninstall 'smart-cities-drl'. No files were found to uninstall.\n",
            "  Running setup.py develop for smart-cities-drl\n",
            "Successfully installed smart-cities-drl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkDZ9DYQ-EUM"
      },
      "source": [
        "!pip install ray[rllib]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctx8LIo3957S",
        "outputId": "7acd4384-0218-45cf-b91d-9931a50562bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import argparse\n",
        "from gym.spaces import Discrete, Tuple\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import random\n",
        "import ray\n",
        "from ray import tune\n",
        "from ray.tune import function\n",
        "from ray.rllib.utils.test_utils import check_learning_achieved\n",
        "from ray.tune import run, sample_from\n",
        "from ray.tune.schedulers import PopulationBasedTraining\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'./smart-cities-drl/src/')\n",
        "\n",
        "from smartcab.henv import SmartCabEnv, HierarchicalSmartCabEnv\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pvtusmvh-BUL"
      },
      "source": [
        "# Postprocess the perturbed config to ensure it's still valid used if PBT.\n",
        "def explore(config):\n",
        "    # ensure we collect enough timesteps to do sgd\n",
        "    if config[\"train_batch_size\"] < config[\"sgd_minibatch_size\"] * 2:\n",
        "        config[\"train_batch_size\"] = config[\"sgd_minibatch_size\"] * 2\n",
        "    # ensure we run at least one sgd iter\n",
        "    if config[\"num_sgd_iter\"] < 1:\n",
        "        config[\"num_sgd_iter\"] = 1\n",
        "    return config\n",
        "\n",
        "pbt = PopulationBasedTraining(\n",
        "    time_attr=\"time_total_s\",\n",
        "    perturbation_interval=120,\n",
        "    resample_probability=0.25,\n",
        "\n",
        "    # Specifies the mutations of these hyperparams\n",
        "    hyperparam_mutations={\n",
        "        \"lambda\": lambda: random.uniform(0.9, 1.0),\n",
        "        \"clip_param\": lambda: random.uniform(0.01, 0.5),\n",
        "        \"lr\": [1e-3, 5e-4, 1e-4, 5e-5, 1e-5],\n",
        "        \"num_sgd_iter\": lambda: random.randint(1, 30),\n",
        "        \"sgd_minibatch_size\": lambda: random.randint(128, 16384),\n",
        "        \"train_batch_size\": lambda: random.randint(2000, 160000),\n",
        "    },\n",
        "    custom_explore_fn=explore)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y8_M3KL-SDU",
        "outputId": "e807e69f-fab4-470c-f71c-2b3154fbfea1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "stop = {\n",
        "    \"training_iteration\": 200,\n",
        "    \"timesteps_total\": 100000,\n",
        "    \"episode_reward_mean\": 0.0,\n",
        "}\n",
        "\n",
        "env = SmartCabEnv(None)\n",
        "\n",
        "def policy_mapping_fn(agent_id):\n",
        "    if agent_id.startswith(\"low_level_\"):\n",
        "        return \"low_level_policy\"\n",
        "    else:\n",
        "        return \"high_level_policy\"\n",
        "\n",
        "config = {\n",
        "    \"env\": HierarchicalSmartCabEnv,\n",
        "    \"horizon\": 99, \n",
        "    \"num_workers\": 0,\n",
        "    \"entropy_coeff\": 0.01,\n",
        "    \"kl_coeff\": 1.0,\n",
        "    \"model\": {\n",
        "        \"free_log_std\": True\n",
        "    },\n",
        "    \"num_sgd_iter\": 10,\n",
        "    \"sgd_minibatch_size\": 128,\n",
        "    \"lambda\": sample_from(lambda spec: random.uniform(0.9, 1.0)),\n",
        "    \"clip_param\": sample_from(lambda spec: random.uniform(0.1, 0.5)),\n",
        "    \"lr\": sample_from(lambda spec: random.uniform(1e-3, 1e-5)),\n",
        "    \"train_batch_size\": sample_from(\n",
        "        lambda spec: random.randint(1000, 60000)),\n",
        "    \"multiagent\": {\n",
        "        \"policies\": {\n",
        "            \"high_level_policy\": (None, env.observation_space,\n",
        "                                   env.action_space, {\n",
        "                                      \"gamma\": 0.9\n",
        "                                  }),\n",
        "            \"low_level_policy\": (None,\n",
        "                                  Tuple([\n",
        "                                      env.observation_space,\n",
        "                                       env.action_space,\n",
        "                                  ]), env.action_space, {\n",
        "                                      \"gamma\": 0.0\n",
        "                                  }),\n",
        "        },\n",
        "        \"policy_mapping_fn\": function(policy_mapping_fn),\n",
        "    },\n",
        "    \"framework\": \"tf\" ,\n",
        "    # Use GPUs iff `RLLIB_NUM_GPUS` env var set to > 0.\n",
        "    \"num_gpus\": 1,\n",
        "}\n",
        "\n",
        "results = tune.run(\"PPO\",num_samples=8, scheduler=pbt, metric=\"episode_reward_mean\", mode=\"max\", stop=stop, config=config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DeprecationWarning: wrapping <function policy_mapping_fn at 0x7f27ca1cdf80> with tune.function() is no longer needed\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Actions:  6\n",
            "Targets:  4\n",
            "States:  500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-09 17:50:54,460\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "/usr/local/lib/python3.7/dist-packages/ray/tune/utils/util.py:634: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  if np.isnan(value):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 1.5/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 1/2 CPUs, 1/1 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects (0/1.0 accelerator_type:T4)<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 1/8 (1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  clip_param</th><th style=\"text-align: right;\">  lambda</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_2348f_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">    0.237024</td><td style=\"text-align: right;\"> 0.94129</td><td style=\"text-align: right;\">6.91066e-05</td><td style=\"text-align: right;\">             40969</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m 2021-04-09 17:51:00,163\tINFO trainer.py:616 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m 2021-04-09 17:51:00,164\tINFO trainer.py:643 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m Actions:  6\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m Targets:  4\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m States:  500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m 2021-04-09 17:51:00,827\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m   <tf.Variable 'high_level_policy/log_std:0' shape=(3,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m 2021-04-09 17:51:02,363\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m The following Variables were used a Lambda layer's call (lambda_1), but\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m   <tf.Variable 'low_level_policy/log_std:0' shape=(3,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m 2021-04-09 17:51:07,402\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m 2021-04-09 17:51:07,405\tWARNING deprecation.py:34 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/ray/rllib/policy/tf_policy.py:928: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=5917)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_HierarchicalSmartCabEnv_2348f_00000:\n",
            "  custom_metrics: {}\n",
            "  date: 2021-04-09_17-52-42\n",
            "  done: false\n",
            "  episode_len_mean: 99.0\n",
            "  episode_reward_max: -380.0\n",
            "  episode_reward_mean: -648.3405797101449\n",
            "  episode_reward_min: -931.0\n",
            "  episodes_this_iter: 414\n",
            "  episodes_total: 414\n",
            "  experiment_id: 78c7af00b9c94a478ab8a214bb4b9c25\n",
            "  hostname: 056f531b774a\n",
            "  info:\n",
            "    learner:\n",
            "      high_level_policy:\n",
            "        cur_kl_coeff: 1.0\n",
            "        cur_lr: 6.910657248226926e-05\n",
            "        entropy: 1.7895158529281616\n",
            "        entropy_coeff: 0.009999999776482582\n",
            "        kl: 0.002212020568549633\n",
            "        model: {}\n",
            "        policy_loss: -0.0029601852875202894\n",
            "        total_loss: -0.018642984330654144\n",
            "        vf_explained_var: 0.0023564232978969812\n",
            "        vf_loss: 3.348241932599194e-07\n",
            "      low_level_policy:\n",
            "        cur_kl_coeff: 1.0\n",
            "        cur_lr: 6.910657248226926e-05\n",
            "        entropy: 1.7711988687515259\n",
            "        entropy_coeff: 0.009999999776482582\n",
            "        kl: 0.021126722916960716\n",
            "        model: {}\n",
            "        policy_loss: -0.1615699678659439\n",
            "        total_loss: 75.10667419433594\n",
            "        vf_explained_var: 0.019146855920553207\n",
            "        vf_loss: 75.26483154296875\n",
            "    num_steps_sampled: 41000\n",
            "    num_steps_trained: 41000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 75.18897058823529\n",
            "    ram_util_percent: 18.195588235294117\n",
            "  pid: 5917\n",
            "  policy_reward_max:\n",
            "    high_level_policy: 0.0\n",
            "    low_level_policy: -20.0\n",
            "  policy_reward_mean:\n",
            "    high_level_policy: 0.0\n",
            "    low_level_policy: -162.08514492753622\n",
            "  policy_reward_min:\n",
            "    high_level_policy: 0.0\n",
            "    low_level_policy: -329.0\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.05046439366801065\n",
            "    mean_env_wait_ms: 0.03371307673749335\n",
            "    mean_inference_ms: 1.8127725687303997\n",
            "    mean_raw_obs_processing_ms: 0.11970322264865806\n",
            "  time_since_restore: 95.00391912460327\n",
            "  time_this_iter_s: 95.00391912460327\n",
            "  time_total_s: 95.00391912460327\n",
            "  timers:\n",
            "    learn_throughput: 3556.078\n",
            "    learn_time_ms: 11529.557\n",
            "    load_throughput: 445444.35\n",
            "    load_time_ms: 92.043\n",
            "    sample_throughput: 494.744\n",
            "    sample_time_ms: 82871.208\n",
            "  timestamp: 1617990762\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 41000\n",
            "  training_iteration: 1\n",
            "  trial_id: 2348f_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 1/2 CPUs, 1/1 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects (0/1.0 accelerator_type:T4)<br>Current best trial: 2348f_00000 with episode_reward_mean=-648.3405797101449 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 1, 'train_batch_size': 40969, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': True, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'gamma': 0.99, 'horizon': 99, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'HierarchicalSmartCabEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 6.910657536943112e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': True, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'high_level_policy': (None, Tuple(Box(0.0, 4.0, (2,), float32), Discrete(5), Discrete(4)), Discrete(6), {'gamma': 0.9}), 'low_level_policy': (None, Tuple(Tuple(Box(0.0, 4.0, (2,), float32), Discrete(5), Discrete(4)), Discrete(6)), Discrete(6), {'gamma': 0.0})}, 'policy_mapping_fn': <function policy_mapping_fn at 0x7f27c9f435f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 0.9412897064826731, 'kl_coeff': 1.0, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 10, 'lr_schedule': None, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.23702396669830447, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False, '_fake_gpus': False, 'vf_share_layers': -1}<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 2/8 (1 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  clip_param</th><th style=\"text-align: right;\">  lambda</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_2348f_00000</td><td>RUNNING </td><td>172.28.0.2:5917</td><td style=\"text-align: right;\">    0.237024</td><td style=\"text-align: right;\"> 0.94129</td><td style=\"text-align: right;\">6.91066e-05</td><td style=\"text-align: right;\">             40969</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         95.0039</td><td style=\"text-align: right;\">41000</td><td style=\"text-align: right;\">-648.341</td><td style=\"text-align: right;\">                -380</td><td style=\"text-align: right;\">                -931</td><td style=\"text-align: right;\">                99</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_2348f_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">    0.370803</td><td style=\"text-align: right;\"> 0.91771</td><td style=\"text-align: right;\">0.000358753</td><td style=\"text-align: right;\">             49912</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_HierarchicalSmartCabEnv_2348f_00000:\n",
            "  custom_metrics: {}\n",
            "  date: 2021-04-09_17-54-16\n",
            "  done: false\n",
            "  episode_len_mean: 99.0\n",
            "  episode_reward_max: -285.0\n",
            "  episode_reward_mean: -496.52415458937196\n",
            "  episode_reward_min: -760.0\n",
            "  episodes_this_iter: 414\n",
            "  episodes_total: 828\n",
            "  experiment_id: 78c7af00b9c94a478ab8a214bb4b9c25\n",
            "  hostname: 056f531b774a\n",
            "  info:\n",
            "    learner:\n",
            "      high_level_policy:\n",
            "        cur_kl_coeff: 0.5\n",
            "        cur_lr: 6.910657248226926e-05\n",
            "        entropy: 1.78268563747406\n",
            "        entropy_coeff: 0.009999999776482582\n",
            "        kl: 0.003906698431819677\n",
            "        model: {}\n",
            "        policy_loss: -0.011853426694869995\n",
            "        total_loss: -0.02772693522274494\n",
            "        vf_explained_var: 0.2619088888168335\n",
            "        vf_loss: 8.628056491488678e-09\n",
            "      low_level_policy:\n",
            "        cur_kl_coeff: 1.5\n",
            "        cur_lr: 6.910657248226926e-05\n",
            "        entropy: 1.7337336540222168\n",
            "        entropy_coeff: 0.009999999776482582\n",
            "        kl: 0.011258479207754135\n",
            "        model: {}\n",
            "        policy_loss: -0.12842102348804474\n",
            "        total_loss: 61.644596099853516\n",
            "        vf_explained_var: 0.011005052365362644\n",
            "        vf_loss: 61.773475646972656\n",
            "    num_steps_sampled: 82000\n",
            "    num_steps_trained: 82000\n",
            "  iterations_since_restore: 2\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 0\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 75.41567164179105\n",
            "    ram_util_percent: 18.296268656716418\n",
            "  pid: 5917\n",
            "  policy_reward_max:\n",
            "    high_level_policy: 0.0\n",
            "    low_level_policy: -20.0\n",
            "  policy_reward_mean:\n",
            "    high_level_policy: 0.0\n",
            "    low_level_policy: -124.13103864734299\n",
            "  policy_reward_min:\n",
            "    high_level_policy: 0.0\n",
            "    low_level_policy: -253.0\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.050354326058157484\n",
            "    mean_env_wait_ms: 0.033629926082176465\n",
            "    mean_inference_ms: 1.8078388568083006\n",
            "    mean_raw_obs_processing_ms: 0.1206855390367301\n",
            "  time_since_restore: 188.9316337108612\n",
            "  time_this_iter_s: 93.92771458625793\n",
            "  time_total_s: 188.9316337108612\n",
            "  timers:\n",
            "    learn_throughput: 3639.318\n",
            "    learn_time_ms: 11265.846\n",
            "    load_throughput: 806816.413\n",
            "    load_time_ms: 50.817\n",
            "    sample_throughput: 495.778\n",
            "    sample_time_ms: 82698.301\n",
            "  timestamp: 1617990856\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 82000\n",
            "  training_iteration: 2\n",
            "  trial_id: 2348f_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.3/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.28 GiB heap, 0.0/2.49 GiB objects (0/1.0 accelerator_type:T4)<br>Current best trial: 2348f_00000 with episode_reward_mean=-496.52415458937196 and parameters={'num_workers': 0, 'num_envs_per_worker': 1, 'create_env_on_driver': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'num_gpus': 1, 'train_batch_size': 40969, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'free_log_std': True, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'num_framestacks': 'auto', 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1, 'framestack': True}, 'optimizer': {}, 'gamma': 0.99, 'horizon': 99, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'HierarchicalSmartCabEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 6.910657536943112e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'tf', 'eager_tracing': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': True, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'high_level_policy': (None, Tuple(Box(0.0, 4.0, (2,), float32), Discrete(5), Discrete(4)), Discrete(6), {'gamma': 0.9}), 'low_level_policy': (None, Tuple(Tuple(Box(0.0, 4.0, (2,), float32), Discrete(5), Discrete(4)), Discrete(6)), Discrete(6), {'gamma': 0.0})}, 'policy_mapping_fn': <function policy_mapping_fn at 0x7f26d823b5f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent', 'count_steps_by': 'env_steps'}, 'logger_config': None, 'replay_sequence_length': 1, 'use_critic': True, 'use_gae': True, 'lambda': 0.9412897064826731, 'kl_coeff': 1.0, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 10, 'lr_schedule': None, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.23702396669830447, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False, '_fake_gpus': False, 'vf_share_layers': -1}<br>Result logdir: /root/ray_results/PPO<br>Number of trials: 2/8 (1 PAUSED, 1 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  clip_param</th><th style=\"text-align: right;\">  lambda</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_2348f_00000</td><td>PAUSED  </td><td>     </td><td style=\"text-align: right;\">    0.237024</td><td style=\"text-align: right;\"> 0.94129</td><td style=\"text-align: right;\">6.91066e-05</td><td style=\"text-align: right;\">             40969</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         188.932</td><td style=\"text-align: right;\">82000</td><td style=\"text-align: right;\">-496.524</td><td style=\"text-align: right;\">                -285</td><td style=\"text-align: right;\">                -760</td><td style=\"text-align: right;\">                99</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_2348f_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">    0.370803</td><td style=\"text-align: right;\"> 0.91771</td><td style=\"text-align: right;\">0.000358753</td><td style=\"text-align: right;\">             49912</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">     </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m 2021-04-09 17:54:20,532\tINFO trainer.py:616 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m 2021-04-09 17:54:20,532\tINFO trainer.py:643 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m Actions:  6\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m Targets:  4\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m States:  500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m 2021-04-09 17:54:21,192\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m The following Variables were used a Lambda layer's call (lambda), but\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m   <tf.Variable 'high_level_policy/log_std:0' shape=(3,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m 2021-04-09 17:54:22,691\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m WARNING:tensorflow:\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m The following Variables were used a Lambda layer's call (lambda_1), but\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m are not present in its tracked objects:\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m   <tf.Variable 'low_level_policy/log_std:0' shape=(3,) dtype=float32>\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m It is possible that this is intended behavior, but it is more likely\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m an omission. This is a strong indication that this layer should be\n",
            "\u001b[2m\u001b[36m(pid=5918)\u001b[0m formulated as a subclassed Layer rather than a Lambda layer.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tPHmCZZKG7Z"
      },
      "source": [
        "!rllib train --env=HierarchicalSmartCabEnv --run=PPO --config config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAqDHAm5lktc",
        "outputId": "618182a0-f648-4544-a9ce-96255daa502f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import ray.rllib.agents.ppo as ppo\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "CHECKPOINT_ROOT = \"tmp/ppo/taxi\"\n",
        "shutil.rmtree(CHECKPOINT_ROOT, ignore_errors=True, onerror=None)\n",
        "\n",
        "config={\n",
        "      \"num_gpus\": 1,\n",
        "      \"env\": SmartCabEnv,\n",
        "      \"horizon\": 99\n",
        "}\n",
        "agent = ppo.PPOTrainer(config)\n",
        "N_ITER = 50\n",
        "results = []\n",
        "episode_data = []\n",
        "episode_json = []\n",
        "\n",
        "for n in range(N_ITER):\n",
        "    result = agent.train()\n",
        "    results.append(result)\n",
        "    \n",
        "    episode = {'n': n, \n",
        "               'episode_reward_min': result['episode_reward_min'], \n",
        "               'episode_reward_mean': result['episode_reward_mean'], \n",
        "               'episode_reward_max': result['episode_reward_max'],  \n",
        "               'episode_len_mean': result['episode_len_mean']\n",
        "              }\n",
        "    \n",
        "    episode_data.append(episode)\n",
        "    episode_json.append(json.dumps(episode))\n",
        "    file_name = agent.save(CHECKPOINT_ROOT)\n",
        "    \n",
        "    print(f'{n+1:3d}: Min/Mean/Max reward: {result[\"episode_reward_min\"]:8.4f}/{result[\"episode_reward_mean\"]:8.4f}/{result[\"episode_reward_max\"]:8.4f}, len mean: {result[\"episode_len_mean\"]:8.4f}. Checkpoint saved to {file_name}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=4834)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=4834)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=4834)\u001b[0m non-resource variables are not supported in the long term\n",
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m 2021-04-09 17:36:31,445\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
            "\u001b[2m\u001b[36m(pid=4834)\u001b[0m 2021-04-09 17:36:31,536\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m Actions:  6\n",
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m Targets:  4\n",
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m States:  500\n",
            "\u001b[2m\u001b[36m(pid=4834)\u001b[0m Actions:  6\n",
            "\u001b[2m\u001b[36m(pid=4834)\u001b[0m Targets:  4\n",
            "\u001b[2m\u001b[36m(pid=4834)\u001b[0m States:  500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-04-09 17:36:33,573\tWARNING deprecation.py:34 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
            "2021-04-09 17:36:36,798\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n",
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m 2021-04-09 17:36:36,807\tWARNING deprecation.py:34 -- DeprecationWarning: `env_index` has been deprecated. Use `episode.env_id` instead. This will raise an error in the future!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/ray/rllib/policy/tf_policy.py:928: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=4834)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/ray/rllib/policy/tf_policy.py:928: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=4834)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=4834)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/ray/rllib/policy/tf_policy.py:928: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=4835)\u001b[0m Prefer Variable.assign which has equivalent behavior in 2.X.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  1: Min/Mean/Max reward: -954.0000/-682.7750/-517.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_1/checkpoint-1\n",
            "  2: Min/Mean/Max reward: -954.0000/-610.3375/-308.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_2/checkpoint-2\n",
            "  3: Min/Mean/Max reward: -954.0000/-513.9600/-308.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_3/checkpoint-3\n",
            "  4: Min/Mean/Max reward: -745.0000/-396.9200/-194.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_4/checkpoint-4\n",
            "  5: Min/Mean/Max reward: -555.0000/-311.0400/-156.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_5/checkpoint-5\n",
            "  6: Min/Mean/Max reward: -422.0000/-246.4400/-118.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_6/checkpoint-6\n",
            "  7: Min/Mean/Max reward: -327.0000/-200.8400/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_7/checkpoint-7\n",
            "  8: Min/Mean/Max reward: -308.0000/-172.9100/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_8/checkpoint-8\n",
            "  9: Min/Mean/Max reward: -308.0000/-157.9000/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_9/checkpoint-9\n",
            " 10: Min/Mean/Max reward: -251.0000/-148.2100/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_10/checkpoint-10\n",
            " 11: Min/Mean/Max reward: -251.0000/-135.4800/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_11/checkpoint-11\n",
            " 12: Min/Mean/Max reward: -251.0000/-123.3200/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_12/checkpoint-12\n",
            " 13: Min/Mean/Max reward: -156.0000/-114.0100/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_13/checkpoint-13\n",
            " 14: Min/Mean/Max reward: -156.0000/-110.9700/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_14/checkpoint-14\n",
            " 15: Min/Mean/Max reward: -156.0000/-108.3100/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_15/checkpoint-15\n",
            " 16: Min/Mean/Max reward: -156.0000/-105.6500/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_16/checkpoint-16\n",
            " 17: Min/Mean/Max reward: -156.0000/-103.7500/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_17/checkpoint-17\n",
            " 18: Min/Mean/Max reward: -137.0000/-100.7100/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_18/checkpoint-18\n",
            " 19: Min/Mean/Max reward: -137.0000/-100.3300/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_19/checkpoint-19\n",
            " 20: Min/Mean/Max reward: -118.0000/-100.1400/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_20/checkpoint-20\n",
            " 21: Min/Mean/Max reward: -118.0000/-100.5200/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_21/checkpoint-21\n",
            " 22: Min/Mean/Max reward: -118.0000/-100.3300/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_22/checkpoint-22\n",
            " 23: Min/Mean/Max reward: -118.0000/-99.5700/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_23/checkpoint-23\n",
            " 24: Min/Mean/Max reward: -99.0000/-99.0000/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_24/checkpoint-24\n",
            " 25: Min/Mean/Max reward: -118.0000/-99.1900/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_25/checkpoint-25\n",
            " 26: Min/Mean/Max reward: -118.0000/-99.1900/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_26/checkpoint-26\n",
            " 27: Min/Mean/Max reward: -99.0000/-99.0000/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_27/checkpoint-27\n",
            " 28: Min/Mean/Max reward: -118.0000/-99.3800/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_28/checkpoint-28\n",
            " 29: Min/Mean/Max reward: -137.0000/-100.3300/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_29/checkpoint-29\n",
            " 30: Min/Mean/Max reward: -137.0000/-99.9500/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_30/checkpoint-30\n",
            " 31: Min/Mean/Max reward: -137.0000/-99.3800/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_31/checkpoint-31\n",
            " 32: Min/Mean/Max reward: -99.0000/-99.0000/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_32/checkpoint-32\n",
            " 33: Min/Mean/Max reward: -118.0000/-99.1900/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_33/checkpoint-33\n",
            " 34: Min/Mean/Max reward: -118.0000/-99.1900/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_34/checkpoint-34\n",
            " 35: Min/Mean/Max reward: -118.0000/-99.1900/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_35/checkpoint-35\n",
            " 36: Min/Mean/Max reward: -118.0000/-99.3800/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_36/checkpoint-36\n",
            " 37: Min/Mean/Max reward: -118.0000/-99.1900/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_37/checkpoint-37\n",
            " 38: Min/Mean/Max reward: -118.0000/-99.5700/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_38/checkpoint-38\n",
            " 39: Min/Mean/Max reward: -118.0000/-99.5700/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_39/checkpoint-39\n",
            " 40: Min/Mean/Max reward: -118.0000/-99.3800/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_40/checkpoint-40\n",
            " 41: Min/Mean/Max reward: -118.0000/-99.1900/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_41/checkpoint-41\n",
            " 42: Min/Mean/Max reward: -99.0000/-99.0000/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_42/checkpoint-42\n",
            " 43: Min/Mean/Max reward: -99.0000/-99.0000/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_43/checkpoint-43\n",
            " 44: Min/Mean/Max reward: -99.0000/-99.0000/-99.0000, len mean:  99.0000. Checkpoint saved to tmp/ppo/taxi/checkpoint_44/checkpoint-44\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-63249a830894>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_ITER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mMAX_WORKER_FAILURE_RETRIES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRayError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ignore_worker_failures\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/trainable.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \"\"\"\n\u001b[1;32m    225\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"step() needs to return a dict.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/agents/trainer_template.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_exec_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# self._iteration gets incremented after this function returns,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/util/iter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"LocalIterator[T]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mapply_foreach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/util/iter.py\u001b[0m in \u001b[0;36mapply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    789\u001b[0m                         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m                             \u001b[0;32myield\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NextValueNotReady\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/execution/train_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    206\u001b[0m                         batch_fetches = optimizer.optimize(\n\u001b[1;32m    207\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                             self.per_device_batch_size)\n\u001b[0m\u001b[1;32m    209\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_fetches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLEARNER_STATS_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                             \u001b[0miter_extra_fetches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/rllib/execution/multi_gpu_impl.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, sess, batch_index)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mfetches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_grad_and_stats_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_common_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1369\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1373\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1360\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QRNNsSDmITj"
      },
      "source": [
        "\"policy = agent.get_policy()\n",
        "model = policy.model\n",
        "print(model.base_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Lq6B_eqqe7K",
        "outputId": "ff493bf3-fa9c-4979-c907-04c4b240fada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ray.shutdown()\n",
        "ray.init(ignore_reinit_error=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-09 17:36:23,015\tINFO services.py:1174 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metrics_export_port': 51633,\n",
              " 'node_id': '3f386c993d2c5fca12f65842f1dc69b55fb87f5b98ac62669f84e623',\n",
              " 'node_ip_address': '172.28.0.2',\n",
              " 'object_store_address': '/tmp/ray/session_2021-04-09_17-36-22_259695_4666/sockets/plasma_store',\n",
              " 'raylet_ip_address': '172.28.0.2',\n",
              " 'raylet_socket_name': '/tmp/ray/session_2021-04-09_17-36-22_259695_4666/sockets/raylet',\n",
              " 'redis_address': '172.28.0.2:6379',\n",
              " 'session_dir': '/tmp/ray/session_2021-04-09_17-36-22_259695_4666',\n",
              " 'webui_url': '127.0.0.1:8265'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW0LE7kyqirY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}