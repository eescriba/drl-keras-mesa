{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "smartcab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.7 64-bit ('venv': venv)",
      "metadata": {
        "interpreter": {
          "hash": "915e8579bc6bc5b7e6bdee387f64d79c54c721fc11f17b28b0b204a29bde1622"
        }
      },
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "orig_nbformat": 2
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO9547wOqrGb"
      },
      "source": [
        "# SmartCab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWzkFkIFqz4C"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pLSISOhRLDK",
        "outputId": "70972536-55c3-4e56-972f-b1922e7e3c7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Colab\n",
        "!rm -r smart-cities-drl\n",
        "!git clone https://github.com/eescriba/smart-cities-drl\n",
        "!cd smart-cities-drl/ && pip install -e .\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0,'./smart-cities-drl/src/')\n",
        "\n",
        "# Local\n",
        "# !pip install -e ..\n",
        "# import sys\n",
        "# sys.path.insert(0,'../src/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'smart-cities-drl'...\n",
            "remote: Enumerating objects: 829, done.\u001b[K\n",
            "remote: Counting objects: 100% (829/829), done.\u001b[K\n",
            "remote: Compressing objects: 100% (578/578), done.\u001b[K\n",
            "remote: Total 829 (delta 367), reused 657 (delta 214), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (829/829), 10.80 MiB | 7.83 MiB/s, done.\n",
            "Resolving deltas: 100% (367/367), done.\n",
            "Obtaining file:///content/smart-cities-drl\n",
            "Requirement already satisfied: mesa in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (0.8.9)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (0.17.3)\n",
            "Requirement already satisfied: ray[rllib] in /usr/local/lib/python3.7/dist-packages (from smart-cities-drl==0.1.0) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (1.19.5)\n",
            "Requirement already satisfied: cookiecutter in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (1.7.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (4.41.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (2.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (1.1.5)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from mesa->smart-cities-drl==0.1.0) (5.1.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->smart-cities-drl==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->smart-cities-drl==0.1.0) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->smart-cities-drl==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (0.7.0)\n",
            "Requirement already satisfied: aioredis in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (1.3.1)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (0.11.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (1.0.2)\n",
            "Requirement already satisfied: pydantic>=1.8 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (1.8.2)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (0.3.7)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (0.7.13)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (1.34.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (2.23.0)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (3.5.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (3.7.4.post0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (2.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (3.0.12)\n",
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (0.6.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (3.17.3)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (0.4.4)\n",
            "Requirement already satisfied: dm-tree; extra == \"rllib\" in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (0.1.6)\n",
            "Requirement already satisfied: tensorboardX; extra == \"rllib\" in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (2.3)\n",
            "Requirement already satisfied: lz4; extra == \"rllib\" in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (3.1.3)\n",
            "Requirement already satisfied: opencv-python-headless<=4.3.0.36; extra == \"rllib\" in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (4.3.0.36)\n",
            "Requirement already satisfied: tabulate; extra == \"rllib\" in /usr/local/lib/python3.7/dist-packages (from ray[rllib]->smart-cities-drl==0.1.0) (0.8.9)\n",
            "Requirement already satisfied: python-slugify>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (5.0.2)\n",
            "Requirement already satisfied: poyo>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (0.5.0)\n",
            "Requirement already satisfied: Jinja2<4.0.0,>=2.7 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (2.11.3)\n",
            "Requirement already satisfied: binaryornot>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (0.4.4)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (1.15.0)\n",
            "Requirement already satisfied: jinja2-time>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from cookiecutter->mesa->smart-cities-drl==0.1.0) (0.2.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->mesa->smart-cities-drl==0.1.0) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->mesa->smart-cities-drl==0.1.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->mesa->smart-cities-drl==0.1.0) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->smart-cities-drl==0.1.0) (0.16.0)\n",
            "Requirement already satisfied: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis->ray[rllib]->smart-cities-drl==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: async-timeout in /usr/local/lib/python3.7/dist-packages (from aioredis->ray[rllib]->smart-cities-drl==0.1.0) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.8->ray[rllib]->smart-cities-drl==0.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[rllib]->smart-cities-drl==0.1.0) (0.1.2)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[rllib]->smart-cities-drl==0.1.0) (1.26.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]->smart-cities-drl==0.1.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]->smart-cities-drl==0.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]->smart-cities-drl==0.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[rllib]->smart-cities-drl==0.1.0) (1.24.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[rllib]->smart-cities-drl==0.1.0) (21.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[rllib]->smart-cities-drl==0.1.0) (1.6.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[rllib]->smart-cities-drl==0.1.0) (5.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[rllib]->smart-cities-drl==0.1.0) (5.4.8)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[rllib]->smart-cities-drl==0.1.0) (7.352.0)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[rllib]->smart-cities-drl==0.1.0) (1.7)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify>=4.0.0->cookiecutter->mesa->smart-cities-drl==0.1.0) (1.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<4.0.0,>=2.7->cookiecutter->mesa->smart-cities-drl==0.1.0) (2.0.1)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.7/dist-packages (from jinja2-time>=0.2.0->cookiecutter->mesa->smart-cities-drl==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]->smart-cities-drl==0.1.0) (57.0.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]->smart-cities-drl==0.1.0) (20.9)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]->smart-cities-drl==0.1.0) (1.31.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]->smart-cities-drl==0.1.0) (1.53.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]->smart-cities-drl==0.1.0) (2.4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]->smart-cities-drl==0.1.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]->smart-cities-drl==0.1.0) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]->smart-cities-drl==0.1.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray[rllib]->smart-cities-drl==0.1.0) (0.4.8)\n",
            "Installing collected packages: smart-cities-drl\n",
            "  Found existing installation: smart-cities-drl 0.1.0\n",
            "    Can't uninstall 'smart-cities-drl'. No files were found to uninstall.\n",
            "  Running setup.py develop for smart-cities-drl\n",
            "Successfully installed smart-cities-drl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv2IiHGYRLDQ",
        "outputId": "cf63eafc-eb33-4925-d201-e777522fa554"
      },
      "source": [
        "import json\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "import gym\n",
        "from gym.spaces import Box, Discrete, Tuple\n",
        "import ray\n",
        "from ray.tune import run, choice, function\n",
        "from ray.rllib.agents.ppo import DEFAULT_CONFIG\n",
        "from core.rl import PPOAgent\n",
        "from core.pbt import PbtOptimizer\n",
        "from smartcab.env import SmartCabEnv, HierarchicalSmartCabEnv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "  \"update your install command.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_compile is deprecated, use jit_compile instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hrqtufqq24H"
      },
      "source": [
        "## Proximal Policy Optimization (PPO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0jHuZL9Tgm_"
      },
      "source": [
        "### Tune hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpHcdjslVi9G",
        "outputId": "6e195dc0-aa00-4277-a62d-b039c979876f"
      },
      "source": [
        "config = DEFAULT_CONFIG\n",
        "env = HierarchicalSmartCabEnv(None)\n",
        "\n",
        "def policy_mapping_fn(agent_id):\n",
        "    if agent_id.startswith(\"low_level_\"):\n",
        "        return \"low_level_policy\"\n",
        "    else:\n",
        "        return \"high_level_policy\"\n",
        "\n",
        "def explore(config):\n",
        "        # Postprocess the perturbed config to ensure it's still valid used if PBT\n",
        "        # ensure we collect enough timesteps to do sgd\n",
        "        if config[\"train_batch_size\"] < config[\"sgd_minibatch_size\"] * 2:\n",
        "            config[\"train_batch_size\"] = config[\"sgd_minibatch_size\"] * 2\n",
        "        # ensure we run at least one sgd iter\n",
        "        if config[\"num_sgd_iter\"] < 1:\n",
        "            config[\"num_sgd_iter\"] = 1\n",
        "        return config\n",
        "\n",
        "multiagent = {\n",
        "        \"policies\": {\n",
        "            \"high_level_policy\": (None, \n",
        "                                  env.flat_env.observation_space,\n",
        "                                  env.high_action_space, \n",
        "                                  {}),\n",
        "            \"low_level_policy\": (None,\n",
        "                                 Tuple([\n",
        "                                        env.flat_env.observation_space,\n",
        "                                        env.high_action_space,\n",
        "                                 ]), \n",
        "                                 env.low_action_space, \n",
        "                                 {}),\n",
        "        },\n",
        "        \"policy_mapping_fn\": function(policy_mapping_fn),\n",
        "        \"policies_to_train\": [\"high_level_policy\"],\n",
        "        \"count_steps_by\":\"env_steps\",\n",
        "        \"observation_filter\": \"MeanStdFilter\",\n",
        "        \"observation_fn\": None\n",
        "    }\n",
        "config[\"multiagent\"] = multiagent\n",
        "\n",
        "ppo = PPOAgent(\"smartcab_ppo_tune\", HierarchicalSmartCabEnv, config)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DeprecationWarning: wrapping <function policy_mapping_fn at 0x7fe2dcda3f80> with tune.function() is no longer needed\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[(2, 3), (2, 12), (4, 7), (6, 1), (11, 13), (13, 9)]\n",
            "Action Space:  Discrete(6)\n",
            "Observation Space:  Tuple(Box(0.0, 14.0, (2,), float32), Discrete(7), Discrete(6))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-30 11:39:26,740\tINFO services.py:1274 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "/usr/local/lib/python3.7/dist-packages/ray/tune/utils/util.py:759: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  if np.isnan(value):\n",
            "2021-06-30 11:39:29,153\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "2021-06-30 11:39:29,158\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "\u001b[2m\u001b[36m(pid=3116)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3116)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3116)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3115)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3115)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3115)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3116)\u001b[0m [(2, 3), (2, 12), (4, 7), (6, 1), (11, 13), (13, 9)]\n",
            "\u001b[2m\u001b[36m(pid=3116)\u001b[0m Action Space:  Discrete(6)\n",
            "\u001b[2m\u001b[36m(pid=3116)\u001b[0m Observation Space:  Tuple(Box(0.0, 14.0, (2,), float32), Discrete(7), Discrete(6))\n",
            "\u001b[2m\u001b[36m(pid=3115)\u001b[0m [(2, 3), (2, 12), (4, 7), (6, 1), (11, 13), (13, 9)]\n",
            "\u001b[2m\u001b[36m(pid=3115)\u001b[0m Action Space:  Discrete(6)\n",
            "\u001b[2m\u001b[36m(pid=3115)\u001b[0m Observation Space:  Tuple(Box(0.0, 14.0, (2,), float32), Discrete(7), Discrete(6))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-06-30 11:39:42,360\tINFO trainable.py:104 -- Trainable.setup took 13.441 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
            "2021-06-30 11:39:42,361\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49VrIblUM4wT"
      },
      "source": [
        "tune_config = {\n",
        "    \"env\": HierarchicalSmartCabEnv,\n",
        "    \"seed\": 123,\n",
        "    \"horizon\": 100,\n",
        "    \"num_gpus\": 1,\n",
        "    \"num_workers\": 1,\n",
        "    \"observation_filter\": \"MeanStdFilter\",\n",
        "    \"lambda\": 0.9,\n",
        "    \"clip_param\": 0.3,\n",
        "    \"lr\": 5e-5,\n",
        "    \"num_sgd_iter\": choice([10, 20, 30]),\n",
        "    \"sgd_minibatch_size\": choice([128, 256, 512]),\n",
        "    \"train_batch_size\": choice([8000, 16000, 32000]),\n",
        "    \"multiagent\": multiagent\n",
        "}\n",
        "stop_criteria = {\n",
        "    \"timesteps_total\": 2000000\n",
        "}\n",
        "hyperparam_mutations={\n",
        "    \"lambda\": lambda: random.uniform(0.7, 1.0),\n",
        "    \"clip_param\": lambda: random.uniform(0.1, 0.5),\n",
        "    \"lr\": [1e-3, 5e-4, 1e-4, 5e-5, 1e-5],\n",
        "    \"num_sgd_iter\": lambda: random.randint(1, 30),\n",
        "    \"sgd_minibatch_size\": lambda: random.randint(128, 16384),\n",
        "    \"train_batch_size\": lambda: random.randint(2000, 160000),\n",
        "}\n",
        "pbt = PbtOptimizer(hyperparam_mutations)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BhEbUSY6Vs-r",
        "outputId": "39dabc02-969e-45bf-d506-f6dcde09c483"
      },
      "source": [
        "ppo.restart()\n",
        "analysis = ppo.tune(tune_config, stop_criteria, scheduler=pbt.scheduler)\n",
        "best_config =  analysis.get_best_config(metric=\"episode_reward_mean\", mode=\"max\")\n",
        "print(\"Best hyperparameters found: \", best_config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-06-30 11:39:45,188\tINFO services.py:1274 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
            "/usr/local/lib/python3.7/dist-packages/ray/tune/utils/util.py:759: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  if np.isnan(value):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.0/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /content/ray_results/smartcab_ppo_tune<br>Number of trials: 8/8 (8 PENDING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00000</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">              8000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">             16000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             32000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             16000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">              8000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">             32000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             32000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             16000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3307)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3307)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3307)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n",
            "\u001b[2m\u001b[36m(pid=3307)\u001b[0m 2021-06-30 11:39:51,039\tINFO trainer.py:671 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
            "\u001b[2m\u001b[36m(pid=3307)\u001b[0m 2021-06-30 11:39:51,040\tINFO trainer.py:698 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 2.5/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /content/ray_results/smartcab_ppo_tune<br>Number of trials: 8/8 (7 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">              8000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">             16000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             32000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             16000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">              8000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">             32000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             32000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             16000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3308)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_probability/python/internal/variadic_reduce.py:115: calling function (from tensorflow.python.eager.def_function) with experimental_compile is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(pid=3308)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(pid=3308)\u001b[0m experimental_compile is deprecated, use jit_compile instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3308)\u001b[0m [(2, 3), (2, 12), (4, 7), (6, 1), (11, 13), (13, 9)]\n",
            "\u001b[2m\u001b[36m(pid=3308)\u001b[0m Action Space:  Discrete(6)\n",
            "\u001b[2m\u001b[36m(pid=3308)\u001b[0m Observation Space:  Tuple(Box(0.0, 14.0, (2,), float32), Discrete(7), Discrete(6))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.1/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /content/ray_results/smartcab_ppo_tune<br>Number of trials: 8/8 (7 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">              8000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">             16000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             32000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             16000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">              8000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">             32000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             32000</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             16000</td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(pid=3307)\u001b[0m 2021-06-30 11:40:00,916\tWARNING util.py:53 -- Install gputil for GPU system monitoring.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Result for PPO_HierarchicalSmartCabEnv_df600_00000:\n",
            "  agent_timesteps_total: 7920\n",
            "  custom_metrics: {}\n",
            "  date: 2021-06-30_11-40-09\n",
            "  done: false\n",
            "  episode_len_mean: 100.0\n",
            "  episode_media: {}\n",
            "  episode_reward_max: -1915.0\n",
            "  episode_reward_mean: -2232.5625\n",
            "  episode_reward_min: -3088.0\n",
            "  episodes_this_iter: 80\n",
            "  episodes_total: 80\n",
            "  experiment_id: 04ed6812b8194e1b96307b2ca853f968\n",
            "  hostname: c2f6a5589ba4\n",
            "  info:\n",
            "    learner:\n",
            "      high_level_policy:\n",
            "        learner_stats:\n",
            "          cur_kl_coeff: 0.20000000298023224\n",
            "          cur_lr: 4.999999873689376e-05\n",
            "          entropy: 0.6912553906440735\n",
            "          entropy_coeff: 0.0\n",
            "          kl: 0.0018854527734220028\n",
            "          model: {}\n",
            "          policy_loss: -0.026443367823958397\n",
            "          total_loss: 521843.5\n",
            "          vf_explained_var: 0.00019735097885131836\n",
            "          vf_loss: 521843.5\n",
            "    num_agent_steps_sampled: 7920\n",
            "    num_agent_steps_trained: 88\n",
            "    num_steps_sampled: 8000\n",
            "    num_steps_trained: 8000\n",
            "  iterations_since_restore: 1\n",
            "  node_ip: 172.28.0.2\n",
            "  num_healthy_workers: 1\n",
            "  off_policy_estimator: {}\n",
            "  perf:\n",
            "    cpu_util_percent: 59.49166666666667\n",
            "    ram_util_percent: 24.899999999999995\n",
            "  pid: 3307\n",
            "  policy_reward_max:\n",
            "    high_level_policy: -563.0\n",
            "    low_level_policy: -31.0\n",
            "  policy_reward_mean:\n",
            "    high_level_policy: -742.8375\n",
            "    low_level_policy: -709.3928571428571\n",
            "  policy_reward_min:\n",
            "    high_level_policy: -1483.0\n",
            "    low_level_policy: -922.0\n",
            "  sampler_perf:\n",
            "    mean_action_processing_ms: 0.04742574936120962\n",
            "    mean_env_render_ms: 0.0\n",
            "    mean_env_wait_ms: 0.03949976938841508\n",
            "    mean_inference_ms: 0.7156949388341686\n",
            "    mean_raw_obs_processing_ms: 0.1551883546371279\n",
            "  time_since_restore: 8.127164125442505\n",
            "  time_this_iter_s: 8.127164125442505\n",
            "  time_total_s: 8.127164125442505\n",
            "  timers:\n",
            "    learn_throughput: 27282.599\n",
            "    learn_time_ms: 293.227\n",
            "    load_throughput: 265304.859\n",
            "    load_time_ms: 30.154\n",
            "    sample_throughput: 1029.605\n",
            "    sample_time_ms: 7769.972\n",
            "    update_time_ms: 2.971\n",
            "  timestamp: 1625053209\n",
            "  timesteps_since_restore: 0\n",
            "  timesteps_total: 8000\n",
            "  training_iteration: 1\n",
            "  trial_id: df600_00000\n",
            "  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "== Status ==<br>Memory usage on this node: 3.2/12.7 GiB<br>PopulationBasedTraining: 0 checkpoints, 0 perturbs<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.31 GiB heap, 0.0/3.65 GiB objects (0.0/1.0 accelerator_type:T4)<br>Result logdir: /content/ray_results/smartcab_ppo_tune<br>Number of trials: 8/8 (7 PENDING, 1 RUNNING)<br><table>\n",
              "<thead>\n",
              "<tr><th>Trial name                             </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  num_sgd_iter</th><th style=\"text-align: right;\">  sgd_minibatch_size</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00000</td><td>RUNNING </td><td>172.28.0.2:3307</td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         8.12716</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">-2232.56</td><td style=\"text-align: right;\">               -1915</td><td style=\"text-align: right;\">               -3088</td><td style=\"text-align: right;\">               100</td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00001</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">             16000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00002</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             32000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00003</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            10</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             16000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00004</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">              8000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00005</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 256</td><td style=\"text-align: right;\">             32000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00006</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            20</td><td style=\"text-align: right;\">                 128</td><td style=\"text-align: right;\">             32000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "<tr><td>PPO_HierarchicalSmartCabEnv_df600_00007</td><td>PENDING </td><td>               </td><td style=\"text-align: right;\">            30</td><td style=\"text-align: right;\">                 512</td><td style=\"text-align: right;\">             16000</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                    </td><td style=\"text-align: right;\">                  </td></tr>\n",
              "</tbody>\n",
              "</table><br><br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjOOMnKkZ3Jg"
      },
      "source": [
        "best_config = {\n",
        "    \"observation_filter\": \"MeanStdFilter\",\n",
        "    \"model\": {\"free_log_std\": True},\n",
        "    \"num_sgd_iter\": 10,\n",
        "    \"sgd_minibatch_size\": 128,\n",
        "    \"lambda\": 0.731396,\n",
        "    \"clip_param\": 0.317651,\n",
        "    \"lr\": 5e-05,\n",
        "    \"train_batch_size\": 18812,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyptyrNeTgnA"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsi17r9uSE-2"
      },
      "source": [
        "ppo = PPOAgent(\"smartcab_ppo_train\", best_config, WasteNetEnv, {})\n",
        "ppo.train(num_iter=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE5CrWozRLDS"
      },
      "source": [
        "policy = ppo.agent.get_policy()\n",
        "model = policy.model\n",
        "print(model.base_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P4Tl-1zsU2h"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_hBOp4kVTQ5"
      },
      "source": [
        "# ppo = PPOAgent(\"smartcab_ppo_test\", best_config, SmartCabEnv, {})\n",
        "# ppo.load(\"checkpoints/checkpoint-best\")\n",
        "ppo.test(num_episodes=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVaoPUTNToBF"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St6gMyOST3_y"
      },
      "source": [
        "!zip -r /content/ray_results.zip /content/ray_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qdEKhi5sWoX"
      },
      "source": [
        "%load_ext tensorboard \n",
        "%tensorboard --logdir=\"/content/ray_results/\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}